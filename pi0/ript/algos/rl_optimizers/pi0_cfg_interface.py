import torch
from torch import nn
from typing import Any, Dict, List, Optional, Tuple, Union
import numpy as np
import torch.nn.functional as F
import json
from pathlib import Path
from pi0.modeling_pi0 import PI0Policy
# from lerobot.common.utils.utils import get_safe_dtype  # æš‚æ—¶æ³¨é‡Šæ‰ï¼Œä½¿ç”¨æœ¬åœ°å®ç°

# Assuming the base interface is in a shared location
from pi0.ript.algos.rl_optimizers.model_interface import RLModelInterface

# æœ¬åœ°å®ç°get_safe_dtypeå‡½æ•°
def get_safe_dtype(tensor):
    """Get safe dtype for tensor operations"""
    if tensor.dtype in [torch.float16, torch.bfloat16]:
        return torch.float32
    return tensor.dtype


class PI0_CFG_Adapter(RLModelInterface):
    """
    Adapter for PI0Policy to work with the RIPT framework using an
    advantage-weighted loss, inspired by Classifier-Free Guidance.

    This adapter computes a weighted L2 loss from the policy's forward pass,
    which serves as a proxy for policy gradient updates, bypassing the need
    for explicit log_prob calculations or a value network.
    """

    def __init__(self, policy: PI0Policy, norm_stats_path: Optional[str] = None, **kwargs):
        """
        Initialize the adapter with a PI0Policy instance.
        Args:
            policy: An instance of PI0Policy.
            norm_stats_path: Path to norm_stats.json file for normalization. 
                           If None, will try to find it automatically.
        """
        # The base model is the PI0Policy itself.
        super().__init__(model=policy, **kwargs)
        self.policy = policy
        
        # è§†é¢‘æ”¶é›†ç›¸å…³
        self.video_frames = {}  # {episode_idx: [frames]}
        self.video_save_enabled = True
        
        # åŠ è½½å½’ä¸€åŒ–ç»Ÿè®¡ä¿¡æ¯
        self._load_norm_stats(norm_stats_path)
        
    def _load_norm_stats(self, norm_stats_path: Optional[str] = None):
        """Load normalization statistics from norm_stats.json"""
        if norm_stats_path is None:
            # å°è¯•åœ¨å¸¸è§ä½ç½®æ‰¾åˆ°norm_stats.json
            possible_paths = [
                "/zhaohan/ZJH/openpi_pytorch/checkpoints/pi0_libero_pytorch/norm_stats.json",
                "/zhaohan/ZJH/openpi_pytorch/lerobot_dataset/norm_stats.json", 
                "./norm_stats.json"
            ]
            
            for path in possible_paths:
                if Path(path).exists():
                    norm_stats_path = path
                    break
        
        if norm_stats_path and Path(norm_stats_path).exists():
            print(f"Loading norm_stats from: {norm_stats_path}")
            with open(norm_stats_path) as f:
                norm_stats = json.load(f)
                
            # æå–çŠ¶æ€å’ŒåŠ¨ä½œçš„å½’ä¸€åŒ–å‚æ•°
            self.state_mean = np.array(norm_stats["norm_stats"]["state"]["mean"][:8], dtype=np.float32)
            self.state_std = np.array(norm_stats["norm_stats"]["state"]["std"][:8], dtype=np.float32)
            self.action_mean = np.array(norm_stats["norm_stats"]["actions"]["mean"][:7], dtype=np.float32)
            self.action_std = np.array(norm_stats["norm_stats"]["actions"]["std"][:7], dtype=np.float32)
            
            print(f"âœ… Loaded normalization stats:")
            print(f"  State mean shape: {self.state_mean.shape}")
            print(f"  State std shape: {self.state_std.shape}")
            print(f"  Action mean shape: {self.action_mean.shape}")
            print(f"  Action std shape: {self.action_std.shape}")
        else:
            print("âš ï¸  Warning: No norm_stats.json found, using identity normalization")
            # ä½¿ç”¨å•ä½å½’ä¸€åŒ–ï¼ˆä¸è¿›è¡Œå½’ä¸€åŒ–ï¼‰
            self.state_mean = np.zeros(8, dtype=np.float32)
            self.state_std = np.ones(8, dtype=np.float32)
            self.action_mean = np.zeros(7, dtype=np.float32)
            self.action_std = np.ones(7, dtype=np.float32)
    
    def normalize_state(self, state: np.ndarray) -> np.ndarray:
        """Normalize state using loaded statistics"""
        return (state - self.state_mean[:len(state)]) / (self.state_std[:len(state)] + 1e-6)
    
    def denormalize_action(self, action: np.ndarray) -> np.ndarray:
        """Denormalize action using loaded statistics"""
        return action * (self.action_std + 1e-6) + self.action_mean

    def process_episodes(
        self,
        episodes: List[Dict[str, Any]],
        device: Optional[torch.device] = None,
    ) -> Dict[str, Any]:
        """
        Process a list of episode dictionaries into a single batch usable by PI0Policy.
        ä¼˜åŒ–ç‰ˆæœ¬ï¼Œæ›´å¥½åœ°å¤„ç† Pi0LiberoRunner ç”Ÿæˆçš„ episode æ•°æ®ã€‚
        
        Args:
            episodes: A list of episode dictionaries collected from the runner.
            device: The device to place tensors on.
        Returns:
            A batch dictionary ready for `policy.forward()`.
        """
        if device is None:
            device = self.device

        # Validate input
        if not episodes:
            raise ValueError("Empty episodes list provided")

        all_obs_states = []
        all_obs_images = []
        all_actions = []
        all_tasks = []

        # Process each episode
        for i, episode in enumerate(episodes):
            try:
                # éªŒè¯ episode ç»“æ„
                required_keys = ['observations', 'actions', 'task']
                missing_keys = [key for key in required_keys if key not in episode]
                if missing_keys:
                    raise KeyError(f"Episode {i} missing keys: {missing_keys}")
                
                # è·å– episode æ•°æ®
                observations = episode['observations']
                actions = episode['actions'] 
                tasks = episode['task']
                
                if not observations:
                    raise ValueError(f"Episode {i} has empty observations")
                    
                # å¤„ç†æ¯ä¸ªæ—¶é—´æ­¥çš„æ•°æ®
                episode_states = []
                episode_images = []
                episode_actions = []
                
                # å–æ ·æœ¬ï¼šç¡®ä¿å›ºå®šçš„åºåˆ—é•¿åº¦
                max_steps = min(len(observations), len(actions))
                # ğŸ”§ ä¿®å¤ï¼šåˆ†ç¦»æ‰©æ•£æ­¥æ•°å’ŒåŠ¨ä½œåºåˆ—é•¿åº¦
                # ä½¿ç”¨ n_action_steps ä½œä¸ºåŠ¨ä½œåºåˆ—é•¿åº¦ï¼Œè€Œä¸æ˜¯ num_stepsï¼ˆæ‰©æ•£å»å™ªæ­¥æ•°ï¼‰
                target_seq_len = getattr(self.policy.config, 'n_action_steps', 50)  
                diffusion_steps = getattr(self.policy.config, 'num_steps', 10)
                print(f"Using target_seq_len={target_seq_len} from PI0 config (n_action_steps)")
                print(f"Diffusion denoising steps={diffusion_steps} from PI0 config (num_steps)")
                
                # ä¸ºäº†ç”Ÿæˆå®Œæ•´çš„è°ƒè¯•è§†é¢‘ï¼Œæˆ‘ä»¬éœ€è¦ä¿å­˜æ‰€æœ‰æ­¥éª¤çš„å›¾åƒ
                # ä½†å¯¹äºæ¨¡å‹è®­ç»ƒï¼Œä»ç„¶ä½¿ç”¨å›ºå®šçš„åºåˆ—é•¿åº¦
                debug_save_all_steps = True  # å¯ç”¨å®Œæ•´è½¨è¿¹è°ƒè¯•ä¿å­˜
                
                if debug_save_all_steps:
                    # è°ƒè¯•æ¨¡å¼ï¼šä¿å­˜æ‰€æœ‰æ­¥éª¤çš„å›¾åƒæ•°æ®
                    sample_indices = list(range(max_steps))
                    print(f"è°ƒè¯•æ¨¡å¼ï¼šä¿å­˜å®Œæ•´è½¨è¿¹ {max_steps} æ­¥ç”¨äºè§†é¢‘ç”Ÿæˆ")
                elif max_steps >= target_seq_len:
                    # å¦‚æœæœ‰è¶³å¤Ÿçš„æ­¥æ•°ï¼Œå–æœ€å target_seq_len æ­¥
                    sample_indices = list(range(max_steps - target_seq_len, max_steps))
                else:
                    # å¦‚æœæ­¥æ•°ä¸è¶³ï¼Œå–æ‰€æœ‰æ­¥æ•°å¹¶è¡¥é½
                    sample_indices = list(range(max_steps))
                
                for step_idx in sample_indices:
                    # å¤„ç†è§‚æµ‹æ•°æ®
                    if step_idx < len(observations):
                        step_obs = observations[step_idx]
                        
                        # å¤„ç†çŠ¶æ€æ•°æ®
                        state = self._extract_state_from_obs(step_obs, i, step_idx)
                        episode_states.append(state)
                        
                        # å¤„ç†å›¾åƒæ•°æ®
                        image = self._extract_image_from_obs(step_obs, i, step_idx)
                        episode_images.append(image)
                    else:
                        # å¦‚æœè§‚æµ‹æ•°æ®ä¸è¶³ï¼Œä½¿ç”¨é»˜è®¤å€¼
                        episode_states.append(np.zeros(7, dtype=np.float32))
                        episode_images.append(np.ones((224, 224, 3), dtype=np.uint8) * 128)
                    
                    # å¤„ç†åŠ¨ä½œæ•°æ®
                    if step_idx < len(actions):
                        step_action = actions[step_idx]
                        if isinstance(step_action, list) and len(step_action) > 0:
                            # å–ç¬¬ä¸€ä¸ªç¯å¢ƒçš„åŠ¨ä½œï¼ˆå¯¹äºå•ç¯å¢ƒæˆ–ç¬¬ä¸€ä¸ªç¯å¢ƒï¼‰
                            action = np.array(step_action[0], dtype=np.float32)
                        else:
                            action = np.array(step_action, dtype=np.float32)
                        
                        # ç¡®ä¿åŠ¨ä½œæ˜¯ 7 ç»´çš„ï¼ˆLIBERO æ ¼å¼ï¼‰
                        if action.size != 7:
                            if action.size > 7:
                                action = action[:7]
                            else:
                                padded_action = np.zeros(7, dtype=np.float32)
                                padded_action[:action.size] = action
                                action = padded_action
                        
                        episode_actions.append(action)
                    else:
                        episode_actions.append(np.zeros(7, dtype=np.float32))
                
                # å¯¹æ•´ä¸ª episode çš„æ•°æ®åšèšåˆï¼Œç¡®ä¿å›ºå®šçš„åºåˆ—é•¿åº¦
                if episode_states:
                    if debug_save_all_steps:
                        # è°ƒè¯•æ¨¡å¼ï¼šä¿å­˜æ‰€æœ‰å›¾åƒç”¨äºè§†é¢‘ç”Ÿæˆï¼Œä½†åªç”¨æœ€åçš„çŠ¶æ€å’ŒåŠ¨ä½œç”¨äºè®­ç»ƒ
                        print(f"è°ƒè¯•ï¼šä¿å­˜äº† {len(episode_images)} å¼ å›¾åƒç”¨äºè§†é¢‘ç”Ÿæˆ")
                        
                        # å¯¹äºæ¨¡å‹è®­ç»ƒï¼Œä»ä½¿ç”¨æœ€åçš„çŠ¶æ€å’Œæœ€åtarget_seq_lenä¸ªåŠ¨ä½œ
                        final_state = np.array(episode_states[-1])  # å–æœ€åä¸€ä¸ªçŠ¶æ€
                        final_image = episode_images[-1]  # å–æœ€åä¸€ä¸ªå›¾åƒç”¨äºæ¨¡å‹è¾“å…¥
                        
                        # ç¡®ä¿åŠ¨ä½œåºåˆ—é•¿åº¦ä¸º target_seq_lenï¼ˆç”¨äºæ¨¡å‹è®­ç»ƒï¼‰
                        if len(episode_actions) >= target_seq_len:
                            # å–æœ€å target_seq_len ä¸ªåŠ¨ä½œç”¨äºè®­ç»ƒ
                            final_action = np.array(episode_actions[-target_seq_len:])
                        else:
                            # ä¸è¶³çš„è¯è¿›è¡Œå¡«å……
                            padded_actions = []
                            for i in range(target_seq_len):
                                if i < len(episode_actions):
                                    padded_actions.append(episode_actions[i])
                                else:
                                    # ç”¨æœ€åä¸€ä¸ªåŠ¨ä½œå¡«å……
                                    padded_actions.append(episode_actions[-1] if episode_actions else np.zeros(7, dtype=np.float32))
                            final_action = np.array(padded_actions)
                        
                        print(f"è°ƒè¯•ï¼šè®­ç»ƒæ•°æ® - çŠ¶æ€å½¢çŠ¶: {final_state.shape}, å›¾åƒå½¢çŠ¶: {final_image.shape}, åŠ¨ä½œå½¢çŠ¶: {final_action.shape}")
                    else:
                        # åŸå§‹æ¨¡å¼ï¼šåªå¤„ç†é‡‡æ ·çš„æ­¥éª¤
                        final_state = np.array(episode_states[-1])  # å–æœ€åä¸€ä¸ªçŠ¶æ€
                        final_image = episode_images[-1]  # å–æœ€åä¸€ä¸ªå›¾åƒ
                        
                        # ç¡®ä¿åŠ¨ä½œåºåˆ—é•¿åº¦ä¸º target_seq_len
                        if len(episode_actions) >= target_seq_len:
                            final_action = np.array(episode_actions[:target_seq_len])  # å–å‰ target_seq_len ä¸ª
                        else:
                            # ä¸è¶³çš„è¯è¿›è¡Œå¡«å……
                            padded_actions = []
                            for i in range(target_seq_len):
                                if i < len(episode_actions):
                                    padded_actions.append(episode_actions[i])
                                else:
                                    # ç”¨æœ€åä¸€ä¸ªåŠ¨ä½œå¡«å……
                                    padded_actions.append(episode_actions[-1] if episode_actions else np.zeros(7, dtype=np.float32))
                            final_action = np.array(padded_actions)
                else:
                    final_state = np.zeros(7, dtype=np.float32)
                    final_image = np.ones((224, 224, 3), dtype=np.uint8) * 128
                    final_action = np.zeros((target_seq_len, 7), dtype=np.float32)
                
                all_obs_states.append(final_state)
                all_obs_images.append(final_image)
                all_actions.append(final_action)
                
                # åœ¨è°ƒè¯•æ¨¡å¼ä¸‹ï¼Œç”Ÿæˆepisodeè§†é¢‘
                if debug_save_all_steps and len(episode_images) > 10:
                    try:
                        self._generate_episode_video(episode_images, i, tasks[0] if tasks else "unknown_task")
                    except Exception as video_e:
                        print(f"ç”Ÿæˆepisodeè§†é¢‘å¤±è´¥: {video_e}")
                
                # å¤„ç†ä»»åŠ¡æè¿°
                if tasks:
                    task_str = tasks[0] if isinstance(tasks, list) else str(tasks)
                else:
                    task_str = "default task"
                all_tasks.append(task_str)
                
            except Exception as e:
                print(f"Error processing episode {i}: {e}")
                print(f"Episode keys: {episode.keys() if isinstance(episode, dict) else 'Not a dict'}")
                # ä½¿ç”¨é»˜è®¤å€¼ç»§ç»­
                all_obs_states.append(np.zeros(7, dtype=np.float32))
                all_obs_images.append(np.ones((224, 224, 3), dtype=np.uint8) * 128)
                all_actions.append(np.zeros((1, 7), dtype=np.float32))
                all_tasks.append("default task")

        try:
            # ğŸ”§ å…³é”®ä¿®å¤ï¼šå°†7ç»´LIBEROåŠ¨ä½œå¡«å……åˆ°32ç»´PI0åŠ¨ä½œ
            padded_actions = []
            for action_seq in all_actions:
                # action_seq shape: (sequence_length, 7)
                seq_len = action_seq.shape[0]
                # åˆ›å»º (sequence_length, 32) çš„é›¶å¡«å……åŠ¨ä½œ
                padded_action_seq = np.zeros((seq_len, 32), dtype=np.float32)
                # å°†å‰7ç»´å¤åˆ¶è¿‡å»
                padded_action_seq[:, :7] = action_seq
                padded_actions.append(padded_action_seq)
            
            # Create the final batch dictionary with nested structure expected by PI0
            batch = {
                'state': torch.from_numpy(np.stack(all_obs_states)).to(device, dtype=torch.float32),
                'image': {
                    'base_0_rgb': torch.from_numpy(np.stack(all_obs_images)).to(device, dtype=torch.uint8)
                },
                'action': torch.from_numpy(np.stack(padded_actions)).to(device, dtype=torch.float32),
                'prompt': all_tasks,
            }
            
            # Validate batch dimensions
            batch_size = len(episodes)
            assert batch['state'].shape[0] == batch_size
            assert batch['image']['base_0_rgb'].shape[0] == batch_size
            assert batch['action'].shape[0] == batch_size
            assert len(batch['prompt']) == batch_size
            
            print(f"Processed batch - states: {batch['state'].shape}, "
                  f"images: {batch['image']['base_0_rgb'].shape}, "
                  f"actions: {batch['action'].shape} (padded to 32 dims)")
            
            return batch
            
        except Exception as e:
            print(f"Error creating batch: {e}")
            print(f"States shapes: {[s.shape for s in all_obs_states]}")
            print(f"Images shapes: {[img.shape for img in all_obs_images]}")
            print(f"Actions shapes: {[a.shape for a in all_actions]}")
            raise

    def compute_weighted_loss(
        self,
        episodes: List[Dict[str, Any]],
        advantages: torch.Tensor,
        device: Optional[torch.device] = None,
    ) -> torch.Tensor:
        """
        Computes the advantage-weighted L2 loss for a batch of trajectories.
        This is the core of the CFG-style training update.
        Enhanced with comprehensive NaN/Inf detection and error handling.

        Args:
            episodes: A list of episode dictionaries.
            advantages: A tensor of shape (batch_size,) containing the advantage for each episode.
            device: The device to place tensors on.

        Returns:
            A scalar tensor representing the final weighted loss for backpropagation.
        """
        if device is None:
            device = self.device

        # Validate inputs
        if not episodes:
            print("âŒ ç©ºçš„episodeåˆ—è¡¨ï¼Œè¿”å›é›¶æŸå¤±")
            return torch.tensor(0.0, device=device, requires_grad=True)
        
        if advantages is None or len(advantages) == 0:
            print("âŒ ç©ºçš„ä¼˜åŠ¿å¼ é‡ï¼Œè¿”å›é›¶æŸå¤±")
            return torch.tensor(0.0, device=device, requires_grad=True)
        
        if len(episodes) != len(advantages):
            print(f"âŒ episodesæ•°é‡({len(episodes)})ä¸advantagesæ•°é‡({len(advantages)})ä¸åŒ¹é…")
            return torch.tensor(0.0, device=device, requires_grad=True)

        # Check for NaN/Inf in advantages before processing
        if torch.isnan(advantages).any() or torch.isinf(advantages).any():
            print("âš ï¸ æ£€æµ‹åˆ°ä¼˜åŠ¿ä¸­çš„NaN/Infå€¼ï¼Œè¿›è¡Œæ¸…ç†")
            advantages = torch.nan_to_num(advantages, nan=0.0, posinf=1.0, neginf=-1.0)

        # å…³é”®ä¿®æ”¹ï¼šä¸ºæ¯ä¸ªè½¨è¿¹åˆ†åˆ«è®¡ç®—æŸå¤±ï¼Œä»¥è·å¾—æ­£ç¡®çš„å½¢çŠ¶
        print(f"å¼€å§‹ä¸º {len(episodes)} ä¸ªè½¨è¿¹åˆ†åˆ«è®¡ç®—æŸå¤±")
        per_trajectory_losses = []
        
        # æ·»åŠ è¿›åº¦æ¡ä»¥æ›´æ¸…æ™°åœ°æ˜¾ç¤ºå¤„ç†è¿›åº¦
        from tqdm import tqdm
        
        try:
            for i, episode in tqdm(enumerate(episodes), total=len(episodes), desc="è®¡ç®—è½¨è¿¹æŸå¤±", leave=False):
                # å°†å•ä¸ªè½¨è¿¹è½¬æ¢ä¸ºæ‰¹æ¬¡æ ¼å¼
                single_batch = self.process_episodes([episode], device)
                
                # åªåœ¨æœ‰é—®é¢˜æ—¶æ‰è¾“å‡ºè¯¦ç»†è°ƒè¯•ä¿¡æ¯
                debug_needed = False
                for key, value in single_batch.items():
                    if torch.is_tensor(value):
                        # Check for NaN/Inf in input tensors
                        if torch.isnan(value).any() or torch.isinf(value).any():
                            if not debug_needed:  # åªè¾“å‡ºä¸€æ¬¡header
                                print(f"\nâš ï¸ è½¨è¿¹ {i}: æ£€æµ‹åˆ°å¼‚å¸¸å€¼")
                                debug_needed = True
                            print(f"  - å¼ é‡ {key} å«æœ‰NaN/Infå€¼")
                            if key == 'observation.image':
                                single_batch[key] = torch.nan_to_num(value, nan=0.5, posinf=1.0, neginf=0.0)
                            else:
                                single_batch[key] = torch.nan_to_num(value, nan=0.0, posinf=1.0, neginf=-1.0)
                
                # ä¸ºå•ä¸ªè½¨è¿¹è®¡ç®—æŸå¤±
                # ğŸ”§ Debug: æ£€æŸ¥ä¼ é€’ç»™PI0çš„batchç»“æ„
                if i == 0:  # åªæ‰“å°ç¬¬ä¸€ä¸ªè½¨è¿¹çš„è°ƒè¯•ä¿¡æ¯
                    print(f"ä¼ é€’ç»™PI0çš„batchç»“æ„:")
                    for key, value in single_batch.items():
                        if isinstance(value, dict):
                            print(f"  {key}: dict with keys {list(value.keys())}")
                            for k2, v2 in value.items():
                                print(f"    {k2}: {type(v2)} {getattr(v2, 'shape', 'N/A')}")
                        else:
                            print(f"  {key}: {type(value)} {getattr(value, 'shape', 'N/A')}")
                
                policy_outputs = self.policy.forward(single_batch)
                
                # å¤„ç†ä¸åŒçš„policyè¾“å‡ºæ ¼å¼
                if isinstance(policy_outputs, tuple):
                    single_loss = policy_outputs[0]
                elif isinstance(policy_outputs, torch.Tensor):
                    single_loss = policy_outputs
                elif isinstance(policy_outputs, dict) and 'loss' in policy_outputs:
                    single_loss = policy_outputs['loss']
                else:
                    print(f"âŒ è½¨è¿¹ {i}: æœªçŸ¥çš„ç­–ç•¥è¾“å‡ºæ ¼å¼: {type(policy_outputs)}")
                    single_loss = torch.tensor(0.0, device=device, requires_grad=True)
                
                if single_loss is None:
                    print(f"âŒ è½¨è¿¹ {i}: ç­–ç•¥è¿”å›NoneæŸå¤±")
                    single_loss = torch.tensor(0.0, device=device, requires_grad=True)
                
                # ç¡®ä¿æŸå¤±æ˜¯æ ‡é‡
                if single_loss.dim() > 0:
                    single_loss = single_loss.mean()
                
                # æ£€æŸ¥NaN/Inf
                if torch.isnan(single_loss) or torch.isinf(single_loss):
                    print(f"âš ï¸ è½¨è¿¹ {i}: æ£€æµ‹åˆ°NaN/InfæŸå¤±ï¼Œæ›¿æ¢ä¸º0")
                    single_loss = torch.tensor(0.0, device=device, requires_grad=True)
                
                per_trajectory_losses.append(single_loss)
                # åªä¿ç•™å¼‚å¸¸æƒ…å†µçš„æ—¥å¿—è¾“å‡ºï¼Œæ­£å¸¸æƒ…å†µé™é»˜å¤„ç†
                
            # å°†åˆ—è¡¨è½¬æ¢ä¸ºå¼ é‡
            per_trajectory_loss = torch.stack(per_trajectory_losses)  # Shape: (num_trajectories,)
            
            print(f"âœ“ è½¨è¿¹æŸå¤±è®¡ç®—å®Œæˆ - å½¢çŠ¶: {per_trajectory_loss.shape}")
            if len(per_trajectory_losses) <= 10:  # åªæœ‰è½¨è¿¹æ•°è¾ƒå°‘æ—¶æ‰æ˜¾ç¤ºè¯¦ç»†å€¼
                print(f"  æŸå¤±å€¼: {[f'{x.item():.4f}' for x in per_trajectory_loss]}")
            else:
                print(f"  æŸå¤±èŒƒå›´: [{per_trajectory_loss.min().item():.4f}, {per_trajectory_loss.max().item():.4f}]")
            
        except Exception as e:
            print(f"âŒ åˆ†åˆ«è®¡ç®—è½¨è¿¹æŸå¤±æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            # åˆ›å»ºå®‰å…¨çš„é»˜è®¤æŸå¤±
            per_trajectory_loss = torch.zeros(len(episodes), device=device, requires_grad=True)

        # 4. Weight the loss by the advantage
        # advantages tensor shape is (batch_size,)
        print(f"ä¼˜åŠ¿å½¢çŠ¶: {advantages.shape}, å€¼: {advantages}")
        
        try:
            # ç°åœ¨å½¢çŠ¶åº”è¯¥åŒ¹é…äº†ï¼
            if per_trajectory_loss.shape[0] != advantages.shape[0]:
                print(f"âŒ æŸå¤±å’Œä¼˜åŠ¿å½¢çŠ¶ä»ç„¶ä¸åŒ¹é…: {per_trajectory_loss.shape[0]} vs {advantages.shape[0]}")
                print("è¿™ä¸åº”è¯¥å‘ç”Ÿï¼Œä½†ä¸ºäº†å®‰å…¨èµ·è§è¿›è¡Œæˆªæ–­")
                min_size = min(per_trajectory_loss.shape[0], advantages.shape[0])
                per_trajectory_loss = per_trajectory_loss[:min_size]
                advantages = advantages[:min_size]
            else:
                print(f"âœ… æŸå¤±å’Œä¼˜åŠ¿å½¢çŠ¶åŒ¹é…: {per_trajectory_loss.shape[0]} vs {advantages.shape[0]}")
            
            advantages = advantages.to(device)
            weighted_loss = per_trajectory_loss * advantages
            
            # Check for NaN/Inf in weighted loss
            if torch.isnan(weighted_loss).any() or torch.isinf(weighted_loss).any():
                print("âš ï¸ åŠ æƒæŸå¤±äº§ç”ŸNaN/Infå€¼ï¼Œè¿›è¡Œæ¸…ç†")
                weighted_loss = torch.nan_to_num(weighted_loss, nan=0.0, posinf=10.0, neginf=-10.0)
            
            print(f"âœ“ åŠ æƒæŸå¤±: {weighted_loss}")
        
        except Exception as e:
            print(f"âŒ è®¡ç®—åŠ æƒæŸå¤±æ—¶å‡ºé”™: {e}")
            weighted_loss = torch.zeros(len(episodes), device=device, requires_grad=True)

        # 5. Return the mean loss for the batch
        try:
            final_loss = weighted_loss.mean()
            
            # Final NaN/Inf check
            if torch.isnan(final_loss) or torch.isinf(final_loss):
                print("âš ï¸ æœ€ç»ˆæŸå¤±ä¸ºNaN/Infï¼Œä½¿ç”¨é›¶æŸå¤±")
                final_loss = torch.tensor(0.0, device=device, requires_grad=True)
            
            print(f"âœ“ æœ€ç»ˆæŸå¤±: {final_loss.item()}")
            return final_loss
        
        except Exception as e:
            print(f"âŒ è®¡ç®—æœ€ç»ˆæŸå¤±æ—¶å‡ºé”™: {e}")
            return torch.tensor(0.0, device=device, requires_grad=True)
    
    def compute_act_logits(self, model, episodes: List[Dict[str, Any]], device: Optional[torch.device] = None):
        """
        This method is required by the RLModelInterface, but for our CFG-style
        optimizer, we use `compute_weighted_loss` instead.
        We can raise an error or return a placeholder.
        """
        raise NotImplementedError(
            "compute_act_logits is not used for PI0_CFG_Adapter. "
            "Use compute_weighted_loss instead."
        )

    @property
    def device(self):
        return next(self.policy.parameters()).device

    def get_policy_model(self):
        """Return the policy model, which is the PI0Policy instance itself."""
        return self.policy
        
    def _extract_state_from_obs(self, obs, episode_idx, step_idx):
        """ä»è§‚æµ‹ä¸­æå–çŠ¶æ€ä¿¡æ¯å¹¶åº”ç”¨å½’ä¸€åŒ–"""
        try:
            # ğŸ”§ ä¿®å¤ï¼šå¤„ç†SubprocVectorEnvè¿”å›çš„numpy.arrayåŒ…è£…çš„è§‚æµ‹
            if isinstance(obs, np.ndarray) and obs.dtype == object:
                if obs.size == 1:
                    obs = obs.item()  # æå–å•ä¸ªå…ƒç´ 
                elif obs.size > 0:
                    obs = obs[0]  # å–ç¬¬ä¸€ä¸ªå…ƒç´ 
            
            if isinstance(obs, list) and len(obs) > 0:
                obs = obs[0]  # å–ç¬¬ä¸€ä¸ªç¯å¢ƒçš„è§‚æµ‹
            
            if not isinstance(obs, dict) or not obs:
                return np.zeros(7, dtype=np.float32)
            
            # ä¼˜å…ˆä½¿ç”¨ end-effector ä¿¡æ¯
            if "robot0_eef_pos" in obs and "robot0_eef_quat" in obs:
                eef_pos = np.array(obs["robot0_eef_pos"], dtype=np.float32)
                eef_quat = np.array(obs["robot0_eef_quat"], dtype=np.float32)
                
                if eef_pos.size != 3:
                    eef_pos = np.zeros(3, dtype=np.float32)
                if eef_quat.size != 4:
                    eef_quat = np.array([0, 0, 0, 1], dtype=np.float32)
                
                # è½¬æ¢å››å…ƒæ•°ä¸ºè½´è§’
                try:
                    from pi0.ript.utils.pi0_libero_utils import quat2axisangle
                    axis_angle = quat2axisangle(eef_quat).astype(np.float32)
                except Exception:
                    axis_angle = np.zeros(3, dtype=np.float32)
                
                # è·å– gripper çŠ¶æ€
                gripper_qpos = 0.0
                if "robot0_gripper_qpos" in obs:
                    try:
                        gripper_qpos = float(obs["robot0_gripper_qpos"][0])
                    except (IndexError, TypeError, ValueError):
                        gripper_qpos = 0.0
                
                # æ„é€ æœªå½’ä¸€åŒ–çš„çŠ¶æ€ (æŒ‰ç…§åŸå§‹demoçš„æ ¼å¼)
                unnorm_state = np.concatenate([eef_pos[:3], axis_angle[:3], [gripper_qpos]]).astype(np.float32)
                
                # åº”ç”¨å½’ä¸€åŒ–ï¼ˆå°±åƒåŸå§‹demoä¸­çš„åšæ³•ï¼‰
                state = self.normalize_state(unnorm_state)
                
            # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨å…³èŠ‚ä½ç½®
            elif "robot0_joint_pos" in obs:
                joint_pos = np.array(obs["robot0_joint_pos"], dtype=np.float32)
                if joint_pos.size >= 7:
                    unnorm_state = joint_pos[:7]
                else:
                    unnorm_state = np.zeros(7, dtype=np.float32)
                    unnorm_state[:joint_pos.size] = joint_pos
                
                # åº”ç”¨å½’ä¸€åŒ– 
                state = self.normalize_state(unnorm_state)
            else:
                state = np.zeros(7, dtype=np.float32)
            
            # å¤„ç†å¼‚å¸¸å€¼
            state = np.nan_to_num(state, nan=0.0, posinf=1.0, neginf=-1.0)
            return state.astype(np.float32)
            
        except Exception as e:
            print(f"æå–çŠ¶æ€æ—¶å‡ºé”™ (episode {episode_idx}, step {step_idx}): {e}")
            return np.zeros(7, dtype=np.float32)
    
    def _extract_image_from_obs(self, obs, episode_idx, step_idx):
        """ä»è§‚æµ‹ä¸­æå–å›¾åƒä¿¡æ¯"""
        try:
            # ğŸ”§ ä¿®å¤ï¼šå¤„ç†SubprocVectorEnvè¿”å›çš„numpy.arrayåŒ…è£…çš„è§‚æµ‹
            if isinstance(obs, np.ndarray) and obs.dtype == object:
                if obs.size == 1:
                    obs = obs.item()  # æå–å•ä¸ªå…ƒç´ 
                elif obs.size > 0:
                    obs = obs[0]  # å–ç¬¬ä¸€ä¸ªå…ƒç´ 
            
            if isinstance(obs, list) and len(obs) > 0:
                obs = obs[0]  # å–ç¬¬ä¸€ä¸ªç¯å¢ƒçš„è§‚æµ‹
            
            if isinstance(obs, dict) and "agentview_image" in obs:
                img = obs["agentview_image"]
                if isinstance(img, np.ndarray) and img.size > 0:
                    # ğŸ”§ ä¿®å¤å›¾åƒæ ¼å¼æ£€æŸ¥ï¼šå¤„ç†CHWå’ŒHWCä¸¤ç§æ ¼å¼
                    if img.ndim == 3:
                        # æ£€æŸ¥æ˜¯CHWæ ¼å¼ (3, H, W) è¿˜æ˜¯HWCæ ¼å¼ (H, W, 3)
                        if img.shape[0] == 3 and img.shape[-1] != 3:  # CHWæ ¼å¼
                            # è½¬æ¢CHW â†’ HWC
                            img = img.transpose(1, 2, 0)
                        elif img.shape[-1] != 3:  # æ—¢ä¸æ˜¯CHWä¹Ÿä¸æ˜¯HWC
                            print(f"âœ— æœªçŸ¥å›¾åƒæ ¼å¼: {img.shape}")
                            raise ValueError(f"Unexpected image format: {img.shape}")
                        
                        # ç°åœ¨imgåº”è¯¥æ˜¯HWCæ ¼å¼
                        # é™é»˜å¤„ç†å›¾åƒï¼ˆå‡å°‘å†—ä½™æ—¥å¿—ï¼‰
                        
                        # ä¸ºæ¨¡å‹æ¨ç†å‡†å¤‡å›¾åƒï¼ˆç¡®ä¿æ¥æ”¶æ­£ç¡®æ–¹å‘çš„å›¾åƒï¼‰
                        # æ ¹æ®æ‚¨çš„éœ€æ±‚ï¼Œç¡®ä¿æ¨¡å‹æ¥æ”¶çš„æ˜¯æ­£ç€çš„å›¾åƒ
                        model_img = img.copy()  # ç›´æ¥ä½¿ç”¨åŸå§‹å›¾åƒï¼Œä¸è¿›è¡Œæ—‹è½¬
                        
                        # æ”¶é›†å›¾åƒç”¨äºè§†é¢‘ç”Ÿæˆï¼ˆéœ€è¦æ—‹è½¬ä»¥æ˜¾ç¤ºæ­£ç¡®æ–¹å‘ï¼‰
                        video_img = img[::-1, ::-1]  # 180åº¦æ—‹è½¬ç”¨äºè§†é¢‘æ˜¾ç¤º
                        self._collect_image_for_video(video_img, episode_idx, step_idx)
                        
                        # è¿”å›ç”¨äºæ¨¡å‹æ¨ç†çš„å›¾åƒï¼ˆå·²è¿›è¡Œ180åº¦æ—‹è½¬ï¼‰
                        # å¦‚æœå›¾åƒå°ºå¯¸ä¸æ˜¯ 224x224ï¼Œéœ€è¦è°ƒæ•´å¤§å°
                        if model_img.shape[:2] != (224, 224):
                            try:
                                from skimage.transform import resize
                                model_img = resize(model_img, (224, 224), preserve_range=True).astype(np.uint8)
                            except ImportError:
                                # å¦‚æœæ²¡æœ‰ skimageï¼Œä½¿ç”¨ç®€å•çš„æ’å€¼
                                import cv2
                                model_img = cv2.resize(model_img, (224, 224))
                        return model_img
                    else:
                        print(f"âœ— å›¾åƒç»´åº¦å¼‚å¸¸: {img.shape}")
                else:
                    print(f"âœ— å›¾åƒæ•°æ®æ— æ•ˆ: type={type(img)}, size={getattr(img, 'size', 'N/A')}")
            else:
                available_keys = list(obs.keys()) if isinstance(obs, dict) else "éå­—å…¸ç±»å‹"
                print(f"âœ— è§‚æµ‹ä¸­æ— agentview_imageé”®, å¯ç”¨é”®: {available_keys}")
            
            # å¦‚æœæ²¡æœ‰æœ‰æ•ˆå›¾åƒï¼Œè¿”å›å ä½ç¬¦
            print(f"âœ— ä½¿ç”¨å ä½ç¬¦å›¾åƒ (episode {episode_idx}, step {step_idx})")
            return np.ones((224, 224, 3), dtype=np.uint8) * 128
            
        except Exception as e:
            print(f"æå–å›¾åƒæ—¶å‡ºé”™ (episode {episode_idx}, step {step_idx}): {e}")
            return np.ones((224, 224, 3), dtype=np.uint8) * 128

    def _collect_image_for_video(self, img, episode_idx, step_idx):
        """æ”¶é›†å›¾åƒç”¨äºè§†é¢‘ç”Ÿæˆ"""
        if not self.video_save_enabled:
            return
            
        try:
            if episode_idx not in self.video_frames:
                self.video_frames[episode_idx] = []
            
            # ä¿å­˜åŸå§‹æ–¹å‘çš„å›¾åƒç”¨äºè§†é¢‘
            self.video_frames[episode_idx].append(img.copy())
            
        except Exception as e:
            print(f"æ”¶é›†è§†é¢‘å¸§æ—¶å‡ºé”™: {e}")

    def finalize_episode_video(self, episode_idx, task_description="default_task"):
        """å®Œæˆepisodeæ—¶ç”Ÿæˆè§†é¢‘"""
        if not self.video_save_enabled or episode_idx not in self.video_frames:
            return None
            
        frames = self.video_frames[episode_idx]
        if len(frames) > 0:
            video_path = self._generate_episode_video(frames, episode_idx, task_description)
            # æ¸…ç†å·²ä½¿ç”¨çš„å¸§
            del self.video_frames[episode_idx]
            return video_path
        return None

    def _generate_episode_video(self, episode_images, episode_idx, task_description):
        """ä»episodeå›¾åƒç”Ÿæˆè§†é¢‘"""
        try:
            import os
            import imageio
            from datetime import datetime
            
            # åˆ›å»ºè§†é¢‘ä¿å­˜ç›®å½•
            debug_dir = os.path.join(os.getcwd(), "ript", "debug_images")
            video_dir = os.path.join(debug_dir, "videos")
            os.makedirs(video_dir, exist_ok=True)
            
            # ç”Ÿæˆè§†é¢‘æ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            task_str = str(task_description).replace(" ", "_").replace("/", "_")[:30]
            video_path = os.path.join(video_dir, f"episode_{episode_idx}_{timestamp}_{task_str}.mp4")
            
            # ç¡®ä¿æ‰€æœ‰å›¾åƒå°ºå¯¸ä¸€è‡´
            processed_images = []
            for img in episode_images:
                if isinstance(img, np.ndarray) and img.size > 0:
                    if img.ndim == 3 and img.shape[-1] == 3:
                        # è°ƒæ•´åˆ°ç»Ÿä¸€å°ºå¯¸
                        if img.shape[:2] != (224, 224):
                            try:
                                from skimage.transform import resize
                                img = resize(img, (224, 224), preserve_range=True).astype(np.uint8)
                            except ImportError:
                                import cv2
                                img = cv2.resize(img, (224, 224))
                        
                        # å›¾åƒå·²ç»åœ¨pi0_libero_utils.pyä¸­å¤„ç†è¿‡180åº¦æ—‹è½¬
                        # ä½†æ˜¯ä¸ºäº†è§†é¢‘æ˜¾ç¤ºæ­£ç¡®ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨åŸå§‹æ–¹å‘çš„å›¾åƒ
                        processed_images.append(img)  # ä½¿ç”¨åŸå§‹æ–¹å‘çš„å›¾åƒ
            
            if len(processed_images) >= 5:  # è‡³å°‘5å¸§æ‰ç”Ÿæˆè§†é¢‘
                # ä¿å­˜è§†é¢‘
                imageio.mimsave(video_path, processed_images, fps=10)
                print(f"âœ“ Episodeè§†é¢‘å·²ç”Ÿæˆ: {video_path} ({len(processed_images)} å¸§)")
                return video_path
            else:
                print(f"âš ï¸ Episode {episode_idx} å›¾åƒæ•°é‡ä¸è¶³ï¼Œè·³è¿‡è§†é¢‘ç”Ÿæˆ ({len(processed_images)} å¸§)")
                return None
                
        except Exception as e:
            print(f"ç”Ÿæˆepisodeè§†é¢‘æ—¶å‡ºé”™: {e}")
            return None