"""
Train PI0 policy using RIPT.
ä½¿ç”¨ç®€åŒ–çš„ç›´æ¥å¯¼å…¥ç³»ç»Ÿ

ä½¿ç”¨æ–¹æ³•:
    cd /zhaohan/ZJH/openpi_pytorch
    python pi0/ript/scripts/train_ript_pi0.py --config_path pi0/ript/config/train_pi0_cfg_rl.yaml
"""

#!/usr/bin/env python3

# === è·¯å¾„åˆå§‹åŒ– (å¿…é¡»åœ¨å…¶ä»–å¯¼å…¥ä¹‹å‰) ===
import os
import sys
from pathlib import Path

# è®¾ç½®NCCLè¶…æ—¶æ—¶é—´
os.environ["NCCL_TIMEOUT"] = "108000"

# è°ƒè¯•ç›¸å…³é…ç½®
DEBUG_SAVE_IMAGES = True  # é»˜è®¤å¼€å¯ä¿å­˜å›¾åƒ
DEBUG_SAVE_VIDEO = True   # é»˜è®¤å¼€å¯ä¿å­˜è§†é¢‘
DEBUG_IMAGE_DIR = "pi0/ript/debug_images"  # è°ƒè¯•å›¾åƒä¿å­˜ç›®å½•

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
current_file = Path(__file__).resolve()
project_root = current_file.parents[3]  # ä¸Š3çº§åˆ°openpi_pytorchç›®å½•
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

print("=== PI0 + RIPT è®­ç»ƒè„šæœ¬ ===")
print(f"è„šæœ¬ä½ç½®: {current_file}")
print(f"é¡¹ç›®æ ¹ç›®å½•: {project_root}")
print()

# ç›´æ¥å¯¼å…¥å¿…è¦æ¨¡å—
try:
    print("æ­£åœ¨å¯¼å…¥å¿…è¦æ¨¡å—...")
    
    # PI0 ç­–ç•¥
    from pi0.modeling_pi0 import PI0Policy
    
    # RIPT ç»„ä»¶
    from pi0.ript.reward_function import BinarySuccessReward
    from pi0.ript.algos.rl_optimizers.rl_optimizer_pi0_cfg import RLOptimizerPI0_CFG
    from pi0.ript.algos.rl_optimizers.pi0_cfg_interface import PI0_CFG_Adapter
    from pi0.ript.algos.rl_optimizers.rollout_generator import RolloutGenerator
    
    # ğŸš€ æ™ºèƒ½Runnerå¯¼å…¥ - æ”¯æŒRIPT-VLAæ¨¡å¼
    def import_runner_classes():
        """æ™ºèƒ½å¯¼å…¥runnerç±»"""
        try:
            # å¯¼å…¥åŸæœ‰runner
            from pi0.ript.env.pi0_libero_runner import LIBEROEnvRunner
            print("âœ… åŸæœ‰LIBEROEnvRunnerå¯¼å…¥æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸ åŸæœ‰runnerå¯¼å…¥å¤±è´¥: {e}")
            LIBEROEnvRunner = None
            
        try:
            # å¯¼å…¥æ–°çš„RIPT-VLA runner
            from pi0.ript.env.pi0_libero_runner_ript_vla import PI0LiberoRunner as RiptVlaRunner
            print("âœ… RIPT-VLA Runnerå¯¼å…¥æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸ RIPT-VLA runnerå¯¼å…¥å¤±è´¥: {e}")
            RiptVlaRunner = None
            
        return LIBEROEnvRunner, RiptVlaRunner
    
    # æ‰§è¡Œå¯¼å…¥
    OriginalRunner, RiptVlaRunner = import_runner_classes()
    
    # ğŸš€ Runneré€‰æ‹©å‡½æ•°
    def create_env_runner(config, policy, rank=0, world_size=1):
        """æ ¹æ®é…ç½®é€‰æ‹©åˆé€‚çš„ç¯å¢ƒrunner"""
        
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨RIPT-VLA runner
        use_ript_vla = False
        # ä¿®å¤ï¼šç›´æ¥ä½¿ç”¨config.get()è€Œä¸æ˜¯hasattrï¼Œå› ä¸ºOmegaConfçš„ç‰¹æ®Šè¡Œä¸º
        features = config.get('features', {})
        if features:
            use_ript_vla = features.get('use_ript_vla_runner', False)
        
        # è°ƒè¯•ä¿¡æ¯
        print(f"ğŸ” è°ƒè¯•ä¿¡æ¯:")
        print(f"   hasattr(config, 'features'): {hasattr(config, 'features')}")
        print(f"   config['features']: {config.get('features', 'NOT_FOUND')}")
        print(f"   RiptVlaRunner is not None: {RiptVlaRunner is not None}")
        print(f"ğŸ” Runneré€‰æ‹©: use_ript_vla_runner = {use_ript_vla}")
        
        if use_ript_vla and RiptVlaRunner is not None:
            print("ğŸš€ ä½¿ç”¨RIPT-VLAé£æ ¼çš„ç¯å¢ƒrunner")
            return RiptVlaRunner(
                policy=policy,
                benchmark_name=config['task']['benchmark_name'],
                rollouts_per_env=config['algo']['rloo_batch_size'],
                num_parallel_envs=config['task']['num_parallel_envs'],
                max_episode_length=config['task']['max_episode_length'],
                task_names_to_use=config['task'].get('task_names_to_use', []),
                rank=rank
            )
        elif OriginalRunner is not None:
            print("ğŸ”„ ä½¿ç”¨åŸæœ‰çš„ç¯å¢ƒrunner")
            # æ„å»ºä¸åŸæœ‰è°ƒç”¨å…¼å®¹çš„å‚æ•°
            norm_stats_path = config.get('norm_stats_path', None)
            local_tasks = config['task'].get('task_names_to_use', [])
            
            return OriginalRunner(
                policy=policy,
                benchmark_name=config['task']['benchmark_name'],
                rollouts_per_env=config['algo']['rloo_batch_size'],
                num_parallel_envs=config['task']['num_parallel_envs'],
                max_episode_length=config['task']['max_episode_length'],
                task_names_to_use=local_tasks,
                norm_stats_path=norm_stats_path,
                config=config,
                rank=rank,
                world_size=world_size,
            )
        else:
            raise RuntimeError("âŒ æ— å¯ç”¨çš„ç¯å¢ƒrunnerï¼è¯·æ£€æŸ¥å¯¼å…¥ã€‚")
    
    # LIBERO benchmark (éœ€è¦æ‰‹åŠ¨å®ç°ä¸€ä¸ªç®€å•çš„æ¥å£)
    try:
        from libero.libero.benchmark import get_benchmark_dict
        benchmark = get_benchmark_dict()
    except ImportError:
        print("è­¦å‘Š: LIBEROæœªå®‰è£…ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿbenchmark")
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„æ¨¡æ‹Ÿbenchmark
        class MockBenchmark:
            def get_task_names(self):
                return ["KITCHEN_SCENE1_put_the_black_bowl_on_the_plate"]
            def get_task_init_states(self, task_id):
                return [{"state": i} for i in range(10)]
        
        benchmark = {"libero_spatial": lambda: MockBenchmark()}
    
    print("âœ“ æ‰€æœ‰æ¨¡å—å¯¼å…¥æˆåŠŸ")
    
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

# æ ‡å‡†åº“å¯¼å…¥
import argparse
import torch
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP
from torch.utils.data import DataLoader, Dataset
from torch.utils.data.distributed import DistributedSampler
import numpy as np
import wandb
import yaml
import time
import json
from datetime import datetime
from torch.cuda.amp import GradScaler, autocast
import gc
import psutil
import threading
import signal
from typing import Optional
import io
import atexit
from functools import partial
from tqdm.auto import tqdm
#
# === Logging + Stdout Tee Utilities =========================================================
class _TeeIO(io.TextIOBase):
    """
    Tee stdout/stderr to one or more underlying text streams (console + log file).
    We open the log file in line-buffered mode so updates flush immediately.
    """
    def __init__(self, *streams):
        self._streams = tuple(s for s in streams if s is not None)

    def write(self, data):
        for s in self._streams:
            try:
                s.write(data)
                s.flush()
            except Exception:
                pass
        return len(data)

    def flush(self):
        for s in self._streams:
            try:
                s.flush()
            except Exception:
                pass

def setup_run_logging(output_dir: str, rank: int):
    """
    Create per-rank log file and tee sys.stdout/sys.stderr so *all* prints end up in the log.

    Returns: opened file handle (caller must NOT close; we register an atexit hook).
    """
    os.makedirs(output_dir, exist_ok=True)
    log_path = Path(output_dir) / f"train_rank{rank}.log"
    log_fh = open(log_path, mode="a", buffering=1, encoding="utf-8")  # line-buffered
    # Wrap existing stdout/stderr
    sys.stdout = _TeeIO(sys.stdout, log_fh)
    sys.stderr = _TeeIO(sys.stderr, log_fh)

    def _close_log():
        try:
            if hasattr(log_fh, 'closed') and not log_fh.closed:
                log_fh.flush()
                log_fh.close()
        except Exception as e:
            print(f"æ—¥å¿—æ–‡ä»¶å…³é—­è­¦å‘Š: {e}")
    
    # ç¦ç”¨è‡ªåŠ¨atexitæ³¨å†Œï¼Œæ”¹ä¸ºæ‰‹åŠ¨ç®¡ç†
    # atexit.register(_close_log)
    
    # å°†closeå‡½æ•°é™„åŠ åˆ°æ–‡ä»¶å¥æŸ„ï¼Œä¾¿äºæ‰‹åŠ¨è°ƒç”¨
    log_fh._manual_close = _close_log
    
    return log_fh

# === Action Progress Bar ====================================================================
class ActionProgressBar:
    """
    Lightweight textual progress indicator for action *chunks* generated by the policy.
    Each callback invocation == 1 chunk update.

    total_steps: intended maximum chunks per rollout episode (use max_episode_length).
    rank: only rank==0 renders a visible tqdm bar; others stay quiet but still count.
    """
    def __init__(self, total_steps: int, rank: int = 0, desc: str = "ActionGen"):
        self.total_steps = max(1, int(total_steps)) if total_steps is not None else None
        self.rank = rank
        self.count = 0
        self._bar = None
        if self.rank == 0:
            try:
                # dynamic_ncols adapts width; leave=False so it resets each episode
                self._bar = tqdm(total=self.total_steps, desc=desc, leave=False, dynamic_ncols=True)
            except Exception:
                self._bar = None

    def reset(self):
        self.count = 0
        if self._bar is not None:
            try:
                self._bar.reset(total=self.total_steps)
            except Exception:
                pass

    def update(self, actions_chunk=None):
        """
        Called each time the wrapped policy emits a new action chunk.
        We don't log the raw action tensor; we just tick progress.
        """
        self.count += 1
        if self._bar is not None:
            try:
                # If total unknown we set total on first call to something large; else clamp
                if self.total_steps is not None:
                    self._bar.update(1)
                    if self.count >= self.total_steps:
                        # auto refresh & newline
                        self._bar.refresh()
                else:
                    # fallback textual print
                    self._bar.write(f"[ActionChunk {self.count}]")
            except Exception:
                pass
        # ä»…å½“ tqdm è¿›åº¦æ¡ä¸å¯ç”¨æ—¶, æ‰å›é€€åˆ°æ§åˆ¶å°æ‰“å°, å¹¶ä½¿ç”¨å›è½¦è¦†å†™åŒä¸€è¡Œé¿å…åˆ·å±ã€‚
        if self._bar is None:
            print(f"[Rank{self.rank}] Action chunk #{self.count}\r", end="", flush=True)

# æ·»åŠ å›¾åƒä¿å­˜ç›¸å…³å¯¼å…¥
import os
import imageio
import matplotlib.pyplot as plt
from PIL import Image
from datetime import datetime


class LiberoInitStateDataset(Dataset):
    """A PyTorch Dataset to handle initial states from a Libero benchmark."""
    def __init__(self, benchmark_name, task_names_to_use, split='train'):
        self.benchmark_name = benchmark_name.lower()
        # ä¸åœ¨åˆå§‹åŒ–æ—¶åˆ›å»ºbenchmarkå¯¹è±¡ï¼Œè€Œæ˜¯åœ¨éœ€è¦æ—¶åˆ›å»º
        # å­˜å‚¨æ‰€æœ‰éœ€è¦çš„ä¿¡æ¯ï¼Œè€Œä¸æ˜¯å­˜å‚¨å¯¹è±¡å¼•ç”¨
        benchmark_obj = benchmark[self.benchmark_name]()
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šä»»åŠ¡åç§°ï¼Œåˆ™ä½¿ç”¨æ‰€æœ‰ä»»åŠ¡
        if not task_names_to_use:
            task_names_to_use = benchmark_obj.get_task_names()
        
        self.task_names = task_names_to_use
        
        # é¢„å…ˆåŠ è½½æ‰€æœ‰åˆå§‹çŠ¶æ€ï¼Œé¿å…åœ¨workerä¸­é‡æ–°åŠ è½½
        all_init_states_list = []
        self.task_init_states = {}  # å­˜å‚¨æ¯ä¸ªä»»åŠ¡çš„åˆå§‹çŠ¶æ€ï¼Œç”¨äºä»»åŠ¡åˆ†é…
        
        for task_name in self.task_names:
            try:
                task_id = benchmark_obj.get_task_names().index(task_name)
                # è·å–å•ä¸ªä»»åŠ¡çš„åˆå§‹çŠ¶æ€
                task_init_states = benchmark_obj.get_task_init_states(task_id)
                all_init_states_list.append(task_init_states)
                self.task_init_states[task_name] = task_init_states
            except ValueError:
                # å¤„ç†é…ç½®ä¸­çš„ä»»åŠ¡åç§°å¯èƒ½ä¸åœ¨åŸºå‡†ä¸­çš„æƒ…å†µ
                print(f"Warning: Task '{task_name}' not found in benchmark '{benchmark_name}'. Skipping.")

        if not all_init_states_list:
             raise ValueError(f"No valid initial states found for tasks {self.task_names} in benchmark {benchmark_name}.")

        # ---- ä¿®æ”¹ ----
        # ä¸å†æ‹¼æ¥æˆäºŒç»´çŸ©é˜µï¼Œæ”¹ä¸ºæ‰å¹³ listï¼Œæ”¯æŒä¸åŒä»»åŠ¡ä¸åŒç»´åº¦
        from itertools import chain
        self.flat_states = list(chain.from_iterable(all_init_states_list))  # List[np.ndarray]

        # å‘åå…¼å®¹: ä¿ç•™æ—§å±æ€§åï¼ŒæŒ‡å‘ç›¸åŒåˆ—è¡¨ï¼Œé˜²æ­¢å…¶ä»–æ¨¡å—å¼•ç”¨ self.init_states æŠ¥é”™
        self.init_states = self.flat_states
        
        # å»ºç«‹ç´¢å¼• -> ä»»åŠ¡åæ˜ å°„ï¼ˆä¾›ä»»åŠ¡åˆ†é…æˆ–è°ƒè¯•ï¼‰
        self.init_state_to_task = []
        for task_name, states in self.task_init_states.items():
            self.init_state_to_task.extend([task_name] * len(states))
    
    # æ·»åŠ åºåˆ—åŒ–æ”¯æŒ
    def __getstate__(self):
        # è¿”å›éœ€è¦åºåˆ—åŒ–çš„çŠ¶æ€
        return {
            'benchmark_name': self.benchmark_name,
            'task_names': self.task_names,
            'flat_states': self.flat_states,
            'task_init_states': self.task_init_states,
            'init_state_to_task': self.init_state_to_task
        }
    
    def __setstate__(self, state):
        # ä»åºåˆ—åŒ–çŠ¶æ€æ¢å¤
        self.benchmark_name = state['benchmark_name']
        self.task_names = state['task_names']
        # æ¢å¤ flat_states ä¸å…¼å®¹åˆ«å
        self.flat_states = state['flat_states']
        self.init_states = self.flat_states
        self.task_init_states = state['task_init_states']
        self.init_state_to_task = state['init_state_to_task']

    def __len__(self):
        return len(self.flat_states)

    def __getitem__(self, idx):
        return self.flat_states[idx]
    
    def get_task_names(self):
        return self.task_names
    
    def get_task_init_states(self, task_name, num_states=None):
        """è·å–æŒ‡å®šä»»åŠ¡çš„åˆå§‹çŠ¶æ€"""
        if task_name not in self.task_init_states:
            raise ValueError(f"Task '{task_name}' not found in dataset")
        
        states = self.task_init_states[task_name]
        if num_states is not None:
            # å¦‚æœè¯·æ±‚çš„çŠ¶æ€æ•°é‡è¶…è¿‡å¯ç”¨æ•°é‡ï¼Œåˆ™å¾ªç¯ä½¿ç”¨
            indices = np.arange(num_states) % len(states)
            return states[indices]
        return states


def get_memory_usage():
    """è·å–å½“å‰å†…å­˜ä½¿ç”¨æƒ…å†µ"""
    if torch.cuda.is_available():
        gpu_memory = torch.cuda.memory_allocated() / 1024**3  # GB
        gpu_memory_cached = torch.cuda.memory_reserved() / 1024**3  # GB
        cpu_memory = psutil.virtual_memory().percent
        return {
            'gpu_memory_allocated_gb': gpu_memory,
            'gpu_memory_cached_gb': gpu_memory_cached,
            'cpu_memory_percent': cpu_memory
        }
    else:
        cpu_memory = psutil.virtual_memory().percent
        return {'cpu_memory_percent': cpu_memory}

def clear_gpu_memory():
    """æ¸…ç†GPUå†…å­˜"""
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        gc.collect()

def memory_cleanup_thread(stop_event, cleanup_interval=30):
    """åå°å†…å­˜æ¸…ç†çº¿ç¨‹"""
    while not stop_event.is_set():
        if stop_event.wait(cleanup_interval):
            break
        clear_gpu_memory()

def get_model_from_ddp(ddp_model):
    """ä»DDPæ¨¡å‹ä¸­è·å–åŸå§‹æ¨¡å‹ï¼Œå…¼å®¹å•GPUæ¨¡å¼"""
    if hasattr(ddp_model, 'module'):
        return ddp_model.module
    else:
        return ddp_model

def setup_distributed():
    """è®¾ç½®åˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒï¼Œæ”¯æŒå•GPUæ¨¡å¼"""
    # æ£€æŸ¥æ˜¯å¦åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸­
    rank_env = os.environ.get("RANK")
    world_size_env = os.environ.get("WORLD_SIZE")
    local_rank_env = os.environ.get("LOCAL_RANK")
    
    # å¦‚æœæ²¡æœ‰è®¾ç½®åˆ†å¸ƒå¼ç¯å¢ƒå˜é‡ï¼Œåˆ™ä½¿ç”¨å•GPUæ¨¡å¼
    if rank_env is None or world_size_env is None:
        print("æœªæ£€æµ‹åˆ°åˆ†å¸ƒå¼ç¯å¢ƒå˜é‡ï¼Œä½¿ç”¨å•GPUæ¨¡å¼")
        local_rank = 0
        global_rank = 0
        world_size = 1
        
        # è®¾ç½®è®¾å¤‡
        if torch.cuda.is_available():
            device = torch.device("cuda:0")
            torch.cuda.set_device(0)
            print(f"ä½¿ç”¨è®¾å¤‡: {device}")
        else:
            device = torch.device("cpu")
            print("è­¦å‘Šï¼šæœªæ£€æµ‹åˆ°CUDAè®¾å¤‡ï¼Œå°†ä½¿ç”¨CPUè¿›è¡Œè®­ç»ƒ")
        
        # è®¾ç½®éšæœºç§å­
        base_seed = 42
        torch.manual_seed(base_seed)
        np.random.seed(base_seed)
        
        return local_rank, global_rank, world_size, device
    
    # åˆ†å¸ƒå¼æ¨¡å¼
    print("æ£€æµ‹åˆ°åˆ†å¸ƒå¼ç¯å¢ƒå˜é‡ï¼Œä½¿ç”¨åˆ†å¸ƒå¼è®­ç»ƒæ¨¡å¼")
    
    # è®¾ç½®NCCLè¶…æ—¶
    os.environ["NCCL_TIMEOUT"] = "108000"
    
    # è·å–æœ¬åœ°æ’å
    local_rank = int(local_rank_env)
    
    # è®¾ç½®å½“å‰è®¾å¤‡
    if torch.cuda.is_available():
        torch.cuda.set_device(local_rank)
        device = torch.device(f"cuda:{local_rank}")
    else:
        device = torch.device("cpu")
        print("è­¦å‘Šï¼šæœªæ£€æµ‹åˆ°CUDAè®¾å¤‡ï¼Œå°†ä½¿ç”¨CPUè¿›è¡Œè®­ç»ƒ")
    
    # åˆå§‹åŒ–è¿›ç¨‹ç»„ï¼Œæ·»åŠ è¶…æ—¶è®¾ç½®ä»¥é˜²æ­¢æ­»é”
    init_params = {
        "backend": "nccl" if torch.cuda.is_available() else "gloo",
        "timeout": torch.distributed.default_pg_timeout if hasattr(torch.distributed, 'default_pg_timeout') else None
    }
    
    # ç§»é™¤Noneå€¼ä»¥é¿å…å‚æ•°é”™è¯¯
    init_params = {k: v for k, v in init_params.items() if v is not None}
    
    try:
        dist.init_process_group(**init_params)
    except Exception as e:
        print(f"åˆ†å¸ƒå¼åˆå§‹åŒ–å¤±è´¥: {e}")
        print("å°è¯•ä½¿ç”¨glooåç«¯...")
        dist.init_process_group(backend="gloo")
    
    # è·å–å…¨å±€æ’åå’Œä¸–ç•Œå¤§å°
    global_rank = dist.get_rank()
    world_size = dist.get_world_size()
    
    # è®¾ç½®éšæœºç§å­ï¼Œç¡®ä¿æ¯ä¸ªè¿›ç¨‹ä½¿ç”¨ä¸åŒçš„ç§å­
    base_seed = 42
    torch.manual_seed(base_seed + global_rank)
    np.random.seed(base_seed + global_rank)
    
    return local_rank, global_rank, world_size, device

def save_checkpoint(policy, optimizer, step, config, filename, is_best=False, async_save=True):
    """ä¿å­˜æ£€æŸ¥ç‚¹ï¼ŒåŒ…æ‹¬æ¨¡å‹ã€ä¼˜åŒ–å™¨çŠ¶æ€å’Œè®­ç»ƒé…ç½®"""
    def _save_checkpoint_data():
        # åˆ›å»ºæ£€æŸ¥ç‚¹æ•°æ®
        checkpoint = {
            'model_state_dict': policy.state_dict(),
            'optimizer_state_dict': optimizer.state_dict() if optimizer else None,
            'step': step,
            'config': config,
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(filename), exist_ok=True)
        
        # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶ç¡®ä¿åŸå­æ€§å†™å…¥
        temp_filename = filename + ".tmp"
        torch.save(checkpoint, temp_filename)
        os.rename(temp_filename, filename)
        
        # å¦‚æœæ˜¯æœ€ä½³æ¨¡å‹ï¼Œåˆ›å»ºä¸€ä¸ªå‰¯æœ¬
        if is_best:
            best_filename = os.path.join(os.path.dirname(filename), "best_model.pth")
            temp_best_filename = best_filename + ".tmp"
            torch.save(checkpoint, temp_best_filename)
            os.rename(temp_best_filename, best_filename)
        
        # æ¸…ç†å†…å­˜
        del checkpoint
        clear_gpu_memory()
        
        print(f"æ£€æŸ¥ç‚¹å·²ä¿å­˜åˆ° {filename}")
    
    if async_save:
        # å¼‚æ­¥ä¿å­˜ä»¥é¿å…é˜»å¡è®­ç»ƒ
        save_thread = threading.Thread(target=_save_checkpoint_data)
        save_thread.daemon = True
        save_thread.start()
    else:
        _save_checkpoint_data()

def load_checkpoint(policy, optimizer, filename):
    """åŠ è½½æ£€æŸ¥ç‚¹ï¼Œæ¢å¤æ¨¡å‹ã€ä¼˜åŒ–å™¨çŠ¶æ€å’Œè®­ç»ƒé…ç½®"""
    if not os.path.exists(filename):
        print(f"æ£€æŸ¥ç‚¹æ–‡ä»¶ {filename} æœªæ‰¾åˆ°ã€‚ä»å¤´å¼€å§‹è®­ç»ƒã€‚")
        return 0
    
    # åŠ è½½æ£€æŸ¥ç‚¹
    checkpoint = torch.load(filename, map_location=lambda storage, loc: storage)
    
    # æ¢å¤æ¨¡å‹çŠ¶æ€
    policy.load_state_dict(checkpoint['model_state_dict'])
    
    # å¦‚æœæä¾›äº†ä¼˜åŒ–å™¨ä¸”æ£€æŸ¥ç‚¹ä¸­æœ‰ä¼˜åŒ–å™¨çŠ¶æ€ï¼Œåˆ™æ¢å¤ä¼˜åŒ–å™¨çŠ¶æ€
    if optimizer is not None and 'optimizer_state_dict' in checkpoint and checkpoint['optimizer_state_dict'] is not None:
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
    
    # è·å–è®­ç»ƒæ­¥éª¤
    step = checkpoint.get('step', 0)
    
    print(f"å·²ä» {filename} åŠ è½½æ£€æŸ¥ç‚¹ (æ­¥éª¤ {step})")
    return step

def get_optimizer(model, config):
    """æ ¹æ®é…ç½®åˆ›å»ºä¼˜åŒ–å™¨"""
    optimizer_config = config['training'].get('optimizer', {})
    optimizer_type = optimizer_config.get('type', 'Adam')
    # ç¡®ä¿å­¦ä¹ ç‡æ˜¯æµ®ç‚¹æ•°
    lr = float(config['algo']['lr'])
    
    if optimizer_type == 'Adam':
        beta1 = float(optimizer_config.get('beta1', 0.9))
        beta2 = float(optimizer_config.get('beta2', 0.999))
        weight_decay = float(optimizer_config.get('weight_decay', 0.0))
        return torch.optim.Adam(
            model.parameters(), 
            lr=lr, 
            betas=(beta1, beta2), 
            weight_decay=weight_decay
        )
    elif optimizer_type == 'AdamW':
        beta1 = float(optimizer_config.get('beta1', 0.9))
        beta2 = float(optimizer_config.get('beta2', 0.999))
        weight_decay = float(optimizer_config.get('weight_decay', 0.01))
        return torch.optim.AdamW(
            model.parameters(), 
            lr=lr, 
            betas=(beta1, beta2), 
            weight_decay=weight_decay
        )
    elif optimizer_type == 'SGD':
        momentum = float(optimizer_config.get('momentum', 0.9))
        weight_decay = float(optimizer_config.get('weight_decay', 0.0))
        return torch.optim.SGD(
            model.parameters(), 
            lr=lr, 
            momentum=momentum, 
            weight_decay=weight_decay
        )
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„ä¼˜åŒ–å™¨ç±»å‹: {optimizer_type}")

def distribute_tasks(all_tasks, world_size, rank):
    """å°†ä»»åŠ¡åˆ†é…ç»™ä¸åŒçš„GPU"""
    rank_to_tasks = {rank_i: [] for rank_i in range(world_size)}
    for task_i, task_name in enumerate(all_tasks):
        rank_to_tasks[task_i % world_size].append(task_name)
    return rank_to_tasks[rank]

# ========= ç³»ç»Ÿæ¸…ç†å‡½æ•° =========

def cleanup_opengl_context():
    """ç®€åŒ–çš„OpenGL/EGLä¸Šä¸‹æ–‡æ¸…ç†ï¼Œé¿å…SIGABRTå´©æºƒ"""
    try:
        # ç®€åŒ–çš„OpenGLæ¸…ç†ï¼Œåªåšæœ€åŸºæœ¬çš„æ“ä½œ
        try:
            import OpenGL.GL as gl
            gl.glFinish()  # å®Œæˆæ‰€æœ‰OpenGLæ“ä½œ
        except ImportError:
            pass  # OpenGLæœªå®‰è£…ï¼Œè·³è¿‡
        except Exception:
            pass  # å¿½ç•¥OpenGLæ¸…ç†é”™è¯¯
            
        # ç®€åŒ–çš„EGLæ¸…ç†ï¼Œç§»é™¤å¯èƒ½å¼•èµ·é—®é¢˜çš„æ­¥éª¤
        try:
            import OpenGL.EGL as egl
            
            # è·å–å½“å‰ä¸Šä¸‹æ–‡
            current_context = egl.eglGetCurrentContext()
            current_display = egl.eglGetCurrentDisplay()
            
            # åªåœ¨ç¡®å®æœ‰æ´»åŠ¨ä¸Šä¸‹æ–‡æ—¶æ‰å°è¯•è§£ç»‘
            if (current_context != egl.EGL_NO_CONTEXT and 
                current_display != egl.EGL_NO_DISPLAY):
                try:
                    egl.eglMakeCurrent(
                        current_display, 
                        egl.EGL_NO_SURFACE, 
                        egl.EGL_NO_SURFACE, 
                        egl.EGL_NO_CONTEXT
                    )
                except Exception:
                    pass  # å¿½ç•¥è§£ç»‘é”™è¯¯ï¼Œè¿™äº›åœ¨shutdownæ—¶æ˜¯å¸¸è§çš„
                        
        except ImportError:
            pass  # EGLä¸å¯ç”¨
        except Exception:
            pass  # å¿½ç•¥æ‰€æœ‰EGLç›¸å…³é”™è¯¯
            
        print("ç®€åŒ–OpenGLæ¸…ç†å®Œæˆ")
        
    except Exception:
        pass  # å¿½ç•¥æ‰€æœ‰æ¸…ç†é”™è¯¯

def safe_distributed_cleanup(timeout=10):
    """å®‰å…¨æ¸…ç†åˆ†å¸ƒå¼è®­ç»ƒï¼Œå¸¦è¶…æ—¶ä¿æŠ¤"""
    if not dist.is_initialized():
        return
        
    def barrier_with_timeout():
        try:
            dist.barrier()
        except Exception as e:
            print(f"åˆ†å¸ƒå¼barrierå‡ºé”™: {e}")
    
    try:
        # åœ¨å•ç‹¬çº¿ç¨‹ä¸­è¿è¡Œbarrierï¼Œå¸¦è¶…æ—¶
        barrier_thread = threading.Thread(target=barrier_with_timeout)
        barrier_thread.daemon = True
        barrier_thread.start()
        barrier_thread.join(timeout=timeout)
        
        if barrier_thread.is_alive():
            print(f"è­¦å‘Š: åˆ†å¸ƒå¼barrierè¶…æ—¶ ({timeout}ç§’)")
        
        # é”€æ¯è¿›ç¨‹ç»„
        dist.destroy_process_group()
        
    except Exception as e:
        print(f"åˆ†å¸ƒå¼æ¸…ç†å‡ºé”™: {e}")

def safe_environment_cleanup(env):
    """å®‰å…¨æ¸…ç†ç¯å¢ƒï¼Œé˜²æ­¢å­è¿›ç¨‹æ³„æ¼"""
    if env is None:
        return
        
    try:
        # ç¡®ä¿ç¯å¢ƒå…³é—­
        if hasattr(env, 'close'):
            env.close()
        
        # ç­‰å¾…å­è¿›ç¨‹ç»ˆæ­¢
        time.sleep(0.1)
        
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        del env
        gc.collect()
        
    except Exception as e:
        print(f"ç¯å¢ƒæ¸…ç†å‡ºé”™: {e}")

def consolidated_exit_handler():
    """æœ€ç®€åŒ–çš„é€€å‡ºå¤„ç†ç¨‹åºï¼Œé¿å…ä»»ä½•å¯èƒ½çš„èµ„æºå†²çª"""
    try:
        print("æ­£åœ¨æ‰§è¡Œæœ€ç®€åŒ–æ¸…ç†...")
        
        # åªåšæœ€åŸºæœ¬çš„GPUå†…å­˜æ¸…ç†
        try:
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
        except Exception:
            pass
        
        print("æœ€ç®€åŒ–æ¸…ç†å®Œæˆ")
        
    except Exception:
        pass  # å®Œå…¨å¿½ç•¥æ‰€æœ‰é”™è¯¯

# å®Œå…¨ç§»é™¤atexitæ³¨å†Œä»¥é¿å…shutdownæ—¶çš„å†²çª
# åªä½¿ç”¨signal handlerså’Œæ‰‹åŠ¨æ¸…ç†

# ========= ä¿¡å·å¤„ç†ç¨‹åº =========

def signal_handler(signum, frame):
    """ç®€åŒ–çš„ä¿¡å·å¤„ç†ç¨‹åºï¼Œä¼˜é›…å…³é—­"""
    print(f"\næ”¶åˆ°ä¿¡å· {signum}ï¼Œå¼€å§‹ä¼˜é›…å…³é—­...")
    try:
        # æ‰§è¡Œç®€åŒ–çš„æ¸…ç†
        consolidated_exit_handler()
    except Exception:
        pass  # å¿½ç•¥æ¸…ç†é”™è¯¯
    finally:
        # é€€å‡ºç¨‹åº
        os._exit(0)

# æ³¨å†Œä¿¡å·å¤„ç†ç¨‹åº
signal.signal(signal.SIGTERM, signal_handler)
signal.signal(signal.SIGINT, signal_handler)

def main():
    try:
        parser = argparse.ArgumentParser(
            description="Run RIPT online training for PI0 policy using a config file."
        )
        parser.add_argument(
            "--config_path",
            type=str,
            required=True,
            help="Path to the training config file. See `ript/config` for examples.",
        )
        parser.add_argument(
            "--resume",
            type=str,
            default=None,
            help="Path to checkpoint to resume training from.",
        )
        args = parser.parse_args()

        # We don't yet know the final output_dir from config; create a temporary bootstrap log to capture early prints.
        _bootstrap_log_dir = Path.cwd() / "ript_bootstrap_logs"
        _bootstrap_log_dir.mkdir(parents=True, exist_ok=True)
        _bootstrap_log_fh = setup_run_logging(str(_bootstrap_log_dir), rank=int(os.environ.get("LOCAL_RANK", 0)))
        print(f"[BootstrapLogging] Early logs -> {_bootstrap_log_fh.name}")

        # ä½¿ç”¨æ ‡å‡†yamlé…ç½®åŠ è½½
        print("æ­£åœ¨åŠ è½½é…ç½®æ–‡ä»¶...")
        import yaml
        with open(args.config_path, 'r') as f:
            config = yaml.safe_load(f)
        
        print("âœ“ é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")
        
        # === å¼ºåˆ¶æŒ‡å®šç»Ÿä¸€çš„å½’ä¸€åŒ–å‚æ•°è·¯å¾„ï¼Œé¿å…æœç´¢é¡ºåºå¯¼è‡´ä¸ä¸€è‡´ ===
        config['norm_stats_path'] = "/zhaohan/ZJH/openpi_pytorch/lerobot_dataset/norm_stats.json"

        # è®¾ç½®åˆ†å¸ƒå¼è®­ç»ƒ
        local_rank, global_rank, world_size, device = setup_distributed()
        
        # åˆ›å»ºå®éªŒIDï¼Œç”¨äºåŒºåˆ†ä¸åŒçš„è®­ç»ƒè¿è¡Œ
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        exp_id = f"{config['exp_name']}_{timestamp}"
        
        # æ›´æ–°è¾“å‡ºç›®å½•ä»¥åŒ…å«å®éªŒID
        config['output_dir'] = os.path.join(config['output_dir'], exp_id)

        # Reconfigure logging to the final experiment directory (overrides bootstrap tee)
        _final_log_fh = setup_run_logging(config['output_dir'], rank=global_rank)
        print(f"[RunLogging] Logging ALL stdout/stderr for rank{global_rank} -> {_final_log_fh.name}")

        if global_rank == 0:
            print("====== ä½¿ç”¨é…ç½® ======")
            print(yaml.dump(config))
            print("==========================")
            print(f"ä¸–ç•Œå¤§å°: {world_size} GPUs")
            print(f"ä½¿ç”¨è®¾å¤‡: {device}")
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(config['output_dir'], exist_ok=True)
            
            # åˆå§‹åŒ–wandb
            if config['logging']['use_wandb']:
                wandb.init(
                    project=config['logging']['wandb_project'],
                    entity=config['logging']['wandb_entity'],
                    name=config['exp_name'],
                    config=config,
                    mode=config['logging'].get('wandb_mode', 'online'),  # ä½¿ç”¨é…ç½®ä¸­çš„wandb_modeï¼Œé»˜è®¤ä¸ºonline
                )

        # è®¾ç½®ç§å­ä»¥ç¡®ä¿å¯é‡å¤æ€§
        torch.manual_seed(config['training']['seed'] + global_rank)
        np.random.seed(config['training']['seed'] + global_rank)

        # 1. åŠ è½½ç­–ç•¥æ¨¡å‹
        try:
            # æ·»åŠ è·¯å¾„æ£€æŸ¥å’Œå¼ºåˆ¶æœ¬åœ°åŠ è½½

            
            # è·å–å½“å‰å·¥ä½œç›®å½•
            cwd = os.getcwd()
            print(f"å½“å‰å·¥ä½œç›®å½•: {cwd}")
            
            # è§£ææ¨¡å‹è·¯å¾„
            raw_model_path = config['policy_path']
            print(f"åŸå§‹æ¨¡å‹è·¯å¾„é…ç½®: {raw_model_path}")
            
            # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œå°è¯•ä¸åŒçš„è§£ææ–¹å¼
            if raw_model_path.startswith('./') or raw_model_path.startswith('../'):
                # å°è¯•ç›¸å¯¹äºå½“å‰å·¥ä½œç›®å½•
                model_dir = Path(raw_model_path).expanduser().resolve()
                print(f"è§£æåçš„ç»å¯¹è·¯å¾„: {model_dir}")
                
                # å¦‚æœä¸å­˜åœ¨ï¼Œå°è¯•ç›¸å¯¹äºè„šæœ¬ç›®å½•
                if not model_dir.exists():
                    script_dir = Path(__file__).parent.resolve()
                    alternative_path = (script_dir / '..' / '..' / '..' / '..' / '..' / raw_model_path[2:]).resolve()
                    print(f"å°è¯•ç›¸å¯¹äºè„šæœ¬ç›®å½•çš„è·¯å¾„: {alternative_path}")
                    
                    if alternative_path.exists():
                        model_dir = alternative_path
                        print(f"ä½¿ç”¨æ›¿ä»£è·¯å¾„: {model_dir}")
            else:
                # ç»å¯¹è·¯å¾„æˆ–ç®€å•ç›¸å¯¹è·¯å¾„
                model_dir = Path(raw_model_path).expanduser().resolve()
                print(f"è§£æåçš„ç»å¯¹è·¯å¾„: {model_dir}")
            
            # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
            if not model_dir.exists():
                # å°è¯•åˆ—å‡ºçˆ¶ç›®å½•çš„å†…å®¹ä»¥ä¾¿è°ƒè¯•
                parent_dir = model_dir.parent
                if parent_dir.exists():
                    print(f"çˆ¶ç›®å½• {parent_dir} å†…å®¹:")
                    for item in parent_dir.iterdir():
                        print(f"  - {item.name}")
                
                # å°è¯•ä½¿ç”¨ç¡¬ç¼–ç çš„ç»å¯¹è·¯å¾„ä½œä¸ºæœ€åçš„å¤‡é€‰
                fallback_paths = [
                    # åŸå§‹é…ç½®è·¯å¾„å’Œå¸¸è§å˜ä½“
                    Path('/zhaohan/ZJH/lerobot/lerobot/common/policies/pi0/checkpoints/pi0_libero_pytorch'),
                    Path('/zhaohan/ZJH/lerobot/common/policies/pi0/checkpoints/pi0_libero_pytorch'),
                    Path('/zhaohan/ZJH/lerobot/policies/pi0/checkpoints/pi0_libero_pytorch'),
                ]
                
                for fallback_path in fallback_paths:
                    print(f"å°è¯•å¤‡é€‰è·¯å¾„: {fallback_path}")
                    if fallback_path.exists():
                        model_dir = fallback_path
                        print(f"ä½¿ç”¨å¤‡é€‰è·¯å¾„: {model_dir}")
                        break
                
                if not model_dir.exists():
                    raise FileNotFoundError(f"é¢„è®­ç»ƒæ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {model_dir}")
            
            
                
            policy = PI0Policy.from_pretrained(
                str(model_dir),
                local_files_only=True      # å…³é”®ï¼šåªæŸ¥æœ¬åœ°
            ).to(device)
            
            if global_rank == 0:
                print(f"æˆåŠŸåŠ è½½ç­–ç•¥æ¨¡å‹: {model_dir}")
        except Exception as e:
            print(f"åŠ è½½ç­–ç•¥æ¨¡å‹å¤±è´¥: {e}")
            raise
        
        # 2. å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ä»¥èŠ‚çœå†…å­˜ï¼ˆå¦‚æœé…ç½®ä¸­å¯ç”¨ï¼‰
        if config['distributed'].get('gradient_checkpointing', False):
            # æ£€æŸ¥ç­–ç•¥æ˜¯å¦æ”¯æŒæ¢¯åº¦æ£€æŸ¥ç‚¹
            if hasattr(policy, 'gradient_checkpointing_enable'):
                policy.gradient_checkpointing_enable()
                if global_rank == 0:
                    print("å·²å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹")
            else:
                if global_rank == 0:
                    print("è­¦å‘Š: ç­–ç•¥æ¨¡å‹ä¸æ”¯æŒæ¢¯åº¦æ£€æŸ¥ç‚¹ï¼Œå°†ä¸ä½¿ç”¨è¯¥åŠŸèƒ½")
        
        # 3. æ ¹æ®æ¨¡å¼å†³å®šæ˜¯å¦ä½¿ç”¨DDPåŒ…è£…æ¨¡å‹
        if world_size > 1:
            # åˆ†å¸ƒå¼è®­ç»ƒæ¨¡å¼
            if torch.cuda.is_available():
                ddp_policy = DDP(
                    policy, 
                    device_ids=[local_rank], 
                    output_device=local_rank, 
                    find_unused_parameters=False,
                    # å¦‚æœå¯ç”¨äº†ZeROä¼˜åŒ–ï¼Œåˆ™ä½¿ç”¨é™æ€å›¾
                    static_graph=config['distributed'].get('zero_optimization', False)
                )
            else:
                # CPUç‰ˆæœ¬çš„DDP
                ddp_policy = DDP(
                    policy,
                    find_unused_parameters=False,
                    static_graph=config['distributed'].get('zero_optimization', False)
                )
            if global_rank == 0:
                print("ä½¿ç”¨åˆ†å¸ƒå¼æ•°æ®å¹¶è¡Œ (DDP) æ¨¡å¼")
        else:
            # å•GPUæ¨¡å¼ï¼Œä¸ä½¿ç”¨DDP
            ddp_policy = policy
            if global_rank == 0:
                print("ä½¿ç”¨å•GPUæ¨¡å¼ï¼ˆæ— DDPï¼‰")

        # 4. è·å–ä»»åŠ¡åˆ—è¡¨
        task_name = config['task'].get('task_name') # ä½¿ç”¨.getä»¥ç¡®ä¿å®‰å…¨
        if task_name:
            all_tasks = [task_name]
        else:
            # è·å–åŸºå‡†ä¸­çš„æ‰€æœ‰ä»»åŠ¡
            benchmark_obj = benchmark[config['task']['benchmark_name'].lower()]()
            all_tasks = benchmark_obj.get_task_names()
        
        # 5. å°†ä»»åŠ¡åˆ†é…ç»™ä¸åŒçš„GPU
        local_tasks = distribute_tasks(all_tasks, world_size, global_rank)
        
        if global_rank == 0:
            print(f"ä»»åŠ¡åˆ†é…:")
            for r in range(world_size):
                tasks = distribute_tasks(all_tasks, world_size, r)
                print(f"  GPU {r}: {tasks}")
        
        print(f"GPU {global_rank} çš„ä»»åŠ¡: {local_tasks}")

        # å¯åŠ¨åå°å†…å­˜æ¸…ç†çº¿ç¨‹
        memory_cleanup_stop_event = threading.Event()
        memory_cleanup_thread_obj = threading.Thread(
            target=memory_cleanup_thread, 
            args=(memory_cleanup_stop_event,),
            daemon=True
        )
        memory_cleanup_thread_obj.start()
        
        # 6. åˆ›å»ºLIBEROç¯å¢ƒè¿è¡Œå™¨
        try:
            # é¦–å…ˆåŒ…è£…ç­–ç•¥ä»¥æä¾›æ›´å¥½çš„é”™è¯¯å¤„ç†
            from pi0.ript.utils.pi0_libero_utils import Pi0PolicyWrapper
            
            wrapped_policy = Pi0PolicyWrapper(get_model_from_ddp(ddp_policy))

            # --- Action progress instrumentation --------------------------------------------------------
            # Use max_episode_length from config as an approximate total per rollout episode.
            _apb = ActionProgressBar(
                total_steps=config['task']['max_episode_length'],
                rank=global_rank,
                desc="Actions"
            )

            # Attach callback so every generated action chunk ticks the bar.
            if hasattr(wrapped_policy, "set_action_callback"):
                wrapped_policy.set_action_callback(_apb.update)
            else:
                # Fallback: monkeypatch attribute used by wrapper (we'll patch wrapper to call this)
                wrapped_policy.action_callback = _apb.update

            # å®šä¹‰norm_stats_pathä¾›åç»­ä½¿ç”¨
            norm_stats_path = config.get('norm_stats_path', None)
            
            # ğŸš€ ä½¿ç”¨æ–°çš„æ™ºèƒ½Runneré€‰æ‹©é€»è¾‘
            libero_runner = create_env_runner(
                config=config,
                policy=wrapped_policy,  # ä½¿ç”¨åŒ…è£…åçš„ç­–ç•¥
                rank=global_rank,
                world_size=world_size
            )
            
            if global_rank == 0:
                print("æˆåŠŸåˆ›å»ºLIBEROç¯å¢ƒè¿è¡Œå™¨")
        except Exception as e:
            print(f"åˆ›å»ºLIBEROç¯å¢ƒè¿è¡Œå™¨å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise

        # 7. åˆ›å»ºåˆå§‹çŠ¶æ€æ•°æ®é›†
        init_states_dataset = LiberoInitStateDataset(
            benchmark_name=config['task']['benchmark_name'],
            task_names_to_use=local_tasks,
            split='train',
        )
        
        # æ ¹æ®æ¨¡å¼é€‰æ‹©é‡‡æ ·å™¨
        if world_size > 1:
            # ä½¿ç”¨DistributedSamplerç¡®ä¿æ¯ä¸ªGPUè·å–ä¸åŒçš„æ•°æ®
            init_states_sampler = DistributedSampler(
                init_states_dataset, 
                num_replicas=world_size,
                rank=global_rank,
                shuffle=True
            )
            shuffle_data = False  # ç”±DistributedSamplerå¤„ç†
        else:
            # å•GPUæ¨¡å¼ï¼Œä¸ä½¿ç”¨DistributedSampler
            init_states_sampler = None
            shuffle_data = True
        
        init_states_dataloader = DataLoader(
            init_states_dataset,
            batch_size=config['task']['num_parallel_envs'], # ä½¿ç”¨é…ç½®ä¸­çš„å¹¶è¡Œç¯å¢ƒæ•°é‡
            shuffle=shuffle_data,
            sampler=init_states_sampler,
            num_workers=0,  # è®¾ç½®ä¸º0ä»¥é¿å…å¤šè¿›ç¨‹åºåˆ—åŒ–é—®é¢˜
            pin_memory=True,
            prefetch_factor=None,  # å½“num_workers=0æ—¶ä¸éœ€è¦prefetch_factor
        )

        # 8. åˆ›å»ºRolloutç”Ÿæˆå™¨
        num_parallel_envs = config['task']['num_parallel_envs']  # ä»é…ç½®ä¸­è·å–å¹¶ä¿å­˜ä¸ºå˜é‡
        
        # æ ¹æ®è®¾å¤‡ç±»å‹è®¾ç½®agent_gpuså‚æ•°
        agent_gpus = [local_rank] if torch.cuda.is_available() else None
        
        rollout_generator = RolloutGenerator(
            env_runner=libero_runner,
            init_state_dataloader=init_states_dataloader,
            init_state_dataset=init_states_dataset,
            rollouts_per_env=config['algo']['rloo_batch_size'],
            num_envs=num_parallel_envs,  # ä½¿ç”¨ä¿å­˜çš„å˜é‡
            max_steps=1_000_000, # ä¸€ä¸ªè¾ƒå¤§çš„æ•°å­—ï¼Œå®é™…æ­¥æ•°ç”±runneræ§åˆ¶
            agent_gpus=agent_gpus, # æ ¹æ®è®¾å¤‡ç±»å‹è®¾ç½®
            enable_dynamic_sampling=config['algo'].get('enable_dynamic_sampling', False),
            enable_rollout_stats_tracking=config['algo'].get('enable_rollout_stats_tracking', False),
            rollout_skip_threshold=config['algo'].get('rollout_skip_threshold', 3),
            rollout_stats_path=config['algo'].get('rollout_stats_path', None),
            use_val_init=config['algo'].get('use_val_init', False),
        )

        # 9. åˆ›å»ºä¼˜åŒ–å™¨
        optimizer = get_optimizer(ddp_policy, config)

        # 10. åˆ›å»ºRLä¼˜åŒ–å™¨
        rl_optimizer = RLOptimizerPI0_CFG(
            rollout_generator=rollout_generator,
            reward_function=BinarySuccessReward(),
            num_epochs=config['algo']['num_epochs'],
            batch_size=config['algo']['data_batch_size'],
            gradient_accumulation_steps=config['algo']['gradient_accumulation_steps'],
            grad_norm_clip=config['algo'].get('grad_norm_clip', None),
        )

        # 11. åˆ›å»ºæ¨¡å‹æ¥å£ï¼ˆä¼ é€’å½’ä¸€åŒ–å‚æ•°ï¼‰
        model_interface = PI0_CFG_Adapter(
            policy=get_model_from_ddp(ddp_policy),
            norm_stats_path=norm_stats_path
        )
        
        # ä¸ºæ¨¡å‹æ¥å£é™„åŠ ä¼˜åŒ–å™¨ï¼Œè¿™æ ·RLä¼˜åŒ–å™¨å¯ä»¥è®¿é—®å®ƒ
        get_model_from_ddp(ddp_policy).optimizer = optimizer

        # 12. åˆ›å»ºæ··åˆç²¾åº¦è®­ç»ƒçš„scalerï¼ˆå¦‚æœå¯ç”¨ï¼‰
        use_mixed_precision = config['training'].get('use_mixed_precision', False)
        use_fp16 = config['distributed'].get('fp16', False)
        use_bf16 = config['distributed'].get('bf16', False)
        
        # åœ¨CPUæ¨¡å¼ä¸‹ç¦ç”¨æ··åˆç²¾åº¦
        if not torch.cuda.is_available():
            use_mixed_precision = False
            use_fp16 = False
            use_bf16 = False
            if global_rank == 0:
                print("åœ¨CPUæ¨¡å¼ä¸‹ç¦ç”¨æ··åˆç²¾åº¦è®­ç»ƒ")
        
        scaler = None
        if use_mixed_precision or use_fp16:
            scaler = GradScaler()
            if global_rank == 0:
                print("å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ (FP16)")
        elif use_bf16 and torch.cuda.is_bf16_supported():
            if global_rank == 0:
                print("å¯ç”¨BF16ç²¾åº¦è®­ç»ƒ")
        
        # 13. æ¢å¤è®­ç»ƒï¼ˆå¦‚æœæä¾›äº†æ£€æŸ¥ç‚¹ï¼‰
        start_step = 0
        if args.resume:
            checkpoint_path = args.resume
            start_step = load_checkpoint(get_model_from_ddp(ddp_policy), optimizer, checkpoint_path)
            
            # åŒæ­¥æ‰€æœ‰è¿›ç¨‹ä»¥ç¡®ä¿å®ƒä»¬ä»ç›¸åŒçš„æ­¥éª¤å¼€å§‹
            if dist.is_initialized():
                start_step_tensor = torch.tensor([start_step], device=device)
                dist.broadcast(start_step_tensor, src=0)
                start_step = int(start_step_tensor.item())

        # 14. å¼€å§‹è®­ç»ƒå¾ªç¯
        best_reward = float('-inf')
        consecutive_oom_errors = 0
        max_oom_retries = 3
        
        for step in range(start_step, config['training']['num_train_steps']):
            if global_rank == 0:
                print(f"========== è®­ç»ƒæ­¥éª¤ {step+1}/{config['training']['num_train_steps']} ==========")
                step_start_time = time.time()

            # Reset per-train-step action progress display
            if '_apb' in locals():
                _apb.reset()
            else:
                try:
                    _apb.reset()
                except Exception:
                    pass

            # åœ¨æ¯ä¸ªepochå¼€å§‹æ—¶è®¾ç½®æ•°æ®åŠ è½½å™¨çš„epoch
            if hasattr(init_states_dataloader, 'sampler') and hasattr(init_states_dataloader.sampler, 'set_epoch'):
                init_states_dataloader.sampler.set_epoch(step)

            # è¿è¡Œä¼˜åŒ–æ­¥éª¤
            try:
                # åœ¨è®­ç»ƒå‰æ¸…ç†å†…å­˜
                if step % 5 == 0:  # æ¯5æ­¥æ¸…ç†ä¸€æ¬¡
                    clear_gpu_memory()
                
                # è®°å½•è®­ç»ƒå‰çš„å†…å­˜ä½¿ç”¨
                if global_rank == 0 and step % 10 == 0:
                    memory_stats = get_memory_usage()
                    print(f"è®­ç»ƒå‰å†…å­˜ä½¿ç”¨: {memory_stats}")
                
                # æ·»åŠ è®­ç»ƒå‰çš„ç­–ç•¥çŠ¶æ€æ£€æŸ¥
                if global_rank == 0 and step % 20 == 0:
                    print(f"æ£€æŸ¥ç­–ç•¥çŠ¶æ€: ç­–ç•¥ç±»å‹={type(get_model_from_ddp(ddp_policy))}")
                    if hasattr(get_model_from_ddp(ddp_policy), '_action_queue'):
                        print(f"åŠ¨ä½œé˜Ÿåˆ—é•¿åº¦: {len(get_model_from_ddp(ddp_policy)._action_queue)}")
                    if hasattr(wrapped_policy, 'action_failure_count'):
                        print(f"åŠ¨ä½œå¤±è´¥æ¬¡æ•°: {wrapped_policy.action_failure_count}")
                
                # ä½¿ç”¨ç»Ÿä¸€çš„autocastè®¾ç½®
                autocast_enabled = use_mixed_precision or use_fp16 or (use_bf16 and torch.cuda.is_bf16_supported())
                autocast_dtype = torch.bfloat16 if (use_bf16 and torch.cuda.is_bf16_supported()) else torch.float16
                
                if autocast_enabled:
                    with autocast(dtype=autocast_dtype if torch.cuda.is_available() else torch.float32):
                        metrics = rl_optimizer.train_on_rollouts(
                            model_interface, 
                            float(config['algo']['lr']),
                            scaler=scaler,
                            use_amp=use_mixed_precision or use_fp16
                        )
                else:
                    metrics = rl_optimizer.train_on_rollouts(
                        model_interface, 
                        float(config['algo']['lr']),
                        scaler=None,
                        use_amp=False
                    )
                
                # éªŒè¯è®­ç»ƒç»“æœ
                if metrics is None:
                    print("è­¦å‘Š: è®­ç»ƒè¿”å›None metrics")
                    metrics = {'mean_reward': 0.0, 'success_rate': 0.0}
                
                # é‡ç½®OOMé”™è¯¯è®¡æ•°å™¨
                consecutive_oom_errors = 0
                
            except torch.cuda.OutOfMemoryError as e:
                consecutive_oom_errors += 1
                print(f"CUDAå†…å­˜ä¸è¶³é”™è¯¯ (ç¬¬{consecutive_oom_errors}æ¬¡): {e}")
                
                if consecutive_oom_errors <= max_oom_retries:
                    print("å°è¯•æ¸…ç†å†…å­˜å¹¶é‡è¯•...")
                    clear_gpu_memory()
                    
                    # é‡ç½®ç­–ç•¥çŠ¶æ€
                    if hasattr(wrapped_policy, 'reset'):
                        wrapped_policy.reset()
                        # Reset action progress bar after OOM restart
                        try:
                            _apb.reset()
                        except Exception:
                            pass
                    
                    # å‡å°‘æ‰¹æ¬¡å¤§å°
                    if hasattr(rl_optimizer, 'batch_size'):
                        rl_optimizer.batch_size = max(1, rl_optimizer.batch_size // 2)
                        print(f"å°†æ‰¹æ¬¡å¤§å°å‡å°‘åˆ°: {rl_optimizer.batch_size}")
                    
                    # è·³è¿‡å½“å‰æ­¥éª¤
                    metrics = {'mean_reward': 0.0, 'success_rate': 0.0, 'error': 'OOM'}
                    continue
                else:
                    print(f"è¿ç»­{max_oom_retries}æ¬¡å†…å­˜ä¸è¶³é”™è¯¯ï¼Œç»ˆæ­¢è®­ç»ƒ")
                    raise
                    
            except Exception as e:
                print(f"è®­ç»ƒæ­¥éª¤å‡ºé”™: {e}")
                print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
                if global_rank == 0:
                    import traceback
                    traceback.print_exc()
                    
                    # æä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
                    print(f"å½“å‰æ­¥éª¤: {step}")
                    print(f"é…ç½®ä¿¡æ¯: batch_size={config['algo']['data_batch_size']}, lr={config['algo']['lr']}")
                    
                    # æ£€æŸ¥ç­–ç•¥çŠ¶æ€
                    if hasattr(wrapped_policy, 'action_failure_count'):
                        print(f"ç­–ç•¥å¤±è´¥æ¬¡æ•°: {wrapped_policy.action_failure_count}")
                
                # é‡ç½®ç­–ç•¥çŠ¶æ€
                if hasattr(wrapped_policy, 'reset'):
                    try:
                        wrapped_policy.reset()
                        try:
                            _apb.reset()
                        except Exception:
                            pass
                        print("å·²é‡ç½®ç­–ç•¥çŠ¶æ€")
                    except Exception as reset_e:
                        print(f"é‡ç½®ç­–ç•¥çŠ¶æ€æ—¶å‡ºé”™: {reset_e}")
                
                metrics = {'mean_reward': 0.0, 'success_rate': 0.0, 'error': str(e)}
                
                # æ¸…ç†å†…å­˜ä»¥é˜²æ­¢é”™è¯¯ç´¯ç§¯
                clear_gpu_memory()

            # è®°å½•æŒ‡æ ‡
            if global_rank == 0 and metrics is not None:
                step_duration = time.time() - step_start_time
                memory_stats = get_memory_usage()
                
                # åˆå¹¶æ‰€æœ‰æŒ‡æ ‡
                all_metrics = {
                    **metrics,
                    'step_time_seconds': step_duration,
                    'learning_rate': optimizer.param_groups[0]['lr'],
                    **memory_stats
                }
                
                if config['logging']['use_wandb']:
                    # è®°å½•æ¢¯åº¦å’Œå‚æ•°ï¼ˆå¦‚æœå¯ç”¨ä¸”ä¸ä¼šå¯¼è‡´å†…å­˜é—®é¢˜ï¼‰
                    if config['logging'].get('log_gradients', False) and step % 10 == 0:  # å‡å°‘é¢‘ç‡
                        try:
                            for name, param in ddp_policy.named_parameters():
                                if param.requires_grad and param.grad is not None:
                                    # åªè®°å½•ç»Ÿè®¡ä¿¡æ¯è€Œä¸æ˜¯å®Œæ•´çš„ç›´æ–¹å›¾
                                    grad_norm = param.grad.norm().item()
                                    param_norm = param.norm().item()
                                    wandb.log({
                                        f"grad_norms/{name}": grad_norm,
                                        f"param_norms/{name}": param_norm
                                    }, step=step)
                        except Exception as e:
                            print(f"è®°å½•æ¢¯åº¦ä¿¡æ¯æ—¶å‡ºé”™: {e}")
                    
                    wandb.log(all_metrics, step=step)
                
                print(f"æ­¥éª¤ {step+1} æŒ‡æ ‡: {all_metrics}")
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºæœ€ä½³æ¨¡å‹
                current_reward = metrics.get('mean_reward', float('-inf'))
                is_best = current_reward > best_reward
                if is_best:
                    best_reward = current_reward
                    print(f"æ–°çš„æœ€ä½³å¥–åŠ±: {best_reward:.4f}")

            # ä¿å­˜æ£€æŸ¥ç‚¹ï¼ˆå†…å­˜ä¼˜åŒ–ç‰ˆæœ¬ï¼‰
            if global_rank == 0:
                # å®šæœŸä¿å­˜
                if (step + 1) % config['training'].get('save_freq', 10) == 0:
                    checkpoint_path = os.path.join(config['output_dir'], f"checkpoint_step_{step+1}.pth")
                    save_checkpoint(
                        get_model_from_ddp(ddp_policy), 
                        optimizer, 
                        step+1, 
                        config, 
                        checkpoint_path,
                        is_best=is_best,
                        async_save=True  # å¼‚æ­¥ä¿å­˜
                    )
                
                # æ¯éš”è¾ƒé•¿æ—¶é—´ä¿å­˜ä¸€æ¬¡æœ€æ–°æ£€æŸ¥ç‚¹ä»¥é¿å…é¢‘ç¹IO
                if (step + 1) % max(1, config['training'].get('save_freq', 10) // 2) == 0:
                    latest_path = os.path.join(config['output_dir'], "latest.pth")
                    save_checkpoint(
                        get_model_from_ddp(ddp_policy), 
                        optimizer, 
                        step+1, 
                        config, 
                        latest_path,
                        async_save=False  # åŒæ­¥ä¿å­˜æœ€æ–°æ£€æŸ¥ç‚¹
                    )
            
            # ä½¿ç”¨æ›´å®‰å…¨çš„åŒæ­¥æ–¹å¼ï¼Œé¿å…æ­»é”
            try:
                if dist.is_initialized():
                    # è®¾ç½®è¶…æ—¶ä»¥é¿å…æ— é™ç­‰å¾…
                    timeout = torch.distributed.default_pg_timeout if hasattr(torch.distributed, 'default_pg_timeout') else None
                    if timeout:
                        dist.barrier()
                    else:
                        # å¯¹äºæ²¡æœ‰è¶…æ—¶æ”¯æŒçš„ç‰ˆæœ¬ï¼Œä½¿ç”¨all_reduceä½œä¸ºæ›¿ä»£
                        dummy_tensor = torch.zeros(1, device=device)
                        dist.all_reduce(dummy_tensor)
            except Exception as e:
                print(f"åŒæ­¥è¿‡ç¨‹ä¸­å‡ºé”™ï¼Œç»§ç»­è®­ç»ƒ: {e}")

        # åœæ­¢åå°å†…å­˜æ¸…ç†çº¿ç¨‹
        memory_cleanup_stop_event.set()
        if memory_cleanup_thread_obj.is_alive():
            memory_cleanup_thread_obj.join(timeout=5)  # 5ç§’è¶…æ—¶
        
        # ä¿å­˜æœ€ç»ˆçš„rolloutç»Ÿè®¡ä¿¡æ¯
        try:
            rollout_generator.save_stats()
        except Exception as e:
            print(f"ä¿å­˜rolloutç»Ÿè®¡ä¿¡æ¯æ—¶å‡ºé”™: {e}")
        
        # æ¸…ç†rolloutç”Ÿæˆå™¨ï¼ˆä½¿ç”¨å¢å¼ºçš„cleanupæ–¹æ³•ï¼‰
        try:
            rollout_generator.cleanup()
        except Exception as e:
            print(f"æ¸…ç†rolloutç”Ÿæˆå™¨æ—¶å‡ºé”™: {e}")
            # æ‰‹åŠ¨æ¸…ç†ç¯å¢ƒèµ„æº
            try:
                safe_environment_cleanup(getattr(rollout_generator, 'env_runner', None))
            except Exception as fallback_error:
                print(f"ç¯å¢ƒæ¸…ç†å›é€€å¤±è´¥: {fallback_error}")

        # Ensure progress bar is closed cleanly (rank0 only)
        try:
            if global_rank == 0 and hasattr(_apb, "_bar") and _apb._bar is not None:
                _apb._bar.close()
        except Exception:
            pass

        if global_rank == 0 and config['logging']['use_wandb']:
            wandb.finish()
        
        # æ¸…ç†GPUå†…å­˜
        clear_gpu_memory()
        
        # ä½¿ç”¨å®‰å…¨çš„åˆ†å¸ƒå¼æ¸…ç†ï¼ˆå¸¦è¶…æ—¶ä¿æŠ¤ï¼‰
        safe_distributed_cleanup()
        
        # ç›´æ¥é€€å‡ºï¼Œé¿å…ä»»ä½•cleanupå¼•èµ·çš„é—®é¢˜
        print("è®­ç»ƒå®Œæˆï¼Œç›´æ¥é€€å‡º...")
        os._exit(0)  # ä½¿ç”¨_exité¿å…ä»»ä½•Pythonæ¸…ç†
        
    except Exception as e:
        print(f"è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        
        # æ¸…ç†èµ„æº
        try:
            # åœæ­¢åå°çº¿ç¨‹
            if 'memory_cleanup_stop_event' in locals():
                memory_cleanup_stop_event.set()
            
            # æ¸…ç†GPUå†…å­˜
            clear_gpu_memory()
            
            # æ¸…ç†rolloutç”Ÿæˆå™¨ï¼ˆä½¿ç”¨å¢å¼ºçš„cleanupæ–¹æ³•ï¼‰
            if 'rollout_generator' in locals():
                try:
                    rollout_generator.cleanup()
                except Exception as cleanup_error:
                    print(f"æ¸…ç†rolloutç”Ÿæˆå™¨æ—¶å‡ºé”™: {cleanup_error}")
                    # æ‰‹åŠ¨æ¸…ç†ç¯å¢ƒèµ„æº
                    safe_environment_cleanup(getattr(rollout_generator, 'env_runner', None))
        except Exception as cleanup_error:
            print(f"æ¸…ç†èµ„æºæ—¶å‡ºé”™: {cleanup_error}")
        
        # ä½¿ç”¨å®‰å…¨çš„åˆ†å¸ƒå¼æ¸…ç†ï¼ˆå¸¦è¶…æ—¶ä¿æŠ¤ï¼‰
        safe_distributed_cleanup()
        
        # å¼‚å¸¸æƒ…å†µä¸‹ä¹Ÿç›´æ¥é€€å‡º
        print("å¼‚å¸¸é€€å‡º...")
        os._exit(1)  # å¼‚å¸¸é€€å‡ºç 


if __name__ == "__main__":
    main()

def save_observation_images(obs, step, save_dir):
    """æ”¶é›†å›¾åƒå¸§ç”¨äºç”Ÿæˆè§†é¢‘ï¼Œä¸å†ä¿å­˜å•ç‹¬å›¾åƒ"""
    collected_frames = []
    
    try:
        # ç¡®ä¿æ˜¯åˆ—è¡¨ç±»å‹
        if not isinstance(obs, list):
            obs_list = [obs]
        else:
            obs_list = obs
            
        for env_idx, env_obs in enumerate(obs_list):
            # æ£€æŸ¥obsç±»å‹
            if env_obs is None:
                continue
                
            # å¤„ç†ä¸åŒç±»å‹çš„è§‚æµ‹
            if isinstance(env_obs, dict):
                # ä¼˜å…ˆä½¿ç”¨agentview_image
                if "agentview_image" in env_obs:
                    img_data = env_obs["agentview_image"].copy()  # åˆ›å»ºå‰¯æœ¬ä»¥é¿å…ä¿®æ”¹åŸå§‹æ•°æ®
                    # æ—‹è½¬å›¾åƒä½¿å…¶æ–¹å‘æ­£ç¡®ï¼ˆè‹¥å›¾åƒå·²ç»å€’ç½®ï¼‰
                    img_data = img_data[::-1, ::-1]  # 180åº¦æ—‹è½¬
                    collected_frames.append(img_data)
                    break  # åªæ”¶é›†ä¸€ä¸ªè§†å›¾çš„å›¾åƒ
                elif "robot0_eye_in_hand_image" in env_obs:
                    img_data = env_obs["robot0_eye_in_hand_image"].copy()
                    img_data = img_data[::-1, ::-1]  # 180åº¦æ—‹è½¬
                    collected_frames.append(img_data)
                    break
                elif "images" in env_obs and isinstance(env_obs["images"], list) and len(env_obs["images"]) > 0:
                    img_data = env_obs["images"][0].copy()
                    img_data = img_data[::-1, ::-1]  # 180åº¦æ—‹è½¬
                    collected_frames.append(img_data)
                    break
            
            elif isinstance(env_obs, np.ndarray) and env_obs.ndim >= 2:
                img_data = env_obs.copy()
                img_data = img_data[::-1, ::-1]  # 180åº¦æ—‹è½¬
                collected_frames.append(img_data)
        
        return collected_frames
    except Exception as e:
        print(f"æ”¶é›†å›¾åƒå¸§æ—¶å‡ºé”™: {str(e)}")
        return []


def save_rollout_video(images, task_name, success=False, fps=10):
    """å°†ä¸€ç³»åˆ—å›¾åƒç›´æ¥ä¿å­˜ä¸ºè§†é¢‘ï¼Œä¸ä¿å­˜ä¸­é—´å›¾åƒæ–‡ä»¶"""
    if not images:
        return None
        
    try:
        # åˆ›å»ºè§†é¢‘ä¿å­˜ç›®å½•
        video_dir = os.path.join(DEBUG_IMAGE_DIR, "videos")
        os.makedirs(video_dir, exist_ok=True)
        
        # ç”Ÿæˆè§†é¢‘æ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        task_str = task_name.replace(" ", "_").replace("/", "_")[:30]
        video_path = os.path.join(video_dir, f"{timestamp}_{task_str}_{'æˆåŠŸ' if success else 'å¤±è´¥'}.mp4")
        
        # ä¿å­˜è§†é¢‘
        imageio.mimsave(video_path, images, fps=fps)
        print(f"å·²ä¿å­˜è½¨è¿¹è§†é¢‘: {video_path}")
        return video_path
    except Exception as e:
        print(f"ä¿å­˜è§†é¢‘æ—¶å‡ºé”™: {str(e)}")
        return None