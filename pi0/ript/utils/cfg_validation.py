#!/usr/bin/env python3
"""
CFGå®ç°éªŒè¯è„šæœ¬
===============

éªŒè¯CFGè®­ç»ƒå’Œæ¨ç†çš„æ­£ç¡®æ€§ï¼Œç¡®ä¿ä¸åŸå§‹CFGRLå®ç°å¯¹é½
"""
import torch
import numpy as np
from typing import Dict, Any

def validate_cfg_training(policy, episodes: list, advantages: torch.Tensor, device: str = "cuda"):
    """
    éªŒè¯CFGè®­ç»ƒå®ç°çš„æ­£ç¡®æ€§
    
    æ£€æŸ¥é¡¹:
    1. åŒä¸€æ‰¹noise/timeä¸‹ï¼Œis_positive=1ä¸=0è¾“å‡ºçš„lossesä¸åº”å®Œå…¨ç›¸ç­‰
    2. æ¡ä»¶å’Œæ— æ¡ä»¶åˆ†æ”¯éƒ½èƒ½æ­£å¸¸å‰å‘ä¼ æ’­
    3. ä¼˜åŠ¿æƒé‡æ­£ç¡®åº”ç”¨
    """
    print("ğŸ” éªŒè¯CFGè®­ç»ƒå®ç°...")
    
    try:
        from pi0.ript.algos.rl_optimizers.pi0_cfg_interface import PI0_CFG_Adapter
        
        adapter = PI0_CFG_Adapter(policy)
        
        # æµ‹è¯•åŸºæœ¬è®­ç»ƒæµç¨‹
        loss = adapter.compute_weighted_loss(episodes, advantages, device=torch.device(device))
        
        print(f"âœ… CFGè®­ç»ƒæŸå¤±è®¡ç®—æˆåŠŸ: {loss.item():.6f}")
        
        # æ£€æŸ¥æŸå¤±æ˜¯å¦ä¸ºæœ‰é™å€¼
        assert torch.isfinite(loss), "CFGæŸå¤±å¿…é¡»ä¸ºæœ‰é™å€¼"
        assert loss.requires_grad, "CFGæŸå¤±å¿…é¡»æ”¯æŒæ¢¯åº¦è®¡ç®—"
        
        return True
        
    except Exception as e:
        print(f"âŒ CFGè®­ç»ƒéªŒè¯å¤±è´¥: {e}")
        return False

def validate_cfg_inference(policy, observation: Dict[str, Any], device: str = "cuda"):
    """
    éªŒè¯CFGæ¨ç†å®ç°çš„æ­£ç¡®æ€§
    
    æ£€æŸ¥é¡¹:
    1. cfg_scale=1.0ä¸>1.0çš„åŠ¨ä½œåº”æœ‰å¯è§‚å·®å¼‚
    2. cfg_scaleå¢å¤§æ—¶(v_cond - v_uncond)çš„æŠ•å½±æ­¥é•¿å˜å¤§
    3. çº¯æ— æ¡ä»¶æ¨ç†ä¸æŠ¥é”™
    """
    print("ğŸ” éªŒè¯CFGæ¨ç†å®ç°...")
    
    try:
        policy = policy.to(device).eval()
        
        # æµ‹è¯•ä¸åŒcfg_scaleçš„è¾“å‡ºå·®å¼‚
        action_uncond = policy.select_action(observation, cfg_scale=1.0)  # çº¯æ— æ¡ä»¶
        action_cfg_3 = policy.select_action(observation, cfg_scale=3.0)   # CFGå¼•å¯¼
        action_cfg_5 = policy.select_action(observation, cfg_scale=5.0)   # æ›´å¼ºCFGå¼•å¯¼
        
        # è®¡ç®—åŠ¨ä½œå·®å¼‚
        diff_1_3 = torch.norm(action_uncond - action_cfg_3).item()
        diff_3_5 = torch.norm(action_cfg_3 - action_cfg_5).item()
        
        print(f"âœ… CFGæ¨ç†æµ‹è¯•æˆåŠŸ:")
        print(f"   cfg_scale=1.0 vs 3.0 å·®å¼‚: {diff_1_3:.6f}")
        print(f"   cfg_scale=3.0 vs 5.0 å·®å¼‚: {diff_3_5:.6f}")
        
        # æ£€æŸ¥CFGå¼•å¯¼ç¡®å®äº§ç”Ÿäº†ä¸åŒçš„è¾“å‡º
        assert diff_1_3 > 1e-6, f"CFGå¼•å¯¼åº”è¯¥äº§ç”Ÿä¸åŒçš„åŠ¨ä½œï¼Œä½†å·®å¼‚è¿‡å°: {diff_1_3}"
        
        return True
        
    except Exception as e:
        print(f"âŒ CFGæ¨ç†éªŒè¯å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def validate_noise_time_consistency(policy, episodes: list, advantages: torch.Tensor, device: str = "cuda"):
    """
    éªŒè¯noiseå’Œtimeåœ¨æ¡ä»¶/æ— æ¡ä»¶åˆ†æ”¯é—´çš„ä¸€è‡´æ€§
    
    è¿™æ˜¯ä¸åŸå§‹CFGRLå¯¹é½çš„å…³é”®ç‚¹
    """
    print("ğŸ” éªŒè¯noise/timeä¸€è‡´æ€§...")
    
    try:
        from pi0.ript.algos.rl_optimizers.pi0_cfg_interface import PI0_CFG_Adapter
        
        # æ‰‹åŠ¨æ¨¡æ‹Ÿadapterä¸­çš„noise/timeé‡‡æ ·é€»è¾‘
        adapter = PI0_CFG_Adapter(policy)
        batch = adapter.process_episodes(episodes, torch.device(device))
        
        B = batch["state"].shape[0]
        n, d = policy.config.n_action_steps, policy.config.max_action_dim
        dtype = batch["state"].dtype
        
        # é‡‡æ ·ä¸€æ¬¡noiseå’Œtime
        noise = torch.randn(B, n, d, device=torch.device(device), dtype=dtype)
        time = policy.model.sample_time(B, torch.device(device)).to(dtype)
        
        # æ¡ä»¶åˆ†æ”¯
        batch_positive = batch.copy()
        batch_positive["is_positive"] = torch.ones(B, device=torch.device(device), dtype=torch.long)
        batch_positive["noise"] = noise
        batch_positive["time"] = time
        
        # æ— æ¡ä»¶åˆ†æ”¯
        batch_uncond = batch.copy()
        batch_uncond["is_positive"] = torch.zeros(B, device=torch.device(device), dtype=torch.long)
        batch_uncond["noise"] = noise  # å…³é”®ï¼šä½¿ç”¨ç›¸åŒçš„noise
        batch_uncond["time"] = time    # å…³é”®ï¼šä½¿ç”¨ç›¸åŒçš„time
        
        # å‰å‘ä¼ æ’­
        out_pos = policy.forward(batch_positive)
        out_uncond = policy.forward(batch_uncond)
        
        print("âœ… noise/timeä¸€è‡´æ€§éªŒè¯é€šè¿‡")
        print(f"   æ¡ä»¶åˆ†æ”¯æŸå¤±å½¢çŠ¶: {out_pos[1]['losses'].shape}")
        print(f"   æ— æ¡ä»¶åˆ†æ”¯æŸå¤±å½¢çŠ¶: {out_uncond[1]['losses'].shape}")
        
        # éªŒè¯ä¸¤ä¸ªåˆ†æ”¯çš„æŸå¤±ä¸å®Œå…¨ç›¸ç­‰ï¼ˆè¯´æ˜CFG embeddingç”Ÿæ•ˆï¼‰
        losses_diff = torch.norm(out_pos[1]['losses'] - out_uncond[1]['losses']).item()
        assert losses_diff > 1e-6, f"æ¡ä»¶å’Œæ— æ¡ä»¶åˆ†æ”¯æŸå¤±åº”è¯¥ä¸åŒï¼Œä½†å·®å¼‚è¿‡å°: {losses_diff}"
        print(f"   æ¡ä»¶/æ— æ¡ä»¶æŸå¤±å·®å¼‚: {losses_diff:.6f} (æ­£å¸¸)")
        
        return True
        
    except Exception as e:
        print(f"âŒ noise/timeä¸€è‡´æ€§éªŒè¯å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def run_full_cfg_validation():
    """è¿è¡Œå®Œæ•´çš„CFGéªŒè¯æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹CFGå®ç°å®Œæ•´éªŒè¯\n")
    
    try:
        # è¿™é‡Œéœ€è¦ç”¨æˆ·æä¾›å®é™…çš„policyå’Œæ•°æ®
        # åœ¨å®é™…ä½¿ç”¨æ—¶ï¼Œåº”è¯¥ä»çœŸå®çš„è®­ç»ƒç¯å¢ƒä¸­è°ƒç”¨è¿™äº›éªŒè¯å‡½æ•°
        print("âš ï¸  æ³¨æ„: è¯·åœ¨å®é™…è®­ç»ƒè„šæœ¬ä¸­è°ƒç”¨å„ä¸ªéªŒè¯å‡½æ•°")
        print("   ç¤ºä¾‹ç”¨æ³•:")
        print("   validate_cfg_training(policy, episodes, advantages)")
        print("   validate_cfg_inference(policy, observation)")
        print("   validate_noise_time_consistency(policy, episodes, advantages)")
        
        return True
        
    except Exception as e:
        print(f"âŒ CFGéªŒè¯å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    run_full_cfg_validation()