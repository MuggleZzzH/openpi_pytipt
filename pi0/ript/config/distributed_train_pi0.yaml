# 分布式PI0 RIPT训练配置文件
# 第10阶段：完整的多GPU分布式训练支持

exp_name: pi0_distributed_ript_training

# --- 路径配置 ---
policy_path: "/zhaohan/ZJH/openpi_pytorch/checkpoints/pi0_libero_pytorch"
output_dir: "./pi0/ript/output/distributed"  
norm_stats_path: "/zhaohan/ZJH/openpi_pytorch/lerobot_dataset/norm_stats.json"

# --- 分布式配置 ---
distributed:
  enabled: true
  backend: 'nccl'                    # 分布式后端：nccl, gloo, mpi
  timeout_seconds: 10800             # 3小时超时
  find_unused_parameters: false     # DDP优化参数
  bucket_cap_mb: 25                  # 梯度bucket大小(MB)
  
# --- 数据并行配置 ---
data_parallel:
  sync_every_n_steps: 5              # 每N步同步一次统计数据
  enable_gradient_checkpointing: false # 梯度检查点（节省内存）
  async_data_loading: true           # 异步数据加载

# --- 任务分片配置 ---
task_distribution:
  enable_task_sharding: true         # 启用任务分片
  balance_tasks_across_gpus: true    # 任务负载均衡
  min_tasks_per_gpu: 1              # 每GPU最小任务数

# --- 任务和环境配置 ---
task:
  benchmark_name: "libero_spatial" 
  task_name: 9                       # 单任务训练
  task_names_to_use: null            # 多任务训练时使用此字段
  num_parallel_envs: 1               # 每GPU的并行环境数
  max_episode_length: 200

# --- 算法配置 ---
algo:
  # 分布式训练参数（自动按GPU数分配）
  rloo_batch_size: 4                 # 每个初始状态的轨迹数
  num_epochs: 3                      # 训练epochs  
  data_batch_size: 8                 # 总batch数（会按world_size分配）
  gradient_accumulation_steps: 2     # 梯度累积步数
  lr: 2e-5                          # 分布式训练通常需要稍大的学习率
  grad_norm_clip: 1.0               # 梯度裁剪
  
  # 动态采样配置
  enable_dynamic_sampling: true
  enable_rollout_stats_tracking: true
  rollout_skip_threshold: 3
  rollout_stats_path: "./pi0/ript/output/distributed/rollout_stats.json"
  use_val_init: false

# --- 训练配置 ---  
training:
  num_train_steps: 10                # 分布式训练步数
  seed: 42                          # 随机种子（每个进程会自动+rank）
  save_freq: 5                      # 保存检查点频率
  save_best: true
  use_mixed_precision: false        # 混合精度训练
  
  optimizer:
    type: "AdamW"
    weight_decay: 0.01
    momentum: 0.9
    beta1: 0.9
    beta2: 0.999

# --- 日志配置 ---
logging:
  use_wandb: false                   # 分布式训练时建议关闭wandb避免冲突
  wandb_project: "ript-pi0-distributed"
  wandb_entity: null
  wandb_mode: "offline"
  log_freq: 1
  log_gradients: false
  log_dir: "./pi0/ript/output/distributed/logs"

# --- 增强采样配置 ---
enhanced_sampling:
  enable_smart_filtering: true
  max_sampling_attempts: 15          # 分布式环境下减少尝试次数
  debug_sampling: true
  save_videos: true
  video_dir: "rollout_videos_distributed"

# --- 性能优化配置 ---
performance:
  enable_torch_compile: false        # PyTorch 2.0编译优化
  max_memory_per_gpu_gb: 24         # 每GPU最大内存使用
  prefetch_factor: 2                # 数据预取因子
  num_workers: 4                    # 数据加载worker数
  pin_memory: true                  # 固定内存
  
# --- 容错和恢复配置 ---
fault_tolerance:
  enable_checkpointing: true         # 启用检查点
  checkpoint_interval: 10            # 检查点间隔
  max_checkpoints_to_keep: 3         # 保留检查点数
  auto_resume: true                  # 自动恢复训练
  resume_from_latest: true           # 从最新检查点恢复

# --- 调试配置 ---
debug:
  profile_performance: false         # 性能分析
  log_memory_usage: false           # 内存使用日志
  save_intermediate_results: false   # 保存中间结果
  distributed_debug: false          # 分布式调试模式