# Stage 11 Unified Sample Pool Configuration
# 测试统一样本池训练方法：你想要的理想架构
# 🔥 与原版RIPT对齐的配置

defaults:
  - paths  # 🔥 引入paths配置
  - _self_

exp_name: stage11_unified_pool_test

# === 基本路径配置（使用paths.yaml中的配置）===
policy_path: "/zhaohan/ZJH/openpi_pytorch/checkpoints/pi0_libero_pytorch"
output_dir: "/zhaohan/ZJH/openpi_pytorch/experiments/stage11_unified_pool"  # 🔥 直接使用绝对路径
data_prefix: "/zhaohan/ZJH/openpi_pytorch/datasets"  # 🔥 直接使用绝对路径
# === 任务配置 ===
task:
  benchmark_name: "libero_spatial"         # 🔥 修复：使用小写格式
  task_names_to_use:
    - "pick_up_the_black_bowl_from_table_center_and_place_it_on_the_plate"    # 🔥 修复：从LIBERO官方任务映射获取
  num_parallel_envs: 4  # 🔥 单环境避免内存问题
  max_episode_length: 100  # 🔥 进一步限制episode长度减少样本数

# 🔥 LIBERO数据集配置（与原版RIPT对齐）
use_libero_demos: true                     # 启用LIBERO demo加载
libero_data_prefix: "/zhaohan/ZJH/openpi_pytorch/datasets"   # 🔥 直接使用绝对路径
benchmark_name: "libero_spatial"          # 与task.benchmark_name保持一致

# 🔥 数据集配置（与原版RIPT对齐）
dataset:
  seq_len: 600
  frame_stack: 1
  obs_seq_len: 1
  load_obs_for_pretrain: true
  load_next_obs: true
  get_pad_mask: true
  load_state: true  # 🔥 关键：加载MuJoCo状态数据
  # 🔥 添加缺失的配置项
  _target_: pi0.ript.utils.libero_utils_ript_aligned.build_dataset_ript_aligned

# === 算法配置 ===
algo:
  demo_batch_size: 2
  rloo_batch_size: 4  # 🔥 减少episodes数量避免OOM
  lr: 1e-5
  gradient_accumulation_steps: 4  # 🔥 增加累积步数补偿小batch
  collection_cfg_scale: 1.01
  cfg_uncond_weight: 0.1
  rollout_skip_threshold: 3
  enable_rollout_stats_tracking: false
  use_val_init: false

# === 策略配置 ===
policy:
  cfg_enabled: true  # 启用CFG测试
  train_expert_only: true
  freeze_vision_encoder: true

# === 🚀 数据处理配置 - 启用统一样本池 ===
# 注意：dataset配置已在上面定义，这里添加额外的处理配置
data_processing:
  num_init_states: 1
  state_dim: 8
  
  # 启用SO100处理 + 统一样本池
  use_so100_processing: true
  
  # Legacy配置（SO100模式下忽略）
  windowing_mode: last
  window_stride: 10
  max_windows_per_episode: 1

# === 训练配置 ===
training:
  num_train_steps: 3  # 快速测试
  seed: 42
  n_steps: 3
  rollout_steps: 1
  log_interval: 1
  save_interval: 1
  load_obs: true
  save_freq: 1

# === 日志配置 ===
logging:
  use_wandb: false
  log_freq: 1
  group: null
  mode: online
  project: "openpi-ript-vla"
  resume: true
  save_code: true

# === 特性开关 - 简化配置 ===
features:
  use_ript_vla_runner: false
  enable_parallel_envs: true      # 禁用并行环境避免卡死
  enable_true_parallel_envs: true
  enable_smart_sampling: false
  use_parallel_init_state: true  # 🔥 重新启用并行状态设置（已修复格式问题）

  save_video: false
  enable_file_counter: false
  adaptive_cfg: false
  early_stop_percentage: 1.0

  # 🔥 新增：并行环境初始状态同步控制
  parallel_env_sync:
    enabled: true                    # 启用智能随机选择
    fixed_init_state_id: -1         # 🎲 -1表示随机选择，>=0表示固定ID
    verify_sync: false              # 随机模式下不验证同步性
    sync_tolerance: 1e-6            # 状态差异容忍度
    random_sampling: true           # 🔥 新增：启用随机采样模式
  
  # 动态采样配置
  dynamic_sampling:
    enabled: true

# === 🎯 统一样本池配置说明 ===
# 
# 新的训练流程：
# 1. 收集3个episodes (rloo_batch_size=3)
# 2. 统一生成所有样本到样本池
# 3. 打散样本顺序，破除相关性
# 4. 按固定batch_size=32切分样本
# 5. 标准梯度累积训练
#
# 预期效果：
# - 固定batch大小，标准深度学习范式
# - 样本随机化，更好的训练稳定性
# - 简化的优势传播，无复杂映射
# - 更高的数据利用率

# === 训练配置（与原版RIPT对齐）- 已合并到上面的training部分 ===

# === 数据加载配置（与原版RIPT对齐）===
train_dataloader:
  batch_size: 6  # 🔥 与原版RIPT对齐
  shuffle: true
  num_workers: 6
  persistent_workers: false
  pin_memory: true

# === 日志配置（与原版RIPT对齐）- 已合并到上面的logging部分 ===

# === 可调超参数（避免硬编码） ===
unified_pool_batch_size: 8   # 统一样本池每个batch大小 - 修复显存累积后适当提升
unified_pool_shuffle: true     # 是否在样本池层面打散样本顺序

# 🔥 与原版RIPT对齐的参数说明：
# 1. rloo_batch_size: 控制每次收集的episodes数量
# 2. unified_pool_batch_size: 控制训练时的batch大小
# 3. gradient_accumulation_steps: 控制梯度累积
# 4. collection_cfg_scale: 控制CFG引导强度
# 5. load_state: true - 关键，加载MuJoCo状态数据
