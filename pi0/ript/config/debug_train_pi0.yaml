# Debug config for PI0 RIPT training - minimal setup to isolate issues
exp_name: pi0_debug_test

# --- Paths ---
policy_path: "./checkpoints/pi0_libero_pytorch"
output_dir: "./pi0/ript/output"
norm_stats_path: "./checkpoints/pi0_libero_pytorch/norm_stats.json"

# --- Task and Environment (Minimal) ---
task:
  benchmark_name: "libero_spatial"
  task_name: null
  num_parallel_envs: 2  # 2 parallel environments for testing
  max_episode_length: 60  # Short episodes

# --- RL Algorithm (Minimal) ---
algo:
  rloo_batch_size: 1  # Single rollout
  num_epochs: 1      # Single epoch
  data_batch_size: 1 # Single batch
  gradient_accumulation_steps: 1
  lr: 1e-5
  grad_norm_clip: 1.0
  enable_dynamic_sampling: false
  enable_rollout_stats_tracking: false
  use_val_init: false

# --- Training (Minimal) ---
training:
  num_train_steps: 3  # Only 3 steps for debugging
  seed: 42
  save_freq: 1
  save_best: false
  use_mixed_precision: false
  optimizer:
    type: "Adam"
    weight_decay: 0.0

# --- Distributed (Disabled) ---
distributed:
  backend: "nccl"
  gradient_checkpointing: false
  zero_optimization: false
  fp16: false
  bf16: false
  sharded_ddp: false

# --- Logging (Minimal) ---
logging:
  use_wandb: false  # Disable wandb for debugging
  log_freq: 1
  log_gradients: false

# --- Features (New RIPT-VLA Runner Support) ---
features:
  # ğŸš€ å¯ç”¨RIPT-VLA Runner - æ–°çš„å¹¶è¡Œç¯å¢ƒå®ç°
  use_ript_vla_runner: false  # è®¾ä¸ºtrueå¯ç”¨ï¼Œfalseä½¿ç”¨åŸæœ‰runner
  
  # ä¼ ç»ŸåŠŸèƒ½ï¼ˆå¯ç”¨å¹¶è¡Œç¯å¢ƒæµ‹è¯•ï¼‰
  enable_task_polling: false
  enable_parallel_envs: true  # å¯ç”¨å¹¶è¡Œç¯å¢ƒ
  enable_smart_sampling: false
  enable_true_parallel_envs: false