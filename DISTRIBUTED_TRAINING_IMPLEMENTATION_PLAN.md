# åˆ†å¸ƒå¼è®­ç»ƒæ ¸å¿ƒé€»è¾‘å®ç°è¯¦ç»†è§„åˆ’

## ğŸ“‹ ç›®æ ‡é€»è¾‘æè¿°

### ç†æƒ³åˆ†å¸ƒå¼è®­ç»ƒæµç¨‹
1. **å¯åŠ¨æ—¶**ï¼šå°†9ä¸ªä»»åŠ¡å¹³å‡åˆ†åˆ°å„GPU
   - 2 GPUæ—¶ï¼šrank-0ï¼ˆGPU0ï¼‰â†’ ä»»åŠ¡[0,2,4,6,8]ï¼Œrank-1ï¼ˆGPU1ï¼‰â†’ ä»»åŠ¡[1,3,5,7]
   - å½“å‰è°ƒè¯•YAMLåªæœ‰1ä¸ªtask(9)ï¼šrank-0â†’[9]ï¼Œrank-1â†’[]

2. **è®­ç»ƒå¾ªç¯**ï¼šè¿›è¡Œ`num_train_steps`æ¬¡è¿­ä»£ï¼ˆè°ƒè¯•YAML=3æ¬¡ï¼‰
   - æ¯æ¬¡è¿­ä»£ï¼šå½“å‰è¿›ç¨‹åªå¤„ç†è‡ªå·±ä»»åŠ¡åˆ—è¡¨ä¸­çš„**ä¸€ä¸ªä»»åŠ¡**
   - ä»»åŠ¡è½®è¯¢ï¼šé€šè¿‡`task_cursor`å¾ªç¯åˆ‡æ¢ä»»åŠ¡

3. **æ•°æ®é‡‡æ ·**ï¼šåœ¨å½“å‰ä»»åŠ¡çš„å…¨éƒ¨init-stateåˆ—è¡¨ä¸­
   - ç”¨ç¯å½¢ç´¢å¼•å–`num_parallel_envs Ã— rloo_batch_size`æ¡çŠ¶æ€
   - ç¡®ä¿ä¸åŒç¯å¢ƒè·å¾—ä¸åŒåˆå§‹çŠ¶æ€

4. **å¹¶è¡Œæ‰§è¡Œ**ï¼šå¯åŠ¨`num_parallel_envs`ä¸ªç¯å¢ƒå¹¶è¡Œè·‘rollout
   - æ”¶é›†åˆ°æ»¡è¶³`data_batch_size`æ¡è½¨è¿¹ååœæ­¢é‡‡æ ·

5. **è®­ç»ƒæ›´æ–°**ï¼šç”¨æ”¶é›†çš„æ•°æ®åšåå‘ä¼ æ’­ + DDPæ¢¯åº¦åŒæ­¥

## ğŸ“Š å½“å‰å®ç°çŠ¶æ€æ·±åº¦åˆ†æ

### âœ… å·²æ­£ç¡®å®ç°çš„éƒ¨åˆ†

#### 1. ä»»åŠ¡åˆ†ç‰‡æœºåˆ¶ (`get_distributed_tasks()`)
**ä½ç½®**: `10_train_with_distributed.py:381-406`

**å®ç°çŠ¶æ€**: âœ… **æ ¸å¿ƒé€»è¾‘æ­£ç¡®**
```python
# æ­£ç¡®çš„è½®è¯¢åˆ†é…ç®—æ³•
for task_i, task_name in enumerate(all_tasks):
    rank_to_tasks[task_i % self.world_size].append(task_name)
```

**éªŒè¯ç»“æœ**:
- 9ä¸ªä»»åŠ¡ â†’ rank0: [0,2,4,6,8], rank1: [1,3,5,7]
- 1ä¸ªä»»åŠ¡ â†’ rank0: [9], rank1: [] âœ… ç¬¦åˆé¢„æœŸ

**é—®é¢˜**: å½“å‰YAML`task_name: 9`åªæœ‰1ä¸ªä»»åŠ¡ï¼Œå¯¼è‡´rank1ä¸ºç©º

#### 2. åˆ†å¸ƒå¼è®­ç»ƒä¸»å¾ªç¯
**ä½ç½®**: `10_train_with_distributed.py:804-876`

**å®ç°çŠ¶æ€**: âœ… **æ¶æ„æ­£ç¡®**
```python
for iteration in range(self.config['training']['num_train_steps']):
    # æ•°æ®æ”¶é›† â†’ ä¼˜åŠ¿è®¡ç®— â†’ æ¢¯åº¦æ›´æ–°
```

**ä¼˜ç‚¹**: DDPæ¢¯åº¦åŒæ­¥ã€åˆ†å¸ƒå¼æŒ‡æ ‡èšåˆå·²å®ç°

#### 3. å¹¶è¡Œç¯å¢ƒæ”¯æŒ
**ä½ç½®**: `pi0/ript/env/pi0_libero_runner.py:181-220`

**å®ç°çŠ¶æ€**: âœ… **åŠŸèƒ½å®Œæ•´**
```python
def create_parallel_envs(self, env_name: str):
    parallel_env = SubprocVectorEnv([env_factory for _ in range(env_num)])
```

**ä¼˜ç‚¹**: çœŸæ­£çš„è¿›ç¨‹çº§å¹¶è¡Œï¼Œæ”¯æŒä¸²è¡Œå›é€€

### âŒ æ ¸å¿ƒé€»è¾‘ç¼ºå¤±åˆ†æ

#### 1. **ä»»åŠ¡è½®è¯¢æœºåˆ¶** - ğŸš¨ **å®Œå…¨ç¼ºå¤±**

**æœŸæœ›é€»è¾‘**:
```python
# æ¯æ¬¡è¿­ä»£åªå¤„ç†ä¸€ä¸ªä»»åŠ¡
current_task = local_tasks[task_cursor % len(local_tasks)]
task_cursor += 1  # ä¸‹æ¬¡è¿­ä»£åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªä»»åŠ¡
```

**å½“å‰å®ç°**: 
```python
# é”™è¯¯ï¼šæ¯æ¬¡éƒ½ä¼ é€’æ•´ä¸ªä»»åŠ¡åˆ—è¡¨
env_runner = LIBEROEnvRunner(task_names_to_use=local_tasks)  # æ‰€æœ‰ä»»åŠ¡
```

**é—®é¢˜**:
- `LIBEROEnvRunner`æ²¡æœ‰`task_cursor`æ¦‚å¿µ
- æ¯æ¬¡è¿­ä»£å¤„ç†æ‰€æœ‰ä»»åŠ¡ï¼Œè€Œéå•ä¸ªä»»åŠ¡è½®è¯¢

#### 2. **ç¯å½¢ç´¢å¼•çŠ¶æ€é‡‡æ ·** - ğŸš¨ **å®Œå…¨ç¼ºå¤±**

**æœŸæœ›é€»è¾‘**:
```python
# ç¯å½¢ç´¢å¼•é€‰æ‹©åˆå§‹çŠ¶æ€
start_idx = (init_state_cursor) % len(all_init_states)
required_states = num_parallel_envs * rloo_batch_size
selected_states = []
for i in range(required_states):
    idx = (start_idx + i) % len(all_init_states)
    selected_states.append(all_init_states[idx])
init_state_cursor += required_states
```

**å½“å‰å®ç°**:
```python
# é”™è¯¯ï¼šéšæœºé‡‡æ ·
def sample_batch(self, batch_size=1):
    indices = np.random.choice(len(self.states), batch_size, replace=True)
```

**é—®é¢˜**:
- å®Œå…¨éšæœºé‡‡æ ·ï¼Œæ²¡æœ‰ç¯å½¢ç´¢å¼•
- å¯èƒ½é‡å¤é€‰æ‹©ç›¸åŒçŠ¶æ€
- ä¸åŒç¯å¢ƒå¯èƒ½è·å¾—ç›¸åŒåˆå§‹çŠ¶æ€

#### 3. **ç²¾ç¡®æ•°æ®æ”¶é›†æ§åˆ¶** - ğŸš¨ **é€»è¾‘é”™è¯¯**

**æœŸæœ›é€»è¾‘**:
```python
# æ”¶é›†åˆ°data_batch_sizeæ¡è½¨è¿¹å°±åœæ­¢
collected_episodes = []
while len(collected_episodes) < data_batch_size:
    # é‡‡æ ·è½¨è¿¹...
    collected_episodes.extend(new_episodes)
```

**å½“å‰å®ç°**:
```python
# é”™è¯¯ï¼šæŒ‰æ‰¹æ¬¡æ•°æ”¶é›†ï¼Œä¸ç²¾ç¡®
for i in range(config.target_batches_per_iteration):  # å›ºå®šæ‰¹æ¬¡æ•°
    # æ¯æ‰¹å›ºå®šæ”¶é›†æ•°æ®
```

**é—®é¢˜**:
- `target_batches_per_iteration`ä¸`data_batch_size`æ²¡æœ‰ç²¾ç¡®å¯¹åº”
- å¯èƒ½æ”¶é›†è¿‡å¤šæˆ–è¿‡å°‘æ•°æ®

#### 4. **å•è¿›ç¨‹å†…ä»»åŠ¡å¤„ç†** - ğŸš¨ **æ¶æ„é”™è¯¯**

**æœŸæœ›é€»è¾‘**:
```python
# æ¯æ¬¡è¿­ä»£åªå¤„ç†å½“å‰ä»»åŠ¡
current_task = get_current_task()
rollouts = env_runner.run_single_task(current_task, init_states)
```

**å½“å‰å®ç°**:
```python
# é”™è¯¯ï¼šenv_runnerå›ºå®šå¤„ç†æ‰€æœ‰ä»»åŠ¡
env_runner = LIBEROEnvRunner(task_names_to_use=local_tasks)
# æ— æ³•åŠ¨æ€åˆ‡æ¢å•ä¸ªä»»åŠ¡
```

## ğŸ¯ è¯¦ç»†å®ç°è®¡åˆ’

### é˜¶æ®µ1ï¼šä»»åŠ¡è½®è¯¢æœºåˆ¶é‡æ„

#### 1.1 ä¿®æ”¹`LIBEROEnvRunner`ç±»
**æ–‡ä»¶**: `pi0/ript/env/pi0_libero_runner.py`

**éœ€è¦æ·»åŠ **:
```python
class LIBEROEnvRunner:
    def __init__(self, ...):
        # æ–°å¢ï¼šä»»åŠ¡è½®è¯¢ç›¸å…³å±æ€§
        self.assigned_tasks = task_names_to_use or []  # åˆ†é…çš„ä»»åŠ¡åˆ—è¡¨
        self.task_cursor = 0                          # ä»»åŠ¡è½®è¯¢ç´¢å¼•
        self.current_task = None                      # å½“å‰å¤„ç†çš„ä»»åŠ¡
        
    def set_current_task_by_cursor(self):
        """æ ¹æ®cursorè®¾ç½®å½“å‰ä»»åŠ¡"""
        if self.assigned_tasks:
            self.current_task = self.assigned_tasks[self.task_cursor % len(self.assigned_tasks)]
            return self.current_task
        return None
    
    def advance_task_cursor(self):
        """æ¨è¿›ä»»åŠ¡cursoråˆ°ä¸‹ä¸€ä¸ªä»»åŠ¡"""
        self.task_cursor += 1
        return self.set_current_task_by_cursor()
```

#### 1.2 ä¿®æ”¹åˆ†å¸ƒå¼è®­ç»ƒå¾ªç¯
**æ–‡ä»¶**: `10_train_with_distributed.py`

**ä¿®æ”¹ä½ç½®**: ç¬¬804-820è¡Œçš„è®­ç»ƒå¾ªç¯

**æ–°é€»è¾‘**:
```python
for iteration in range(self.config['training']['num_train_steps']):
    # ğŸ”¥ æ–°å¢ï¼šè®¾ç½®å½“å‰è¿­ä»£çš„ä»»åŠ¡
    current_task = env_runner.set_current_task_by_cursor()
    
    if current_task is None:  # è¯¥rankæ²¡æœ‰åˆ†é…ä»»åŠ¡
        if self.rank == 0:
            print(f"Rank {self.rank} æ²¡æœ‰åˆ†é…ä»»åŠ¡ï¼Œè·³è¿‡è¿­ä»£ {iteration + 1}")
        continue
    
    if self.rank == 0:
        print(f"ğŸ¯ è¿­ä»£ {iteration + 1}: å¤„ç†ä»»åŠ¡ {current_task}")
    
    # æ•°æ®æ”¶é›†ï¼ˆåªå¤„ç†å½“å‰ä»»åŠ¡ï¼‰
    collected_batches = self.distributed_collect_batches(...)
    
    # ğŸ”¥ æ–°å¢ï¼šè¿­ä»£ç»“æŸåæ¨è¿›cursor
    env_runner.advance_task_cursor()
```

### é˜¶æ®µ2ï¼šç¯å½¢ç´¢å¼•åˆå§‹çŠ¶æ€é‡‡æ ·

#### 2.1 é‡æ„åˆå§‹çŠ¶æ€æ•°æ®é›†
**æ–‡ä»¶**: `10_train_with_distributed.py:878-914`

**æ–°å®ç°**:
```python
class DistributedInitialStateDataset:
    def __init__(self, num_states=50, state_dim=8, rank=0, world_size=1):
        self.rank = rank
        self.world_size = world_size
        self.init_state_cursor = 0  # ğŸ”¥ æ–°å¢ï¼šç¯å½¢ç´¢å¼•
        self.states = self._generate_states(num_states, state_dim, rank)
    
    def sample_batch_circular(self, batch_size: int) -> np.ndarray:
        """ç¯å½¢ç´¢å¼•é‡‡æ ·ï¼Œç¡®ä¿ä¸é‡å¤ä¸”æœ‰åº"""
        selected_states = []
        
        for i in range(batch_size):
            idx = (self.init_state_cursor + i) % len(self.states)
            selected_states.append(self.states[idx])
        
        # æ›´æ–°cursor
        self.init_state_cursor = (self.init_state_cursor + batch_size) % len(self.states)
        
        return np.array(selected_states)
    
    def get_states_for_envs(self, num_parallel_envs: int, rloo_batch_size: int) -> np.ndarray:
        """ä¸ºå¹¶è¡Œç¯å¢ƒåˆ†é…ä¸åŒçš„åˆå§‹çŠ¶æ€"""
        total_states_needed = num_parallel_envs * rloo_batch_size
        return self.sample_batch_circular(total_states_needed)
```

#### 2.2 ä¿®æ”¹é‡‡æ ·é€»è¾‘
**æ–‡ä»¶**: `pi0/ript/utils/enhanced_smart_sampling.py`

**ä¿®æ”¹æ–¹æ³•**: `smart_sample_init_state()`

**æ–°é€»è¾‘**:
```python
def smart_sample_init_state(self, init_dataset):
    # ğŸ”¥ ä½¿ç”¨ç¯å½¢ç´¢å¼•è€Œééšæœºé‡‡æ ·
    init_states = init_dataset.get_states_for_envs(
        self.config.num_parallel_envs, 
        self.config.rloo_batch_size
    )
    state_hash = self.compute_state_hash(init_states)
    return init_states, state_hash
```

### é˜¶æ®µ3ï¼šç²¾ç¡®æ•°æ®æ”¶é›†æ§åˆ¶

#### 3.1 ä¿®æ”¹æ•°æ®æ”¶é›†é€»è¾‘
**æ–‡ä»¶**: `10_train_with_distributed.py:516-531`

**æ–°å®ç°**:
```python
def distributed_collect_batches(self, env_runner, reward_function, init_dataset, sampler, config, iteration):
    """ç²¾ç¡®æ§åˆ¶æ•°æ®æ”¶é›†æ•°é‡"""
    if self.rank == 0:
        print(f"ğŸ¯ ç›®æ ‡æ”¶é›†è½¨è¿¹æ•°: {config.data_batch_size}")
    
    collected_episodes = []
    attempt = 0
    max_attempts = config.max_sampling_attempts
    
    # ğŸ”¥ ç²¾ç¡®æ§åˆ¶ï¼šæ”¶é›†åˆ°data_batch_sizeæ¡å°±åœæ­¢
    while len(collected_episodes) < config.data_batch_size and attempt < max_attempts:
        # è®¡ç®—è¿˜éœ€è¦å¤šå°‘è½¨è¿¹
        remaining_needed = config.data_batch_size - len(collected_episodes)
        
        # ç¯å½¢ç´¢å¼•é€‰æ‹©åˆå§‹çŠ¶æ€
        init_states, _ = sampler.smart_sample_init_state(init_dataset)
        
        try:
            rollout_generator = env_runner.run_policy_in_env(
                env_name=env_runner.current_task,  # ğŸ”¥ ä½¿ç”¨å½“å‰ä»»åŠ¡
                all_init_states=init_states
            )
            
            batch_episodes = []
            for success, total_reward, episode_data in rollout_generator:
                episode = {
                    'success': success,
                    'total_reward': total_reward,
                    **episode_data
                }
                batch_episodes.append(episode)
                
                # ğŸ”¥ ç²¾ç¡®æ§åˆ¶ï¼šè¾¾åˆ°ç›®æ ‡æ•°é‡å°±åœæ­¢
                if len(collected_episodes) + len(batch_episodes) >= config.data_batch_size:
                    break
            
            collected_episodes.extend(batch_episodes)
            
        except Exception as e:
            print(f"é‡‡æ ·å¤±è´¥ (å°è¯• {attempt + 1}): {e}")
        
        attempt += 1
    
    # ğŸ”¥ è£å‰ªåˆ°ç²¾ç¡®æ•°é‡
    if len(collected_episodes) > config.data_batch_size:
        collected_episodes = collected_episodes[:config.data_batch_size]
    
    if self.rank == 0:
        print(f"âœ… å®é™…æ”¶é›†è½¨è¿¹æ•°: {len(collected_episodes)}")
    
    return [collected_episodes] if collected_episodes else []
```

### é˜¶æ®µ4ï¼šé…ç½®å‚æ•°ä¿®å¤

#### 4.1 åˆ›å»ºå¤šä»»åŠ¡æµ‹è¯•é…ç½®
**æ–‡ä»¶**: `pi0/ript/config/multi_task_distributed.yaml`

**å…³é”®é…ç½®**:
```yaml
task:
  benchmark_name: "libero_spatial"
  task_names_to_use: [0, 1, 2, 3, 4, 5, 6, 7, 8]  # ğŸ”¥ 9ä¸ªä»»åŠ¡
  num_parallel_envs: 2
  rollouts_per_env: 2
  max_episode_length: 50

algo:
  rloo_batch_size: 2
  data_batch_size: 4          # ğŸ”¥ ç²¾ç¡®æ§åˆ¶ç›®æ ‡
  num_epochs: 1
  gradient_accumulation_steps: 1

training:
  num_train_steps: 6          # ğŸ”¥ 6æ­¥æµ‹è¯•ä»»åŠ¡è½®è¯¢
```

## ğŸ§ª éªŒè¯è®¡åˆ’

### æµ‹è¯•åœºæ™¯1ï¼šåŒGPUå¤šä»»åŠ¡è½®è¯¢
- **ä»»åŠ¡åˆ†é…**: GPU0â†’[0,2,4,6,8], GPU1â†’[1,3,5,7]
- **è¿­ä»£éªŒè¯**: 6æ¬¡è¿­ä»£ï¼Œæ¯GPUè½®è¯¢5ä¸ªä»»åŠ¡
- **é¢„æœŸè¾“å‡º**:
  ```
  è¿­ä»£1: GPU0å¤„ç†ä»»åŠ¡0, GPU1å¤„ç†ä»»åŠ¡1
  è¿­ä»£2: GPU0å¤„ç†ä»»åŠ¡2, GPU1å¤„ç†ä»»åŠ¡3
  ...
  è¿­ä»£6: GPU0å¤„ç†ä»»åŠ¡8, GPU1å¤„ç†ä»»åŠ¡7
  ```

### æµ‹è¯•åœºæ™¯2ï¼šç¯å½¢ç´¢å¼•éªŒè¯
- **åˆå§‹çŠ¶æ€**: 10ä¸ªçŠ¶æ€ï¼Œéœ€è¦4ä¸ªçŠ¶æ€(2envsÃ—2batch)
- **é¢„æœŸé€‰æ‹©**: ç¬¬1æ¬¡[0,1,2,3]ï¼Œç¬¬2æ¬¡[4,5,6,7]ï¼Œç¬¬3æ¬¡[8,9,0,1]

### æµ‹è¯•åœºæ™¯3ï¼šç²¾ç¡®æ•°æ®æ”¶é›†
- **ç›®æ ‡**: data_batch_size=4
- **éªŒè¯**: æ¯æ¬¡è¿­ä»£ç²¾ç¡®æ”¶é›†4æ¡è½¨è¿¹ï¼Œä¸å¤šä¸å°‘

## ğŸ“ˆ å®ç°ä¼˜å…ˆçº§

1. **HIGH**: ä»»åŠ¡è½®è¯¢æœºåˆ¶ (é˜¶æ®µ1) - è§£å†³rank1ç©ºä»»åŠ¡é—®é¢˜
2. **HIGH**: ç¯å½¢ç´¢å¼•é‡‡æ · (é˜¶æ®µ2) - ç¡®ä¿çŠ¶æ€åˆ†é…åˆç†
3. **MEDIUM**: ç²¾ç¡®æ•°æ®æ”¶é›† (é˜¶æ®µ3) - ä¼˜åŒ–è®­ç»ƒæ•ˆç‡
4. **LOW**: å¤šä»»åŠ¡é…ç½® (é˜¶æ®µ4) - å…¨é¢æµ‹è¯•éªŒè¯

## ğŸ“ å®ç°æ£€æŸ¥æ¸…å•

- [ ] `LIBEROEnvRunner`æ·»åŠ `task_cursor`å±æ€§
- [ ] å®ç°`set_current_task_by_cursor()`æ–¹æ³•
- [ ] ä¿®æ”¹è®­ç»ƒå¾ªç¯æ”¯æŒä»»åŠ¡è½®è¯¢
- [ ] é‡æ„`DistributedInitialStateDataset`æ”¯æŒç¯å½¢ç´¢å¼•
- [ ] ä¿®æ”¹`smart_sample_init_state()`ä½¿ç”¨ç¯å½¢é‡‡æ ·
- [ ] å®ç°ç²¾ç¡®çš„`data_batch_size`æ§åˆ¶é€»è¾‘
- [ ] åˆ›å»ºå¤šä»»åŠ¡æµ‹è¯•é…ç½®æ–‡ä»¶
- [ ] ç¼–å†™éªŒè¯æµ‹è¯•è„šæœ¬

## ğŸ¯ æˆåŠŸæ ‡å‡†

å®ç°å®Œæˆåï¼Œåˆ†å¸ƒå¼è®­ç»ƒåº”è¯¥èƒ½å¤Ÿï¼š
1. æ­£ç¡®å°†9ä¸ªä»»åŠ¡åˆ†é…åˆ°2ä¸ªGPU
2. æ¯æ¬¡è¿­ä»£åªå¤„ç†ä¸€ä¸ªä»»åŠ¡ï¼ŒæŒ‰cursorè½®è¯¢
3. ä½¿ç”¨ç¯å½¢ç´¢å¼•é¿å…çŠ¶æ€é‡å¤
4. ç²¾ç¡®æ”¶é›†data_batch_sizeæ•°é‡çš„è½¨è¿¹
5. æ”¯æŒä»»æ„æ•°é‡çš„ä»»åŠ¡å’ŒGPUç»„åˆ

è¿™æ ·å°±èƒ½å®ç°ä½ æè¿°çš„å®Œæ•´åˆ†å¸ƒå¼è®­ç»ƒé€»è¾‘ã€‚