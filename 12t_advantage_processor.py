"""
æµ‹è¯•ä¼˜åŠ¿å€¼å¤„ç†å™¨
éªŒè¯å½’ä¸€åŒ–ã€æˆªæ–­ã€è´Ÿå€¼å¤„ç†ç­‰æ•°å€¼ç¨³å®šæ€§åŠŸèƒ½
"""

import torch
import numpy as np
from ript.utils.advantage_processor import (
    AdvantageProcessor,
    AdvantageProcessingConfig,
    AdvantageNormalizationMode,
    AdvantageClippingMode,
    NegativeHandlingMode,
    create_advantage_processor,
    process_advantages_batch
)


def test_normalization_modes():
    """æµ‹è¯•ä¸åŒçš„å½’ä¸€åŒ–æ¨¡å¼"""
    print("ğŸ§ª æµ‹è¯•å½’ä¸€åŒ–æ¨¡å¼...")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_data = torch.tensor([1.0, 2.0, 3.0, 4.0, 5.0])
    
    # æµ‹è¯•å„ç§å½’ä¸€åŒ–æ¨¡å¼
    modes = [
        AdvantageNormalizationMode.NONE,
        AdvantageNormalizationMode.ZERO_MEAN,
        AdvantageNormalizationMode.STANDARD,
        AdvantageNormalizationMode.MIN_MAX,
        AdvantageNormalizationMode.ROBUST
    ]
    
    for mode in modes:
        config = AdvantageProcessingConfig(
            normalization_mode=mode,
            clipping_mode=AdvantageClippingMode.NONE,
            negative_handling=NegativeHandlingMode.KEEP,
            verbose=True
        )
        
        processor = AdvantageProcessor(config)
        result = processor.process_advantages(test_data.clone())
        
        print(f"æ¨¡å¼ {mode.value}:")
        print(f"  åŸå§‹: {test_data.tolist()}")
        print(f"  ç»“æœ: {result.tolist()}")
        print(f"  å‡å€¼: {result.mean():.4f}, æ ‡å‡†å·®: {result.std():.4f}")
        print()
        
        # éªŒè¯ç»“æœ
        if mode == AdvantageNormalizationMode.NONE:
            assert torch.allclose(result, test_data)
        elif mode == AdvantageNormalizationMode.ZERO_MEAN:
            assert abs(result.mean()) < 1e-6  # å‡å€¼åº”è¯¥æ¥è¿‘0
        elif mode == AdvantageNormalizationMode.STANDARD:
            assert abs(result.mean()) < 1e-6  # å‡å€¼åº”è¯¥æ¥è¿‘0
            assert abs(result.std() - 1.0) < 1e-6  # æ ‡å‡†å·®åº”è¯¥æ¥è¿‘1
        elif mode == AdvantageNormalizationMode.MIN_MAX:
            assert abs(result.min()) < 1e-6  # æœ€å°å€¼åº”è¯¥æ¥è¿‘0
            assert abs(result.max() - 1.0) < 1e-6  # æœ€å¤§å€¼åº”è¯¥æ¥è¿‘1
    
    print("âœ… å½’ä¸€åŒ–æ¨¡å¼æµ‹è¯•é€šè¿‡")


def test_clipping_modes():
    """æµ‹è¯•ä¸åŒçš„æˆªæ–­æ¨¡å¼"""
    print("ğŸ§ª æµ‹è¯•æˆªæ–­æ¨¡å¼...")
    
    # åˆ›å»ºåŒ…å«æå€¼çš„æµ‹è¯•æ•°æ®
    test_data = torch.tensor([-10.0, -2.0, -1.0, 0.0, 1.0, 2.0, 10.0])
    
    # æµ‹è¯•å¯¹ç§°æˆªæ–­
    config = AdvantageProcessingConfig(
        normalization_mode=AdvantageNormalizationMode.NONE,
        clipping_mode=AdvantageClippingMode.SYMMETRIC,
        clip_value=2.0,
        verbose=True
    )
    
    processor = AdvantageProcessor(config)
    result = processor.process_advantages(test_data.clone())
    
    print(f"å¯¹ç§°æˆªæ–­ (Â±2.0):")
    print(f"  åŸå§‹: {test_data.tolist()}")
    print(f"  ç»“æœ: {result.tolist()}")
    
    # éªŒè¯å¯¹ç§°æˆªæ–­
    assert result.min() >= -2.0
    assert result.max() <= 2.0
    
    # æµ‹è¯•åˆ†ä½æ•°æˆªæ–­
    config.clipping_mode = AdvantageClippingMode.QUANTILE
    config.quantile_range = (0.2, 0.8)
    
    processor = AdvantageProcessor(config)
    result = processor.process_advantages(test_data.clone())
    
    print(f"åˆ†ä½æ•°æˆªæ–­ (20%-80%):")
    print(f"  ç»“æœ: {result.tolist()}")
    
    # æµ‹è¯•sigmaæˆªæ–­
    config.clipping_mode = AdvantageClippingMode.SIGMA
    config.clip_value = 1.0  # 1ä¸ªæ ‡å‡†å·®
    
    processor = AdvantageProcessor(config)
    result = processor.process_advantages(test_data.clone())
    
    print(f"Sigmaæˆªæ–­ (Â±1Ïƒ):")
    print(f"  ç»“æœ: {result.tolist()}")
    print()
    
    print("âœ… æˆªæ–­æ¨¡å¼æµ‹è¯•é€šè¿‡")


def test_negative_handling():
    """æµ‹è¯•è´Ÿå€¼å¤„ç†æ¨¡å¼"""
    print("ğŸ§ª æµ‹è¯•è´Ÿå€¼å¤„ç†æ¨¡å¼...")
    
    # åˆ›å»ºåŒ…å«è´Ÿå€¼çš„æµ‹è¯•æ•°æ®
    test_data = torch.tensor([-3.0, -1.0, 0.0, 1.0, 3.0])
    
    # æµ‹è¯•å„ç§è´Ÿå€¼å¤„ç†æ¨¡å¼
    modes = [
        NegativeHandlingMode.KEEP,
        NegativeHandlingMode.SOFTPLUS,
        NegativeHandlingMode.RELU,
        NegativeHandlingMode.SHIFT_POSITIVE,
        NegativeHandlingMode.EXP
    ]
    
    for mode in modes:
        config = AdvantageProcessingConfig(
            normalization_mode=AdvantageNormalizationMode.NONE,
            clipping_mode=AdvantageClippingMode.NONE,
            negative_handling=mode,
            verbose=True
        )
        
        processor = AdvantageProcessor(config)
        result = processor.process_advantages(test_data.clone())
        
        print(f"æ¨¡å¼ {mode.value}:")
        print(f"  åŸå§‹: {test_data.tolist()}")
        print(f"  ç»“æœ: {[f'{x:.4f}' for x in result.tolist()]}")
        
        # éªŒè¯ç»“æœ
        if mode == NegativeHandlingMode.KEEP:
            assert torch.allclose(result, test_data)
        elif mode in [NegativeHandlingMode.SOFTPLUS, NegativeHandlingMode.RELU, 
                     NegativeHandlingMode.SHIFT_POSITIVE, NegativeHandlingMode.EXP]:
            assert result.min() >= 0  # åº”è¯¥æ²¡æœ‰è´Ÿå€¼
        
        print()
    
    print("âœ… è´Ÿå€¼å¤„ç†æµ‹è¯•é€šè¿‡")


def test_numerical_stability():
    """æµ‹è¯•æ•°å€¼ç¨³å®šæ€§"""
    print("ğŸ§ª æµ‹è¯•æ•°å€¼ç¨³å®šæ€§...")
    
    # åˆ›å»ºåŒ…å«é—®é¢˜å€¼çš„æµ‹è¯•æ•°æ®
    test_data = torch.tensor([
        float('nan'),     # NaN
        float('inf'),     # æ­£æ— ç©·
        float('-inf'),    # è´Ÿæ— ç©·
        1e-10,           # å¾ˆå°çš„æ­£æ•°
        -1e-10,          # å¾ˆå°çš„è´Ÿæ•°
        1e10,            # å¾ˆå¤§çš„æ­£æ•°
        -1e10,           # å¾ˆå¤§çš„è´Ÿæ•°
        0.0              # é›¶
    ])
    
    config = AdvantageProcessingConfig(
        normalization_mode=AdvantageNormalizationMode.STANDARD,
        clipping_mode=AdvantageClippingMode.SYMMETRIC,
        clip_value=5.0,
        negative_handling=NegativeHandlingMode.SOFTPLUS,
        verbose=True
    )
    
    processor = AdvantageProcessor(config)
    result = processor.process_advantages(test_data)
    
    print(f"åŸå§‹æ•°æ®: {test_data.tolist()}")
    print(f"å¤„ç†ç»“æœ: {[f'{x:.6f}' for x in result.tolist()]}")
    
    # éªŒè¯æ²¡æœ‰invalidå€¼
    assert not torch.isnan(result).any(), "ç»“æœä¸­ä¸åº”è¯¥æœ‰NaN"
    assert not torch.isinf(result).any(), "ç»“æœä¸­ä¸åº”è¯¥æœ‰Inf"
    assert result.min() >= 0, "è´Ÿå€¼å¤„ç†ååº”è¯¥æ²¡æœ‰è´Ÿæ•°"
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    processor.print_stats()
    
    print("âœ… æ•°å€¼ç¨³å®šæ€§æµ‹è¯•é€šè¿‡")


def test_edge_cases():
    """æµ‹è¯•è¾¹ç•Œæƒ…å†µ"""
    print("ğŸ§ª æµ‹è¯•è¾¹ç•Œæƒ…å†µ...")
    
    config = AdvantageProcessingConfig(verbose=True)
    processor = AdvantageProcessor(config)
    
    # æµ‹è¯•ç©ºå¼ é‡
    try:
        empty_tensor = torch.tensor([])
        result = processor.process_advantages(empty_tensor)
        assert False, "åº”è¯¥æŠ›å‡ºå¼‚å¸¸"
    except ValueError:
        print("âœ“ ç©ºå¼ é‡æ­£ç¡®æŠ›å‡ºå¼‚å¸¸")
    
    # æµ‹è¯•å•ä¸ªå€¼
    single_value = torch.tensor([5.0])
    result = processor.process_advantages(single_value)
    assert result.shape == (1,), "å•ä¸ªå€¼çš„å½¢çŠ¶åº”è¯¥ä¿æŒ"
    print(f"âœ“ å•ä¸ªå€¼å¤„ç†: {single_value.item()} â†’ {result.item():.4f}")
    
    # æµ‹è¯•ç›¸åŒå€¼
    same_values = torch.tensor([3.0, 3.0, 3.0, 3.0])
    result = processor.process_advantages(same_values)
    print(f"âœ“ ç›¸åŒå€¼å¤„ç†: {same_values.tolist()} â†’ {result.tolist()}")
    
    # æµ‹è¯•ä¸åŒæ•°æ®ç±»å‹
    int_data = torch.tensor([1, 2, 3, 4, 5])  # æ•´æ•°ç±»å‹
    result = processor.process_advantages(int_data)
    assert result.dtype.is_floating_point, "è¾“å‡ºåº”è¯¥æ˜¯æµ®ç‚¹ç±»å‹"
    print(f"âœ“ æ•´æ•°è¾“å…¥å¤„ç†: {int_data.tolist()} â†’ {[f'{x:.4f}' for x in result.tolist()]}")
    
    print("âœ… è¾¹ç•Œæƒ…å†µæµ‹è¯•é€šè¿‡")


def test_batch_processing():
    """æµ‹è¯•æ‰¹é‡å¤„ç†"""
    print("ğŸ§ª æµ‹è¯•æ‰¹é‡å¤„ç†...")
    
    # åˆ›å»ºå¤šä¸ªä¼˜åŠ¿å€¼å¼ é‡
    advantages_list = [
        torch.randn(10),      # éšæœºæ•°æ®
        torch.tensor([1.0, 2.0, 3.0]),  # å°æ•°æ®
        torch.randn(100) * 10,  # å¤§èŒƒå›´æ•°æ®
        torch.tensor([-5.0, 0.0, 5.0])  # åŒ…å«è´Ÿå€¼
    ]
    
    # ä½¿ç”¨ä¾¿æ·å‡½æ•°æ‰¹é‡å¤„ç†
    processed_list = process_advantages_batch(
        advantages_list,
        normalization="standard",
        clipping="symmetric",
        clip_value=2.0,
        negative_handling="softplus",
        verbose=False
    )
    
    assert len(processed_list) == len(advantages_list), "æ‰¹é‡å¤„ç†æ•°é‡åº”è¯¥ä¸€è‡´"
    
    for i, (original, processed) in enumerate(zip(advantages_list, processed_list)):
        print(f"æ‰¹æ¬¡ {i}: {original.shape} â†’ {processed.shape}")
        assert original.shape == processed.shape, "å½¢çŠ¶åº”è¯¥ä¿æŒä¸€è‡´"
        assert not torch.isnan(processed).any(), "ä¸åº”è¯¥æœ‰NaN"
        assert not torch.isinf(processed).any(), "ä¸åº”è¯¥æœ‰Inf"
    
    print("âœ… æ‰¹é‡å¤„ç†æµ‹è¯•é€šè¿‡")


def test_convenience_functions():
    """æµ‹è¯•ä¾¿æ·å‡½æ•°"""
    print("ğŸ§ª æµ‹è¯•ä¾¿æ·å‡½æ•°...")
    
    # æµ‹è¯•ä¾¿æ·åˆ›å»ºå‡½æ•°
    processor = create_advantage_processor(
        normalization="standard",
        clipping="quantile",
        clip_value=2.0,
        negative_handling="relu",
        verbose=False
    )
    
    test_data = torch.tensor([-2.0, -1.0, 0.0, 1.0, 2.0])
    result = processor.process_advantages(test_data)
    
    print(f"ä¾¿æ·å‡½æ•°åˆ›å»ºçš„å¤„ç†å™¨:")
    print(f"  åŸå§‹: {test_data.tolist()}")
    print(f"  ç»“æœ: {[f'{x:.4f}' for x in result.tolist()]}")
    
    # éªŒè¯è®¾ç½®
    assert processor.config.normalization_mode == AdvantageNormalizationMode.STANDARD
    assert processor.config.clipping_mode == AdvantageClippingMode.QUANTILE
    assert processor.config.negative_handling == NegativeHandlingMode.RELU
    
    print("âœ… ä¾¿æ·å‡½æ•°æµ‹è¯•é€šè¿‡")


def test_statistical_tracking():
    """æµ‹è¯•ç»Ÿè®¡è·Ÿè¸ª"""
    print("ğŸ§ª æµ‹è¯•ç»Ÿè®¡è·Ÿè¸ª...")
    
    config = AdvantageProcessingConfig(
        track_statistics=True,
        verbose=False
    )
    processor = AdvantageProcessor(config)
    
    # å¤„ç†å¤šæ‰¹æ•°æ®
    for i in range(5):
        test_data = torch.randn(20) * (i + 1)  # é€æ¸å¢å¤§çš„æ•°æ®
        if i == 2:  # åœ¨ç¬¬3æ‰¹ä¸­åŠ å…¥ä¸€äº›é—®é¢˜å€¼
            test_data[0] = float('nan')
            test_data[1] = float('inf')
            test_data[2] = -100.0  # æå€¼
        
        processor.process_advantages(test_data)
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = processor.get_processing_stats()
    
    print(f"ç»Ÿè®¡è·Ÿè¸ªç»“æœ:")
    print(f"  æ€»å¤„ç†æ¬¡æ•°: {stats['total_processed']}")
    print(f"  NaNå¤„ç†æ¬¡æ•°: {stats['nan_count']}")
    print(f"  Infå¤„ç†æ¬¡æ•°: {stats['inf_count']}")
    print(f"  è´Ÿå€¼å¤„ç†æ¬¡æ•°: {stats['negative_count']}")
    print(f"  æˆªæ–­æ¬¡æ•°: {stats['clipped_count']}")
    
    assert stats['total_processed'] == 5, "åº”è¯¥å¤„ç†äº†5æ‰¹æ•°æ®"
    assert stats['nan_count'] > 0, "åº”è¯¥æ£€æµ‹åˆ°NaN"
    assert stats['inf_count'] > 0, "åº”è¯¥æ£€æµ‹åˆ°Inf"
    
    # æ‰“å°è¯¦ç»†ç»Ÿè®¡
    processor.print_stats()
    
    print("âœ… ç»Ÿè®¡è·Ÿè¸ªæµ‹è¯•é€šè¿‡")


def test_real_world_scenario():
    """æµ‹è¯•çœŸå®ä¸–ç•Œåœºæ™¯"""
    print("ğŸ§ª æµ‹è¯•çœŸå®ä¸–ç•Œåœºæ™¯...")
    
    # æ¨¡æ‹ŸRIPTè®­ç»ƒä¸­çš„çœŸå®ä¼˜åŠ¿å€¼
    # é€šå¸¸åŒ…å«ï¼šä¸åŒå¤§å°çš„å¥–åŠ±ã€ä¸€äº›æå€¼ã€å¯èƒ½çš„æ•°å€¼é—®é¢˜
    np.random.seed(42)
    torch.manual_seed(42)
    
    # æ¨¡æ‹ŸRLOOè®¡ç®—åçš„ä¼˜åŠ¿å€¼
    batch_size = 32
    raw_advantages = []
    
    for i in range(batch_size):
        # æ¨¡æ‹Ÿä¸åŒæˆåŠŸç‡çš„rollouts
        if i < 10:  # å‰10ä¸ªï¼šé«˜å¥–åŠ±
            adv = torch.normal(2.0, 0.5, (1,))
        elif i < 20:  # ä¸­é—´10ä¸ªï¼šä¸­ç­‰å¥–åŠ±
            adv = torch.normal(0.0, 1.0, (1,))
        else:  # å12ä¸ªï¼šä½å¥–åŠ±æˆ–è´Ÿå¥–åŠ±
            adv = torch.normal(-1.0, 0.8, (1,))
        
        raw_advantages.append(adv.item())
    
    # æ·»åŠ ä¸€äº›æ•°å€¼é—®é¢˜
    raw_advantages[0] = float('nan')    # æ¨¡æ‹Ÿè®¡ç®—é”™è¯¯
    raw_advantages[1] = float('inf')    # æ¨¡æ‹Ÿæº¢å‡º
    raw_advantages[2] = -1000.0         # æ¨¡æ‹Ÿæç«¯å¤±è´¥
    raw_advantages[3] = 1000.0          # æ¨¡æ‹Ÿæç«¯æˆåŠŸ
    
    advantages_tensor = torch.tensor(raw_advantages, dtype=torch.float32)
    
    print(f"åŸå§‹ä¼˜åŠ¿å€¼ç»Ÿè®¡:")
    print(f"  æ•°é‡: {len(raw_advantages)}")
    # å…¼å®¹æ€§ä¿®å¤ï¼šæ›¿æ¢torch.nanmin/nanmax
    valid_values = advantages_tensor[~torch.isinf(advantages_tensor) & ~torch.isnan(advantages_tensor)]
    if len(valid_values) > 0:
        print(f"  èŒƒå›´: [{valid_values.min():.2f}, {valid_values.max():.2f}]")
    else:
        print(f"  èŒƒå›´: [æ— æœ‰æ•ˆå€¼]")
    print(f"  NaNæ•°: {torch.isnan(advantages_tensor).sum()}")
    print(f"  Infæ•°: {torch.isinf(advantages_tensor).sum()}")
    
    # ä½¿ç”¨æ¨èçš„ç”Ÿäº§ç¯å¢ƒé…ç½®
    processor = create_advantage_processor(
        normalization="standard",    # æ ‡å‡†å½’ä¸€åŒ–
        clipping="symmetric",       # å¯¹ç§°æˆªæ–­
        clip_value=3.0,            # 3å€æ ‡å‡†å·®æˆªæ–­
        negative_handling="softplus", # è½¯æ€§å¤„ç†è´Ÿå€¼
        verbose=True
    )
    
    # å¤„ç†ä¼˜åŠ¿å€¼
    processed_advantages = processor.process_advantages(advantages_tensor)
    
    print(f"\nå¤„ç†åä¼˜åŠ¿å€¼ç»Ÿè®¡:")
    print(f"  èŒƒå›´: [{processed_advantages.min():.4f}, {processed_advantages.max():.4f}]")
    print(f"  å‡å€¼: {processed_advantages.mean():.4f}")
    print(f"  æ ‡å‡†å·®: {processed_advantages.std():.4f}")
    print(f"  è´Ÿå€¼æ•°: {(processed_advantages < 0).sum()}")
    
    # éªŒè¯ç»“æœé€‚åˆç”¨äºè®­ç»ƒ
    assert not torch.isnan(processed_advantages).any()
    assert not torch.isinf(processed_advantages).any()
    assert processed_advantages.min() >= 0  # softplusç¡®ä¿éè´Ÿ
    assert processed_advantages.max() <= 50  # åˆç†çš„ä¸Šç•Œ
    assert abs(processed_advantages.mean()) < 2  # åˆç†çš„å‡å€¼
    
    processor.print_stats()
    
    print("âœ… çœŸå®ä¸–ç•Œåœºæ™¯æµ‹è¯•é€šè¿‡")


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹æµ‹è¯•ä¼˜åŠ¿å€¼å¤„ç†å™¨")
    print("="*50)
    
    try:
        test_normalization_modes()
        test_clipping_modes()
        test_negative_handling()
        test_numerical_stability()
        test_edge_cases()
        test_batch_processing()
        test_convenience_functions()
        test_statistical_tracking()
        test_real_world_scenario()
        
        print("\n" + "="*50)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print("\nğŸ’¡ æ¨èçš„ç”Ÿäº§ç¯å¢ƒé…ç½®:")
        print("   - normalization: 'standard' (é›¶å‡å€¼å•ä½æ–¹å·®)")
        print("   - clipping: 'symmetric' with clip_value=3.0")
        print("   - negative_handling: 'softplus' (å¹³æ»‘å¤„ç†)")
        print("   - å¯ç”¨ç»Ÿè®¡è·Ÿè¸ªä»¥ç›‘æ§æ•°å€¼å¥åº·çŠ¶å†µ")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
