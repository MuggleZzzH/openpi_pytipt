"""
OpenPI-RIPTå…¼å®¹æ•°æ®åŒ…è£…å™¨
æ”¯æŒåœ¨OpenPIæ ‡å‡†æ ¼å¼åŸºç¡€ä¸Šæ·»åŠ å¯é€‰çš„RIPTå­—æ®µï¼ˆadvantages, init_hashï¼‰
ç¡®ä¿å‘åå…¼å®¹æ€§ï¼Œä¸ç ´åç°æœ‰è®­ç»ƒæµç¨‹
"""

import copy
import torch
from torch.utils.data import Dataset
from typing import Dict, Any, Optional, Union
from lerobot.common.datasets.lerobot_dataset import LeRobotDataset
from torchvision.transforms.v2 import Resize
from utils.normalizers import Normalizer
from utils.state_dimension_adapter import StateDimensionAdapter, StateDimensionConfig, create_pi0_state_adapter


class OpenPIRiptDatasetWrapper(Dataset):
    """
    OpenPIå’ŒRIPTå…¼å®¹çš„æ•°æ®åŒ…è£…å™¨
    
    Features:
    - ä¿æŒOpenPIæ ‡å‡†æ•°æ®æ ¼å¼
    - æ”¯æŒå¯é€‰RIPTå­—æ®µï¼ˆadvantages, init_hashï¼‰
    - å‘åå…¼å®¹ç°æœ‰æ•°æ®é›†
    - æ”¯æŒçŠ¶æ€ç»´åº¦è‡ªåŠ¨å¯¹é½
    """
    
    def __init__(
        self,
        repo_id: str = "ZibinDong/so100_grab_screwdriver",
        image_size: int = 224,
        action_chunk_size: int = 50,
        fps: float = 30.0,
        target_state_dim: Optional[int] = None,
        enable_ript_fields: bool = False,
        default_advantages: Optional[torch.Tensor] = None,
        **dataset_kwargs
    ):
        """
        Args:
            repo_id: HuggingFaceæ•°æ®é›†ID
            image_size: å›¾åƒç¼©æ”¾å°ºå¯¸
            action_chunk_size: åŠ¨ä½œchunké•¿åº¦
            fps: å¸§ç‡ï¼Œç”¨äºè®¡ç®—æ—¶é—´æˆ³
            target_state_dim: ç›®æ ‡çŠ¶æ€ç»´åº¦ï¼Œç”¨äºç»´åº¦å¯¹é½
            enable_ript_fields: æ˜¯å¦å¯ç”¨RIPTå­—æ®µ
            default_advantages: é»˜è®¤ä¼˜åŠ¿å€¼
            **dataset_kwargs: ä¼ é€’ç»™LeRobotDatasetçš„é¢å¤–å‚æ•°
        """
        
        self.repo_id = repo_id
        self.image_size = image_size
        self.action_chunk_size = action_chunk_size
        self.fps = fps
        self.target_state_dim = target_state_dim
        self.enable_ript_fields = enable_ript_fields
        
        # åˆå§‹åŒ–çŠ¶æ€ç»´åº¦é€‚é…å™¨
        self.state_adapter = None
        if target_state_dim is not None:
            self.state_adapter = create_pi0_state_adapter(
                target_state_dim=target_state_dim,
                padding_mode="zero",
                truncation_mode="first"
            )
        
        # è®¾ç½®å›¾åƒå˜æ¢
        self.image_transforms = Resize((image_size, image_size))
        
        # è®¾ç½®delta_timestamps (OpenPIæ ‡å‡†)
        self.delta_timestamps = {
            "observation.images.base": [0],
            "observation.images.wrist": [0],
            "observation.state": [0],
            "action": [i / fps for i in range(action_chunk_size)],
        }
        
        # åˆå§‹åŒ–LeRobotDataset
        self.dataset = LeRobotDataset(
            repo_id=repo_id,
            image_transforms=self.image_transforms,
            delta_timestamps=self.delta_timestamps,
            **dataset_kwargs
        )
        
        # åˆå§‹åŒ–å½’ä¸€åŒ–å™¨
        self.normalizer = Normalizer(
            norm_stats=self.dataset.meta.stats,
            norm_type={
                "observation.images.base": "identity",
                "observation.images.wrist": "identity", 
                "observation.state": "meanstd",
                "action": "std",
            },
        )
        
        # è®¾ç½®é»˜è®¤ä¼˜åŠ¿å€¼
        if default_advantages is None:
            self.default_advantages = torch.zeros(action_chunk_size)
        else:
            self.default_advantages = default_advantages
            
        print(f"âœ… OpenPIRiptDatasetWrapperåˆå§‹åŒ–å®Œæˆ")
        print(f"   - æ•°æ®é›†: {repo_id}")
        print(f"   - å›¾åƒå°ºå¯¸: {image_size}x{image_size}")
        print(f"   - åŠ¨ä½œchunkå¤§å°: {action_chunk_size}")
        print(f"   - RIPTå­—æ®µ: {'å¯ç”¨' if enable_ript_fields else 'ç¦ç”¨'}")
        print(f"   - æ•°æ®é›†å¤§å°: {len(self.dataset)}")

    def __len__(self):
        return len(self.dataset)
    
    def __getitem__(self, idx: int) -> Dict[str, Any]:
        """
        è·å–æ•°æ®æ ·æœ¬ï¼Œè¿”å›OpenPIæ ‡å‡†æ ¼å¼ + å¯é€‰RIPTå­—æ®µ
        
        Returns:
            Dict containing:
            - image: {"base_0_rgb": tensor, "left_wrist_0_rgb": tensor}
            - state: å½“å‰çŠ¶æ€ (å¯èƒ½ç»è¿‡ç»´åº¦å¯¹é½)
            - action: åŠ¨ä½œchunk
            - action_is_pad: paddingæ©ç 
            - prompt: ä»»åŠ¡æè¿°
            - advantages: (å¯é€‰) RIPTä¼˜åŠ¿å€¼
            - init_hash: (å¯é€‰) åˆå§‹çŠ¶æ€å“ˆå¸Œ
        """
        try:
            # 1. è·å–åŸå§‹æ•°æ®
            item = self.dataset[idx]
            
            # 2. å¤„ç†ç›¸å¯¹åŠ¨ä½œ (OpenPIæ ‡å‡†)
            item["action"] = item["action"] - item["observation.state"]
            
            # 3. å½’ä¸€åŒ–
            normalized_item = self.normalizer.normalize(item)
            
            # 4. å¤„ç†å›¾åƒ (è½¬æ¢ä¸ºuint8æ ¼å¼)
            base_image = (normalized_item["observation.images.base"] * 255).to(torch.uint8)
            wrist_image = (normalized_item["observation.images.wrist"] * 255).to(torch.uint8)
            
            # 5. å¤„ç†çŠ¶æ€ç»´åº¦å¯¹é½
            current_state = normalized_item["observation.state"][0]  # å–å½“å‰æ—¶åˆ»
            if self.state_adapter is not None:
                current_state = self.state_adapter.align_state_dimension(current_state, batch_idx=idx)
            
            # 6. æ„é€ OpenPIæ ‡å‡†æ ¼å¼
            sample = {
                "image": {
                    "base_0_rgb": base_image,
                    "left_wrist_0_rgb": wrist_image
                },
                "state": current_state,
                "action": normalized_item["action"],
                "action_is_pad": normalized_item["action_is_pad"],
                "prompt": item["task"],
            }
            
            # 7. æ·»åŠ å¯é€‰RIPTå­—æ®µ
            if self.enable_ript_fields:
                # ä¼˜åŠ¿å€¼ï¼šä¼˜å…ˆä½¿ç”¨æ•°æ®ä¸­çš„ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤å€¼
                sample["advantages"] = item.get("advantages", self.default_advantages.clone())
                
                # åˆå§‹çŠ¶æ€å“ˆå¸Œï¼šä¼˜å…ˆä½¿ç”¨æ•°æ®ä¸­çš„ï¼Œå¦åˆ™è®¡ç®—
                sample["init_hash"] = item.get("init_hash", self._compute_init_hash(current_state))
            
            return sample
            
        except Exception as e:
            print(f"âŒ æ•°æ®åŠ è½½é”™è¯¯ (idx={idx}): {e}")
            # è¿”å›ä¸€ä¸ªå®‰å…¨çš„é»˜è®¤æ ·æœ¬
            return self._create_fallback_sample()
    
    def get_state_adapter_stats(self) -> Dict[str, Any]:
        """
        è·å–çŠ¶æ€é€‚é…å™¨ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            çŠ¶æ€é€‚é…å™¨çš„è½¬æ¢ç»Ÿè®¡
        """
        if self.state_adapter is not None:
            return self.state_adapter.get_conversion_stats()
        else:
            return {"message": "çŠ¶æ€é€‚é…å™¨æœªå¯ç”¨"}
    
    def print_state_adapter_stats(self):
        """æ‰“å°çŠ¶æ€é€‚é…å™¨ç»Ÿè®¡ä¿¡æ¯"""
        if self.state_adapter is not None:
            self.state_adapter.print_stats()
        else:
            print("çŠ¶æ€é€‚é…å™¨æœªå¯ç”¨")
    
    def _compute_init_hash(self, state: torch.Tensor) -> str:
        """
        è®¡ç®—åˆå§‹çŠ¶æ€å“ˆå¸Œ
        
        Args:
            state: çŠ¶æ€å¼ é‡
            
        Returns:
            çŠ¶æ€å“ˆå¸Œå­—ç¬¦ä¸²
        """
        # ç®€å•å“ˆå¸Œè®¡ç®—ï¼Œåç»­å¯ä»¥æ›¿æ¢ä¸ºæ›´å¤æ‚çš„é€»è¾‘
        state_bytes = state.detach().cpu().numpy().tobytes()
        hash_value = str(hash(state_bytes))
        return hash_value
    
    def _create_fallback_sample(self) -> Dict[str, Any]:
        """
        åˆ›å»ºå®‰å…¨çš„fallbackæ ·æœ¬ï¼Œé˜²æ­¢æ•°æ®åŠ è½½å¤±è´¥
        
        Returns:
            é»˜è®¤æ ·æœ¬å­—å…¸
        """
        # åˆ›å»ºé»˜è®¤çš„å¼ é‡
        default_image = torch.zeros(3, self.image_size, self.image_size, dtype=torch.uint8)
        
        # åˆ›å»ºé»˜è®¤çŠ¶æ€å¹¶åº”ç”¨çŠ¶æ€é€‚é…å™¨
        fallback_state_dim = self.target_state_dim or 9
        default_state = torch.zeros(fallback_state_dim)
        if self.state_adapter is not None:
            # çŠ¶æ€é€‚é…å™¨å·²å¯ç”¨ï¼Œç¡®ä¿ç»´åº¦æ­£ç¡®
            default_state = self.state_adapter.align_state_dimension(default_state)
        
        default_action = torch.zeros(self.action_chunk_size, 7)  # å‡è®¾7ç»´åŠ¨ä½œ
        default_padding = torch.zeros(self.action_chunk_size, dtype=torch.bool)
        
        sample = {
            "image": {
                "base_0_rgb": default_image,
                "left_wrist_0_rgb": default_image
            },
            "state": default_state,
            "action": default_action,
            "action_is_pad": default_padding,
            "prompt": "fallback_task",
        }
        
        if self.enable_ript_fields:
            sample["advantages"] = self.default_advantages.clone()
            sample["init_hash"] = "fallback_hash"
        
        print("âš ï¸  ä½¿ç”¨fallbackæ ·æœ¬")
        return sample
    
    def get_sample_info(self, idx: int) -> Dict[str, Any]:
        """
        è·å–æ ·æœ¬ä¿¡æ¯ï¼Œç”¨äºè°ƒè¯•
        
        Args:
            idx: æ ·æœ¬ç´¢å¼•
            
        Returns:
            æ ·æœ¬ä¿¡æ¯å­—å…¸
        """
        sample = self[idx]
        
        info = {
            "index": idx,
            "image_shapes": {k: v.shape for k, v in sample["image"].items()},
            "state_shape": sample["state"].shape,
            "action_shape": sample["action"].shape,
            "action_is_pad_shape": sample["action_is_pad"].shape,
            "prompt": sample["prompt"],
        }
        
        if self.enable_ript_fields:
            info["advantages_shape"] = sample["advantages"].shape
            info["init_hash"] = sample["init_hash"]
        
        return info
    
    def validate_dataset(self, num_samples: int = 5) -> bool:
        """
        éªŒè¯æ•°æ®é›†çš„å®Œæ•´æ€§
        
        Args:
            num_samples: éªŒè¯çš„æ ·æœ¬æ•°é‡
            
        Returns:
            æ˜¯å¦éªŒè¯é€šè¿‡
        """
        print(f"ğŸ” éªŒè¯æ•°æ®é›† (æ£€æŸ¥{num_samples}ä¸ªæ ·æœ¬)...")
        
        try:
            for i in range(min(num_samples, len(self))):
                sample = self[i]
                
                # éªŒè¯å¿…éœ€å­—æ®µ
                required_fields = ["image", "state", "action", "action_is_pad", "prompt"]
                for field in required_fields:
                    if field not in sample:
                        print(f"âŒ ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
                        return False
                
                # éªŒè¯å›¾åƒæ ¼å¼
                image_dict = sample["image"]
                for cam_name, img_tensor in image_dict.items():
                    if not isinstance(img_tensor, torch.Tensor):
                        print(f"âŒ å›¾åƒä¸æ˜¯å¼ é‡: {cam_name}")
                        return False
                    if img_tensor.dim() != 3:  # (C, H, W)
                        print(f"âŒ å›¾åƒç»´åº¦é”™è¯¯: {cam_name}, shape={img_tensor.shape}")
                        return False
                
                # éªŒè¯åŠ¨ä½œç»´åº¦ä¸€è‡´æ€§
                action_tensor = sample["action"]
                padding_tensor = sample["action_is_pad"]
                if action_tensor.shape[0] != padding_tensor.shape[0]:
                    print(f"âŒ åŠ¨ä½œä¸paddingé•¿åº¦ä¸åŒ¹é…: {action_tensor.shape[0]} vs {padding_tensor.shape[0]}")
                    return False
                
                # éªŒè¯RIPTå­—æ®µï¼ˆå¦‚æœå¯ç”¨ï¼‰
                if self.enable_ript_fields:
                    if "advantages" not in sample or "init_hash" not in sample:
                        print(f"âŒ ç¼ºå°‘RIPTå­—æ®µ")
                        return False
                
            print(f"âœ… æ•°æ®é›†éªŒè¯é€šè¿‡ ({num_samples}ä¸ªæ ·æœ¬)")
            return True
            
        except Exception as e:
            print(f"âŒ æ•°æ®é›†éªŒè¯å¤±è´¥: {e}")
            return False


def create_openpi_ript_dataset(
    repo_id: str,
    enable_ript: bool = False,
    **kwargs
) -> OpenPIRiptDatasetWrapper:
    """
    å·¥å‚å‡½æ•°ï¼šåˆ›å»ºOpenPI-RIPTå…¼å®¹æ•°æ®é›†
    
    Args:
        repo_id: æ•°æ®é›†ID
        enable_ript: æ˜¯å¦å¯ç”¨RIPTåŠŸèƒ½
        **kwargs: å…¶ä»–å‚æ•°
        
    Returns:
        æ•°æ®é›†å®ä¾‹
    """
    dataset = OpenPIRiptDatasetWrapper(
        repo_id=repo_id,
        enable_ript_fields=enable_ript,
        **kwargs
    )
    
    # éªŒè¯æ•°æ®é›†
    if not dataset.validate_dataset():
        raise ValueError("æ•°æ®é›†éªŒè¯å¤±è´¥")
    
    return dataset


# å‘åå…¼å®¹çš„åˆ«å
PI0RiptDataset = OpenPIRiptDatasetWrapper
