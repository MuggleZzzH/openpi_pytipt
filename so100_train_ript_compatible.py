"""
ä½¿ç”¨OpenPI-RIPTå…¼å®¹æ•°æ®åŒ…è£…å™¨çš„è®­ç»ƒç¤ºä¾‹
å±•ç¤ºå¦‚ä½•åœ¨ä¿æŒOpenPIæ ‡å‡†çš„åŒæ—¶æ”¯æŒRIPTåŠŸèƒ½
"""

import lightning as L
import torch
from torch.optim.lr_scheduler import LinearLR
from torch.utils.data import DataLoader
from lightning.pytorch.callbacks import ModelCheckpoint

from pi0.modeling_pi0 import PI0Policy
from lerobot.configs.policies import PreTrainedConfig
from utils.openpi_ript_dataset_wrapper import create_openpi_ript_dataset


def to_device_dtype(d, device, dtype):
    """å°†æ•°æ®æ‰¹æ¬¡è½¬ç§»åˆ°æŒ‡å®šè®¾å¤‡å’Œæ•°æ®ç±»å‹"""
    for key, value in d.items():
        if isinstance(value, dict):
            to_device_dtype(value, device, dtype)
        elif isinstance(value, torch.Tensor):
            if key not in ["action_is_pad"]:
                d[key] = value.to(device=device, dtype=dtype)
            else:
                d[key] = value.to(device=device)
        else:
            pass
    return d


class LightningTrainingWrapperRiptCompatible(L.LightningModule):
    """
    å…¼å®¹RIPTçš„Lightningè®­ç»ƒåŒ…è£…å™¨
    """
    
    def __init__(self, config, ckpt_path, enable_ript_training=False):
        super().__init__()
        self.policy = None
        self.config = config
        self.ckpt_path = ckpt_path
        self.enable_ript_training = enable_ript_training
        
        print(f"ğŸš€ åˆå§‹åŒ–è®­ç»ƒåŒ…è£…å™¨")
        print(f"   - RIPTè®­ç»ƒ: {'å¯ç”¨' if enable_ript_training else 'ç¦ç”¨'}")

    def configure_model(self):
        if self.policy is None:
            self.policy = PI0Policy.from_pretrained(self.ckpt_path, config=self.config)
            print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ: {self.ckpt_path}")

    def forward(self, batch):
        return self.policy(batch)[0]

    def training_step(self, batch, batch_idx):
        """
        è®­ç»ƒæ­¥éª¤ï¼Œæ”¯æŒæ ‡å‡†è®­ç»ƒå’ŒRIPTè®­ç»ƒ
        """
        if self.enable_ript_training:
            # RIPTè®­ç»ƒæ¨¡å¼ï¼šä½¿ç”¨ä¼˜åŠ¿åŠ æƒ
            loss = self._ript_training_step(batch, batch_idx)
        else:
            # æ ‡å‡†è®­ç»ƒæ¨¡å¼
            loss = self.policy(batch)[0]
            
        self.log("train_loss", loss, prog_bar=True)
        
        # è®°å½•é¢å¤–æŒ‡æ ‡
        if self.enable_ript_training and "advantages" in batch:
            advantages = batch["advantages"]
            self.log("advantages/mean", advantages.mean(), prog_bar=False)
            self.log("advantages/std", advantages.std(), prog_bar=False)
            
        return loss
    
    def _ript_training_step(self, batch, batch_idx):
        """
        RIPTè®­ç»ƒæ­¥éª¤ï¼Œä½¿ç”¨ä¼˜åŠ¿åŠ æƒ
        """
        # è·å–åŸºç¡€æŸå¤±
        base_loss = self.policy(batch)[0]
        
        # å¦‚æœæœ‰ä¼˜åŠ¿å€¼ï¼Œè¿›è¡ŒåŠ æƒ
        if "advantages" in batch:
            advantages = batch["advantages"]
            
            # ç®€å•çš„ä¼˜åŠ¿åŠ æƒï¼ˆåç»­å¯ä»¥æ›¿æ¢ä¸ºæ›´å¤æ‚çš„CFGé€»è¾‘ï¼‰
            # å½’ä¸€åŒ–ä¼˜åŠ¿å€¼
            adv_norm = (advantages - advantages.mean()) / (advantages.std() + 1e-8)
            adv_weights = torch.nn.functional.softplus(adv_norm)
            
            # åŠ æƒæŸå¤±
            weighted_loss = (base_loss * adv_weights.mean()).mean()
            
            return weighted_loss
        else:
            return base_loss

    def configure_optimizers(self):
        optimizer = torch.optim.AdamW(
            self.policy.get_optim_params(), 
            lr=5e-5, 
            weight_decay=1e-2, 
            eps=1e-6
        )
        scheduler = LinearLR(
            optimizer,
            start_factor=0.01,
            end_factor=1.0,
            total_iters=100,
        )
        return {
            "optimizer": optimizer,
            "lr_scheduler": {
                "scheduler": scheduler,
                "interval": "step",
                "frequency": 1,
            },
        }


def create_compatible_dataloader(
    repo_id: str = "ZibinDong/so100_grab_screwdriver",
    batch_size: int = 4,
    enable_ript: bool = False,
    **kwargs
):
    """
    åˆ›å»ºå…¼å®¹çš„æ•°æ®åŠ è½½å™¨
    
    Args:
        repo_id: æ•°æ®é›†ID
        batch_size: æ‰¹æ¬¡å¤§å°
        enable_ript: æ˜¯å¦å¯ç”¨RIPTåŠŸèƒ½
        **kwargs: å…¶ä»–å‚æ•°
    """
    print(f"ğŸ”„ åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
    print(f"   - æ•°æ®é›†: {repo_id}")
    print(f"   - æ‰¹æ¬¡å¤§å°: {batch_size}")
    print(f"   - RIPTæ¨¡å¼: {'å¯ç”¨' if enable_ript else 'ç¦ç”¨'}")
    
    # åˆ›å»ºå…¼å®¹æ•°æ®é›†
    dataset = create_openpi_ript_dataset(
        repo_id=repo_id,
        enable_ript=enable_ript,
        action_chunk_size=50,
        target_state_dim=9,  # æ ¹æ®å®é™…æ¨¡å‹éœ€æ±‚è°ƒæ•´
        **kwargs
    )
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    dataloader = DataLoader(
        dataset, 
        batch_size=batch_size, 
        shuffle=True, 
        num_workers=4, 
        persistent_workers=True
    )
    
    print(f"âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆ")
    return dataloader


def train_openpi_standard():
    """
    æ ‡å‡†OpenPIè®­ç»ƒï¼ˆå‘åå…¼å®¹ï¼‰
    """
    print("ğŸ¯ å¼€å§‹æ ‡å‡†OpenPIè®­ç»ƒ...")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨ï¼ˆRIPTåŠŸèƒ½ç¦ç”¨ï¼‰
    dataloader = create_compatible_dataloader(
        enable_ript=False,
        batch_size=4
    )
    
    # åˆ›å»ºæ£€æŸ¥ç‚¹å›è°ƒ
    callback = ModelCheckpoint(
        dirpath="/tmp/pi0_standard_checkpoints",
        filename="{epoch}-{step}",
        save_top_k=-1,
        every_n_epochs=4,
    )
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = L.Trainer(
        accelerator="cuda",
        devices=1,  # å•GPUç”¨äºæµ‹è¯•
        max_epochs=2,  # å°‘é‡epochç”¨äºæµ‹è¯•
        enable_progress_bar=True,
        gradient_clip_val=1.0,
        precision="bf16-mixed",
        accumulate_grad_batches=4,
        callbacks=[callback],
    )
    
    # åˆå§‹åŒ–æ¨¡å‹
    with trainer.init_module():
        ckpt_path = "/home/dzb/.cache/openpi/openpi-assets/checkpoints/pi0_base_pytorch"
        config = PreTrainedConfig.from_pretrained(ckpt_path)
        config.device = "cpu"
        config.freeze_vision_encoder = True
        config.train_expert_only = True
        config.train_state_proj = True
        
        training_policy = LightningTrainingWrapperRiptCompatible(
            config, 
            ckpt_path, 
            enable_ript_training=False
        )
    
    # å¼€å§‹è®­ç»ƒ
    trainer.fit(training_policy, dataloader)
    print("âœ… æ ‡å‡†è®­ç»ƒå®Œæˆ")


def train_openpi_ript_compatible():
    """
    RIPTå…¼å®¹è®­ç»ƒï¼ˆå±•ç¤ºæ–°åŠŸèƒ½ï¼‰
    """
    print("ğŸ¯ å¼€å§‹RIPTå…¼å®¹è®­ç»ƒ...")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨ï¼ˆRIPTåŠŸèƒ½å¯ç”¨ï¼‰
    dataloader = create_compatible_dataloader(
        enable_ript=True,
        batch_size=4
    )
    
    # åˆ›å»ºæ£€æŸ¥ç‚¹å›è°ƒ
    callback = ModelCheckpoint(
        dirpath="/tmp/pi0_ript_checkpoints",
        filename="{epoch}-{step}",
        save_top_k=-1,
        every_n_epochs=4,
    )
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = L.Trainer(
        accelerator="cuda",
        devices=1,  # å•GPUç”¨äºæµ‹è¯•
        max_epochs=2,  # å°‘é‡epochç”¨äºæµ‹è¯•
        enable_progress_bar=True,
        gradient_clip_val=1.0,
        precision="bf16-mixed",
        accumulate_grad_batches=4,
        callbacks=[callback],
    )
    
    # åˆå§‹åŒ–æ¨¡å‹
    with trainer.init_module():
        ckpt_path = "/home/dzb/.cache/openpi/openpi-assets/checkpoints/pi0_base_pytorch"
        config = PreTrainedConfig.from_pretrained(ckpt_path)
        config.device = "cpu"
        config.freeze_vision_encoder = True
        config.train_expert_only = True
        config.train_state_proj = True
        
        training_policy = LightningTrainingWrapperRiptCompatible(
            config, 
            ckpt_path, 
            enable_ript_training=True
        )
    
    # å¼€å§‹è®­ç»ƒ
    trainer.fit(training_policy, dataloader)
    print("âœ… RIPTå…¼å®¹è®­ç»ƒå®Œæˆ")


def test_data_compatibility():
    """
    æµ‹è¯•æ•°æ®å…¼å®¹æ€§
    """
    print("ğŸ§ª æµ‹è¯•æ•°æ®å…¼å®¹æ€§...")
    
    # æµ‹è¯•1ï¼šæ ‡å‡†æ¨¡å¼
    print("\n--- æµ‹è¯•æ ‡å‡†æ¨¡å¼ ---")
    dataset_standard = create_openpi_ript_dataset(
        repo_id="ZibinDong/so100_grab_screwdriver",
        enable_ript=False
    )
    sample_standard = dataset_standard[0]
    print(f"æ ‡å‡†æ¨¡å¼æ ·æœ¬å­—æ®µ: {list(sample_standard.keys())}")
    
    # æµ‹è¯•2ï¼šRIPTæ¨¡å¼
    print("\n--- æµ‹è¯•RIPTæ¨¡å¼ ---")
    dataset_ript = create_openpi_ript_dataset(
        repo_id="ZibinDong/so100_grab_screwdriver",
        enable_ript=True
    )
    sample_ript = dataset_ript[0]
    print(f"RIPTæ¨¡å¼æ ·æœ¬å­—æ®µ: {list(sample_ript.keys())}")
    
    # éªŒè¯å­—æ®µå…¼å®¹æ€§
    common_fields = ["image", "state", "action", "action_is_pad", "prompt"]
    for field in common_fields:
        assert field in sample_standard, f"æ ‡å‡†æ¨¡å¼ç¼ºå°‘å­—æ®µ: {field}"
        assert field in sample_ript, f"RIPTæ¨¡å¼ç¼ºå°‘å­—æ®µ: {field}"
    
    # éªŒè¯RIPTç‰¹æœ‰å­—æ®µ
    ript_fields = ["advantages", "init_hash"]
    for field in ript_fields:
        assert field not in sample_standard, f"æ ‡å‡†æ¨¡å¼ä¸åº”æœ‰RIPTå­—æ®µ: {field}"
        assert field in sample_ript, f"RIPTæ¨¡å¼ç¼ºå°‘å­—æ®µ: {field}"
    
    print("âœ… æ•°æ®å…¼å®¹æ€§æµ‹è¯•é€šè¿‡")


if __name__ == "__main__":
    # æµ‹è¯•æ•°æ®å…¼å®¹æ€§
    test_data_compatibility()
    
    # æ³¨é‡Šæ‰å®é™…è®­ç»ƒï¼ˆéœ€è¦GPUå’Œæ£€æŸ¥ç‚¹ï¼‰
    # train_openpi_standard()
    # train_openpi_ript_compatible()
    
    print("ğŸ‰ ç¤ºä¾‹ä»£ç è¿è¡Œå®Œæˆ")
