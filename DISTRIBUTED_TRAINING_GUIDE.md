# PI0 RIPT åˆ†å¸ƒå¼è®­ç»ƒæŒ‡å—

## æ¦‚è¿°

ç¬¬10é˜¶æ®µå®ç°äº†å®Œæ•´çš„å¤šGPUåˆ†å¸ƒå¼è®­ç»ƒæ”¯æŒï¼ŒåŸºäºåŸç‰ˆRIPTçš„åˆ†å¸ƒå¼æ¶æ„ï¼Œç»“åˆPyTorch DDP (DistributedDataParallel) æä¾›é«˜æ•ˆçš„åˆ†å¸ƒå¼è®­ç»ƒèƒ½åŠ›ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å•æœºå¤šGPUè®­ç»ƒ

æœ€ç®€å•çš„åˆ†å¸ƒå¼è®­ç»ƒå¯åŠ¨æ–¹å¼ï¼š

```bash
cd /zhaohan/ZJH/openpi_pytorch

# 2GPUå¿«é€Ÿæµ‹è¯•
./scripts/quick_distributed_test.sh

# 4GPUæ ‡å‡†è®­ç»ƒ
./scripts/launch_distributed_training.sh \
    --config pi0/ript/config/distributed_train_pi0.yaml \
    --gpus 4

# 8GPUå¤§è§„æ¨¡è®­ç»ƒ
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 \
./scripts/launch_distributed_training.sh \
    --config pi0/ript/config/distributed_train_pi0.yaml \
    --gpus 8
```

### å¤šæœºè®­ç»ƒ

å¯¹äºè·¨å¤šä¸ªèŠ‚ç‚¹çš„è®­ç»ƒï¼š

```bash
# èŠ‚ç‚¹0 (ä¸»èŠ‚ç‚¹)
./scripts/launch_distributed_training.sh \
    --config pi0/ript/config/distributed_train_pi0.yaml \
    --nodes 2 --gpus 4 --node-rank 0 \
    --master-addr 192.168.1.100 --master-port 12355

# èŠ‚ç‚¹1 (å·¥ä½œèŠ‚ç‚¹)
./scripts/launch_distributed_training.sh \
    --config pi0/ript/config/distributed_train_pi0.yaml \
    --nodes 2 --gpus 4 --node-rank 1 \
    --master-addr 192.168.1.100 --master-port 12355
```

## ğŸ“‹ æ ¸å¿ƒç‰¹æ€§

### âœ… å·²å®ç°åŠŸèƒ½

1. **æ ‡å‡†PyTorchåˆ†å¸ƒå¼è®­ç»ƒ (DDP)**
   - è‡ªåŠ¨æ¢¯åº¦åŒæ­¥å’Œèšåˆ
   - é«˜æ•ˆçš„å‚æ•°æ›´æ–°æœºåˆ¶
   - å†…ç½®å®¹é”™èƒ½åŠ›

2. **ä»»åŠ¡åˆ†ç‰‡å’Œè´Ÿè½½å‡è¡¡**
   - æ™ºèƒ½ä»»åŠ¡åˆ†é…ç»™ä¸åŒGPU
   - è‡ªåŠ¨è´Ÿè½½å‡è¡¡
   - æ”¯æŒå¤šä»»åŠ¡å¹¶è¡Œè®­ç»ƒ

3. **åˆ†å¸ƒå¼æ•°æ®é‡‡æ ·**
   - å„è¿›ç¨‹ç‹¬ç«‹é‡‡æ ·ä¸åŒåˆå§‹çŠ¶æ€
   - æ™ºèƒ½çŠ¶æ€ç»Ÿè®¡åŒæ­¥
   - é¿å…æ•°æ®é‡å¤å’Œç«äº‰

4. **æ¢¯åº¦åŒæ­¥å’Œèšåˆ**
   - è‡ªåŠ¨æ¢¯åº¦èšåˆ
   - æ”¯æŒæ¢¯åº¦ç´¯ç§¯
   - å¯é…ç½®åŒæ­¥é¢‘ç‡

5. **åˆ†å¸ƒå¼ç»Ÿè®¡æ•°æ®åŒæ­¥**
   - é‡‡æ ·ç»Ÿè®¡å®æ—¶åŒæ­¥
   - è®­ç»ƒæŒ‡æ ‡èšåˆ
   - åˆ†å¸ƒå¼æ—¥å¿—è®°å½•

6. **å¤šGPUç¯å¢ƒä¼˜åŒ–**
   - å†…å­˜ä½¿ç”¨ä¼˜åŒ–
   - é€šä¿¡å¼€é”€æœ€å°åŒ–
   - æ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒ

## ğŸ”§ é…ç½®è¯¦è§£

### åˆ†å¸ƒå¼é…ç½®

```yaml
distributed:
  enabled: true                      # å¯ç”¨åˆ†å¸ƒå¼è®­ç»ƒ
  backend: 'nccl'                    # é€šä¿¡åç«¯: nccl(GPU), gloo(CPU)
  timeout_seconds: 10800             # é€šä¿¡è¶…æ—¶(3å°æ—¶)
  find_unused_parameters: false     # DDPä¼˜åŒ–å‚æ•°
  bucket_cap_mb: 25                  # æ¢¯åº¦æ¡¶å¤§å°
```

### æ•°æ®å¹¶è¡Œé…ç½®

```yaml
data_parallel:
  sync_every_n_steps: 5              # ç»Ÿè®¡åŒæ­¥é¢‘ç‡
  enable_gradient_checkpointing: false # æ¢¯åº¦æ£€æŸ¥ç‚¹(èŠ‚çœå†…å­˜)
  async_data_loading: true           # å¼‚æ­¥æ•°æ®åŠ è½½
```

### ä»»åŠ¡åˆ†ç‰‡é…ç½®

```yaml
task_distribution:
  enable_task_sharding: true         # å¯ç”¨ä»»åŠ¡åˆ†ç‰‡
  balance_tasks_across_gpus: true    # è´Ÿè½½å‡è¡¡
  min_tasks_per_gpu: 1              # æ¯GPUæœ€å°ä»»åŠ¡æ•°
```

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

### ç†è®ºåŠ é€Ÿæ¯”

| GPUæ•°é‡ | ç†è®ºåŠ é€Ÿæ¯” | å®é™…åŠ é€Ÿæ¯”* | å†…å­˜ä½¿ç”¨ |
|---------|-----------|------------|----------|
| 1       | 1.0x      | 1.0x       | 100%     |
| 2       | 2.0x      | 1.7-1.9x   | 50%      |
| 4       | 4.0x      | 3.2-3.7x   | 25%      |
| 8       | 8.0x      | 5.5-7.2x   | 12.5%    |

*å®é™…åŠ é€Ÿæ¯”è€ƒè™‘äº†é€šä¿¡å¼€é”€å’Œè´Ÿè½½ä¸å‡è¡¡

### é€šä¿¡å¼€é”€åˆ†æ

- **æ¢¯åº¦åŒæ­¥**: æ¯ä¸ªè®­ç»ƒæ­¥éª¤
- **ç»Ÿè®¡åŒæ­¥**: æ¯Næ­¥ (å¯é…ç½®)
- **æ£€æŸ¥ç‚¹åŒæ­¥**: ä¸»è¿›ç¨‹è´Ÿè´£
- **æ—¥å¿—èšåˆ**: å®æ—¶æˆ–æ‰¹é‡

## ğŸ› ï¸ é«˜çº§é…ç½®

### æ€§èƒ½ä¼˜åŒ–

```yaml
performance:
  enable_torch_compile: false        # PyTorch 2.0ç¼–è¯‘ä¼˜åŒ–
  max_memory_per_gpu_gb: 24         # æ¯GPUå†…å­˜é™åˆ¶
  prefetch_factor: 2                # æ•°æ®é¢„å–
  num_workers: 4                    # æ•°æ®åŠ è½½å™¨workeræ•°
  pin_memory: true                  # å†…å­˜å›ºå®š
```

### å®¹é”™é…ç½®

```yaml
fault_tolerance:
  enable_checkpointing: true         # æ£€æŸ¥ç‚¹ä¿å­˜
  checkpoint_interval: 10            # ä¿å­˜é—´éš”
  max_checkpoints_to_keep: 3         # ä¿ç•™æ•°é‡
  auto_resume: true                  # è‡ªåŠ¨æ¢å¤
  resume_from_latest: true           # ä»æœ€æ–°æ¢å¤
```

### è°ƒè¯•é…ç½®

```yaml
debug:
  profile_performance: false         # æ€§èƒ½åˆ†æ
  log_memory_usage: false           # å†…å­˜æ—¥å¿—
  save_intermediate_results: false   # ä¸­é—´ç»“æœ
  distributed_debug: false          # åˆ†å¸ƒå¼è°ƒè¯•
```

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. NCCLåˆå§‹åŒ–å¤±è´¥

```bash
# æ£€æŸ¥NCCLç‰ˆæœ¬
python -c "import torch; print(torch.cuda.nccl.version())"

# è®¾ç½®è°ƒè¯•ç¯å¢ƒå˜é‡
export NCCL_DEBUG=INFO
export NCCL_TIMEOUT=3600
```

#### 2. GPUå†…å­˜ä¸è¶³

```yaml
# å‡å°‘æ‰¹æ¬¡å¤§å°
algo:
  rloo_batch_size: 2
  data_batch_size: 4

# å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
data_parallel:
  enable_gradient_checkpointing: true
```

#### 3. è¿›ç¨‹åŒæ­¥è¶…æ—¶

```yaml
# å¢åŠ è¶…æ—¶æ—¶é—´
distributed:
  timeout_seconds: 18000  # 5å°æ—¶

# å‡å°‘åŒæ­¥é¢‘ç‡
data_parallel:
  sync_every_n_steps: 10
```

#### 4. ä»»åŠ¡åˆ†é…ä¸å‡

```yaml
# å¯ç”¨è´Ÿè½½å‡è¡¡
task_distribution:
  balance_tasks_across_gpus: true
  enable_task_sharding: true
```

### è°ƒè¯•å·¥å…·

```bash
# æ£€æŸ¥GPUçŠ¶æ€
nvidia-smi

# ç›‘æ§GPUä½¿ç”¨
watch -n 1 nvidia-smi

# æ£€æŸ¥è¿›ç¨‹é€šä¿¡
ps aux | grep torchrun

# æŸ¥çœ‹åˆ†å¸ƒå¼æ—¥å¿—
tail -f pi0/ript/output/distributed/logs/distributed_training_*.log
```

## ğŸ“ˆ ç›‘æ§å’Œæ—¥å¿—

### æ—¥å¿—ç»“æ„

```
pi0/ript/output/distributed/
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ distributed_training_20250805_143022_node0.log
â”‚   â”œâ”€â”€ train_rank_0.log
â”‚   â”œâ”€â”€ train_rank_1.log
â”‚   â””â”€â”€ ...
â”œâ”€â”€ distributed_training_results.json
â””â”€â”€ checkpoints/
    â”œâ”€â”€ checkpoint_step_10.pth
    â””â”€â”€ checkpoint_latest.pth
```

### å…³é”®æŒ‡æ ‡

- **è®­ç»ƒé€Ÿåº¦**: steps/second
- **GPUåˆ©ç”¨ç‡**: % per GPU
- **å†…å­˜ä½¿ç”¨**: MB per GPU
- **é€šä¿¡æ—¶é—´**: ms per sync
- **æˆåŠŸç‡**: episode success rate
- **æŸå¤±æ”¶æ•›**: training loss curve

## ğŸ¯ æœ€ä½³å®è·µ

### 1. èµ„æºé…ç½®

```bash
# å•æœºè®­ç»ƒæ¨èé…ç½®
export CUDA_VISIBLE_DEVICES=0,1,2,3
export OMP_NUM_THREADS=4
export NCCL_TIMEOUT=3600
```

### 2. æ‰¹æ¬¡å¤§å°è°ƒä¼˜

- **æ€»æ‰¹æ¬¡å¤§å° = GPUæ•°é‡ Ã— æ¯GPUæ‰¹æ¬¡å¤§å°**
- **å»ºè®®æ¯GPUæ‰¹æ¬¡å¤§å°**: 2-4 (å—å†…å­˜é™åˆ¶)
- **æ¢¯åº¦ç´¯ç§¯æ­¥æ•°**: æ ¹æ®ç›®æ ‡æ‰¹æ¬¡å¤§å°è°ƒæ•´

### 3. å­¦ä¹ ç‡ç¼©æ”¾

```yaml
# åˆ†å¸ƒå¼è®­ç»ƒé€šå¸¸éœ€è¦ç¨å¤§çš„å­¦ä¹ ç‡
algo:
  lr: 2e-5  # å•æœºä¸º1e-5
```

### 4. åŒæ­¥é¢‘ç‡ä¼˜åŒ–

```yaml
# æƒè¡¡é€šä¿¡å¼€é”€å’Œç»Ÿè®¡å‡†ç¡®æ€§
data_parallel:
  sync_every_n_steps: 5  # é¢‘ç¹åŒæ­¥è·å¾—æ›´å‡†ç¡®ç»Ÿè®¡
  # sync_every_n_steps: 10  # å‡å°‘é€šä¿¡å¼€é”€
```

## ğŸš€ é«˜çº§ç”¨æ³•

### æ··åˆç²¾åº¦è®­ç»ƒ

```yaml
training:
  use_mixed_precision: true

performance:
  enable_torch_compile: true
```

### è‡ªå®šä¹‰ä»»åŠ¡åˆ†ç‰‡

```python
# åœ¨é…ç½®ä¸­æŒ‡å®šç‰¹å®šä»»åŠ¡åˆ†é…
task:
  task_names_to_use: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
  
task_distribution:
  enable_task_sharding: true
```

### åŠ¨æ€å­¦ä¹ ç‡è°ƒæ•´

```yaml
# æ ¹æ®world_sizeè‡ªåŠ¨è°ƒæ•´å­¦ä¹ ç‡
# å®é™…å­¦ä¹ ç‡ = base_lr * sqrt(world_size)
algo:
  lr: 1e-5  # base learning rate
  lr_scaling: "sqrt"  # å¯é€‰: linear, sqrt, none
```

## ğŸ“ æ”¯æŒå’Œåé¦ˆ

å¦‚æœé‡åˆ°é—®é¢˜æˆ–éœ€è¦åŠŸèƒ½è¯·æ±‚ï¼Œè¯·ï¼š

1. æ£€æŸ¥æ—¥å¿—æ–‡ä»¶ä¸­çš„è¯¦ç»†é”™è¯¯ä¿¡æ¯
2. éªŒè¯GPUå’ŒCUDAç¯å¢ƒé…ç½®
3. å°è¯•è°ƒè¯•é…ç½®è¿›è¡Œç®€åŒ–æµ‹è¯•
4. æŸ¥é˜…æ•…éšœæ’é™¤ç« èŠ‚

---

**æ³¨æ„**: åˆ†å¸ƒå¼è®­ç»ƒéœ€è¦è¾ƒé«˜çš„ç³»ç»Ÿé…ç½®å’Œç½‘ç»œå¸¦å®½ã€‚å»ºè®®åœ¨ä¸“ç”¨çš„è®­ç»ƒé›†ç¾¤æˆ–é«˜æ€§èƒ½å·¥ä½œç«™ä¸Šè¿è¡Œã€‚